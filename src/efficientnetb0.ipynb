{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "012de95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing and splitting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|██████████| 257/257 [00:20<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting augmentation on training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting 001_1: 100%|██████████| 6/6 [00:00<00:00, 12.00it/s]\n",
      "Augmenting 001_2: 100%|██████████| 6/6 [00:00<00:00, 12.18it/s]\n",
      "Augmenting 001_3: 100%|██████████| 6/6 [00:00<00:00, 12.64it/s]\n",
      "Augmenting 001_4: 100%|██████████| 6/6 [00:00<00:00, 14.10it/s]\n",
      "Augmenting 001_5: 100%|██████████| 6/6 [00:00<00:00, 12.50it/s]\n",
      "Augmenting 001_6: 100%|██████████| 6/6 [00:00<00:00, 10.17it/s]\n",
      "Augmenting 002_10: 100%|██████████| 6/6 [00:00<00:00, 11.68it/s]\n",
      "Augmenting 002_11: 100%|██████████| 6/6 [00:00<00:00, 13.53it/s]\n",
      "Augmenting 002_12: 100%|██████████| 6/6 [00:00<00:00, 11.78it/s]\n",
      "Augmenting 002_7: 100%|██████████| 6/6 [00:00<00:00, 12.61it/s]\n",
      "Augmenting 002_8: 100%|██████████| 6/6 [00:00<00:00, 12.01it/s]\n",
      "Augmenting 002_9: 100%|██████████| 6/6 [00:00<00:00, 12.46it/s]\n",
      "Augmenting 003_13: 100%|██████████| 6/6 [00:00<00:00, 11.83it/s]\n",
      "Augmenting 003_14: 100%|██████████| 6/6 [00:00<00:00, 11.62it/s]\n",
      "Augmenting 003_15: 100%|██████████| 6/6 [00:00<00:00, 12.33it/s]\n",
      "Augmenting 003_16: 100%|██████████| 6/6 [00:00<00:00, 13.42it/s]\n",
      "Augmenting 003_17: 100%|██████████| 6/6 [00:00<00:00, 12.15it/s]\n",
      "Augmenting 003_18: 100%|██████████| 6/6 [00:00<00:00, 14.36it/s]\n",
      "Augmenting 004_19: 100%|██████████| 6/6 [00:00<00:00, 12.83it/s]\n",
      "Augmenting 004_20: 100%|██████████| 6/6 [00:00<00:00, 10.92it/s]\n",
      "Augmenting 004_21: 100%|██████████| 6/6 [00:00<00:00, 11.92it/s]\n",
      "Augmenting 004_22: 100%|██████████| 6/6 [00:00<00:00, 12.59it/s]\n",
      "Augmenting 004_23: 100%|██████████| 6/6 [00:00<00:00, 13.90it/s]\n",
      "Augmenting 004_24: 100%|██████████| 6/6 [00:00<00:00, 11.51it/s]\n",
      "Augmenting 005_25: 100%|██████████| 6/6 [00:00<00:00, 13.58it/s]\n",
      "Augmenting 005_26: 100%|██████████| 6/6 [00:00<00:00, 13.23it/s]\n",
      "Augmenting 005_27: 100%|██████████| 6/6 [00:00<00:00, 13.04it/s]\n",
      "Augmenting 005_28: 100%|██████████| 6/6 [00:00<00:00, 13.51it/s]\n",
      "Augmenting 005_29: 100%|██████████| 6/6 [00:00<00:00, 15.15it/s]\n",
      "Augmenting 005_30: 100%|██████████| 6/6 [00:00<00:00, 16.46it/s]\n",
      "Augmenting 006_31: 100%|██████████| 6/6 [00:00<00:00, 14.70it/s]\n",
      "Augmenting 006_32: 100%|██████████| 6/6 [00:00<00:00, 13.82it/s]\n",
      "Augmenting 006_33: 100%|██████████| 6/6 [00:00<00:00, 12.33it/s]\n",
      "Augmenting 006_34: 100%|██████████| 6/6 [00:00<00:00, 14.00it/s]\n",
      "Augmenting 006_35: 100%|██████████| 6/6 [00:00<00:00, 13.59it/s]\n",
      "Augmenting 006_36: 100%|██████████| 6/6 [00:00<00:00, 14.44it/s]\n",
      "Augmenting 007_37: 100%|██████████| 6/6 [00:00<00:00, 15.02it/s]\n",
      "Augmenting 007_38: 100%|██████████| 6/6 [00:00<00:00, 13.82it/s]\n",
      "Augmenting 007_39: 100%|██████████| 6/6 [00:00<00:00, 13.93it/s]\n",
      "Augmenting 007_40: 100%|██████████| 6/6 [00:00<00:00, 14.55it/s]\n",
      "Augmenting 007_41: 100%|██████████| 6/6 [00:00<00:00, 14.68it/s]\n",
      "Augmenting 007_42: 100%|██████████| 6/6 [00:00<00:00, 14.00it/s]\n",
      "Augmenting 008_43: 100%|██████████| 6/6 [00:00<00:00, 14.85it/s]\n",
      "Augmenting 008_44: 100%|██████████| 6/6 [00:00<00:00, 15.37it/s]\n",
      "Augmenting 008_45: 100%|██████████| 6/6 [00:00<00:00, 13.80it/s]\n",
      "Augmenting 009_46: 100%|██████████| 6/6 [00:00<00:00, 14.83it/s]\n",
      "Augmenting 009_47: 100%|██████████| 6/6 [00:00<00:00, 13.54it/s]\n",
      "Augmenting 009_48: 100%|██████████| 6/6 [00:00<00:00, 13.97it/s]\n",
      "Augmenting 009_49: 100%|██████████| 6/6 [00:00<00:00, 11.79it/s]\n",
      "Augmenting 009_50: 100%|██████████| 6/6 [00:00<00:00, 13.80it/s]\n",
      "Augmenting 009_51: 100%|██████████| 6/6 [00:00<00:00, 14.01it/s]\n",
      "Augmenting 010_52: 100%|██████████| 6/6 [00:00<00:00, 13.69it/s]\n",
      "Augmenting 010_53: 100%|██████████| 6/6 [00:00<00:00, 12.61it/s]\n",
      "Augmenting 010_54: 100%|██████████| 6/6 [00:00<00:00, 13.39it/s]\n",
      "Augmenting 010_55: 100%|██████████| 6/6 [00:00<00:00, 12.86it/s]\n",
      "Augmenting 010_56: 100%|██████████| 6/6 [00:00<00:00, 12.49it/s]\n",
      "Augmenting 010_57: 100%|██████████| 6/6 [00:00<00:00, 12.75it/s]\n",
      "Augmenting 010_58: 100%|██████████| 6/6 [00:00<00:00, 14.23it/s]\n",
      "Augmenting 010_59: 100%|██████████| 6/6 [00:00<00:00, 13.95it/s]\n",
      "Augmenting 010_60: 100%|██████████| 6/6 [00:00<00:00, 12.97it/s]\n",
      "Augmenting 010_61: 100%|██████████| 6/6 [00:00<00:00, 12.68it/s]\n",
      "Augmenting 011_62: 100%|██████████| 6/6 [00:00<00:00, 13.30it/s]\n",
      "Augmenting 011_63: 100%|██████████| 6/6 [00:00<00:00, 13.55it/s]\n",
      "Augmenting 011_64: 100%|██████████| 6/6 [00:00<00:00, 14.31it/s]\n",
      "Augmenting 011_65: 100%|██████████| 6/6 [00:00<00:00, 12.33it/s]\n",
      "Augmenting 011_66: 100%|██████████| 6/6 [00:00<00:00, 13.54it/s]\n",
      "Augmenting 011_67: 100%|██████████| 6/6 [00:00<00:00, 14.01it/s]\n",
      "Augmenting 011_68: 100%|██████████| 6/6 [00:00<00:00, 13.20it/s]\n",
      "Augmenting 011_69: 100%|██████████| 6/6 [00:00<00:00, 14.68it/s]\n",
      "Augmenting 011_70: 100%|██████████| 6/6 [00:00<00:00, 14.21it/s]\n",
      "Augmenting 011_71: 100%|██████████| 6/6 [00:00<00:00, 13.70it/s]\n",
      "Augmenting 012_72: 100%|██████████| 6/6 [00:00<00:00, 13.28it/s]\n",
      "Augmenting 012_73: 100%|██████████| 6/6 [00:00<00:00, 12.37it/s]\n",
      "Augmenting 012_74: 100%|██████████| 6/6 [00:00<00:00, 13.56it/s]\n",
      "Augmenting 012_75: 100%|██████████| 6/6 [00:00<00:00, 13.25it/s]\n",
      "Augmenting 012_76: 100%|██████████| 6/6 [00:00<00:00, 13.60it/s]\n",
      "Augmenting 012_77: 100%|██████████| 6/6 [00:00<00:00, 13.08it/s]\n",
      "Augmenting 012_78: 100%|██████████| 6/6 [00:00<00:00, 13.31it/s]\n",
      "Augmenting 012_79: 100%|██████████| 6/6 [00:00<00:00, 13.21it/s]\n",
      "Augmenting 012_80: 100%|██████████| 6/6 [00:00<00:00, 14.06it/s]\n",
      "Augmenting 012_81: 100%|██████████| 6/6 [00:00<00:00, 13.36it/s]\n",
      "Augmenting 013_82: 100%|██████████| 6/6 [00:00<00:00, 12.95it/s]\n",
      "Augmenting 013_83: 100%|██████████| 6/6 [00:00<00:00, 13.66it/s]\n",
      "Augmenting 013_84: 100%|██████████| 6/6 [00:00<00:00, 14.25it/s]\n",
      "Augmenting 013_85: 100%|██████████| 6/6 [00:00<00:00, 13.73it/s]\n",
      "Augmenting 013_86: 100%|██████████| 6/6 [00:00<00:00, 14.16it/s]\n",
      "Augmenting 013_87: 100%|██████████| 6/6 [00:00<00:00, 14.81it/s]\n",
      "Augmenting 013_88: 100%|██████████| 6/6 [00:00<00:00, 13.21it/s]\n",
      "Augmenting 013_89: 100%|██████████| 6/6 [00:00<00:00, 14.00it/s]\n",
      "Augmenting 013_90: 100%|██████████| 6/6 [00:00<00:00, 13.98it/s]\n",
      "Augmenting 013_91: 100%|██████████| 6/6 [00:00<00:00, 12.60it/s]\n",
      "Augmenting 014_100: 100%|██████████| 6/6 [00:00<00:00, 14.19it/s]\n",
      "Augmenting 014_101: 100%|██████████| 6/6 [00:00<00:00, 14.26it/s]\n",
      "Augmenting 014_92: 100%|██████████| 6/6 [00:00<00:00, 14.67it/s]\n",
      "Augmenting 014_93: 100%|██████████| 6/6 [00:00<00:00, 14.47it/s]\n",
      "Augmenting 014_94: 100%|██████████| 6/6 [00:00<00:00, 14.21it/s]\n",
      "Augmenting 014_95: 100%|██████████| 6/6 [00:00<00:00, 13.77it/s]\n",
      "Augmenting 014_96: 100%|██████████| 6/6 [00:00<00:00, 14.58it/s]\n",
      "Augmenting 014_97: 100%|██████████| 6/6 [00:00<00:00, 13.16it/s]\n",
      "Augmenting 014_98: 100%|██████████| 6/6 [00:00<00:00, 12.98it/s]\n",
      "Augmenting 014_99: 100%|██████████| 6/6 [00:00<00:00, 14.56it/s]\n",
      "Augmenting 015_102: 100%|██████████| 6/6 [00:00<00:00, 13.19it/s]\n",
      "Augmenting 015_103: 100%|██████████| 6/6 [00:00<00:00, 13.34it/s]\n",
      "Augmenting 015_104: 100%|██████████| 6/6 [00:00<00:00, 12.92it/s]\n",
      "Augmenting 015_105: 100%|██████████| 6/6 [00:00<00:00, 13.63it/s]\n",
      "Augmenting 015_106: 100%|██████████| 6/6 [00:00<00:00, 14.25it/s]\n",
      "Augmenting 016_107: 100%|██████████| 6/6 [00:00<00:00, 13.04it/s]\n",
      "Augmenting 016_108: 100%|██████████| 6/6 [00:00<00:00, 14.30it/s]\n",
      "Augmenting 016_109: 100%|██████████| 6/6 [00:00<00:00, 13.89it/s]\n",
      "Augmenting 016_110: 100%|██████████| 6/6 [00:00<00:00, 13.12it/s]\n",
      "Augmenting 016_111: 100%|██████████| 6/6 [00:00<00:00, 14.36it/s]\n",
      "Augmenting 016_112: 100%|██████████| 6/6 [00:00<00:00, 13.88it/s]\n",
      "Augmenting 016_113: 100%|██████████| 6/6 [00:00<00:00, 13.20it/s]\n",
      "Augmenting 016_114: 100%|██████████| 6/6 [00:00<00:00, 13.73it/s]\n",
      "Augmenting 016_115: 100%|██████████| 6/6 [00:00<00:00, 13.69it/s]\n",
      "Augmenting 016_116: 100%|██████████| 6/6 [00:00<00:00, 13.30it/s]\n",
      "Augmenting 017_117: 100%|██████████| 6/6 [00:00<00:00, 13.13it/s]\n",
      "Augmenting 017_118: 100%|██████████| 6/6 [00:00<00:00, 14.12it/s]\n",
      "Augmenting 017_119: 100%|██████████| 6/6 [00:00<00:00, 14.31it/s]\n",
      "Augmenting 017_120: 100%|██████████| 6/6 [00:00<00:00, 13.50it/s]\n",
      "Augmenting 017_121: 100%|██████████| 6/6 [00:00<00:00, 13.27it/s]\n",
      "Augmenting 017_122: 100%|██████████| 6/6 [00:00<00:00, 13.49it/s]\n",
      "Augmenting 017_123: 100%|██████████| 6/6 [00:00<00:00, 13.65it/s]\n",
      "Augmenting 017_124: 100%|██████████| 6/6 [00:00<00:00, 13.42it/s]\n",
      "Augmenting 017_125: 100%|██████████| 6/6 [00:00<00:00, 13.71it/s]\n",
      "Augmenting 017_126: 100%|██████████| 6/6 [00:00<00:00, 13.30it/s]\n",
      "Augmenting 018_127: 100%|██████████| 6/6 [00:00<00:00, 14.52it/s]\n",
      "Augmenting 018_128: 100%|██████████| 6/6 [00:00<00:00, 13.62it/s]\n",
      "Augmenting 018_129: 100%|██████████| 6/6 [00:00<00:00, 13.55it/s]\n",
      "Augmenting 018_130: 100%|██████████| 6/6 [00:00<00:00, 13.26it/s]\n",
      "Augmenting 018_131: 100%|██████████| 6/6 [00:00<00:00, 14.34it/s]\n",
      "Augmenting 018_132: 100%|██████████| 6/6 [00:00<00:00, 13.76it/s]\n",
      "Augmenting 018_133: 100%|██████████| 6/6 [00:00<00:00, 14.32it/s]\n",
      "Augmenting 018_134: 100%|██████████| 6/6 [00:00<00:00, 15.51it/s]\n",
      "Augmenting 018_135: 100%|██████████| 6/6 [00:00<00:00, 14.64it/s]\n",
      "Augmenting 018_136: 100%|██████████| 6/6 [00:00<00:00, 13.00it/s]\n",
      "Augmenting 019_137: 100%|██████████| 6/6 [00:00<00:00, 12.11it/s]\n",
      "Augmenting 019_138: 100%|██████████| 6/6 [00:00<00:00, 13.07it/s]\n",
      "Augmenting 019_139: 100%|██████████| 6/6 [00:00<00:00, 13.39it/s]\n",
      "Augmenting 019_140: 100%|██████████| 6/6 [00:00<00:00, 13.34it/s]\n",
      "Augmenting 019_141: 100%|██████████| 6/6 [00:00<00:00, 13.63it/s]\n",
      "Augmenting 019_142: 100%|██████████| 6/6 [00:00<00:00, 13.55it/s]\n",
      "Augmenting 019_143: 100%|██████████| 6/6 [00:00<00:00, 15.28it/s]\n",
      "Augmenting 019_144: 100%|██████████| 6/6 [00:00<00:00, 14.04it/s]\n",
      "Augmenting 019_145: 100%|██████████| 6/6 [00:00<00:00, 14.00it/s]\n",
      "Augmenting 019_146: 100%|██████████| 6/6 [00:00<00:00, 13.84it/s]\n",
      "Augmenting 020_147: 100%|██████████| 6/6 [00:00<00:00, 15.04it/s]\n",
      "Augmenting 020_148: 100%|██████████| 6/6 [00:00<00:00, 13.33it/s]\n",
      "Augmenting 020_149: 100%|██████████| 6/6 [00:00<00:00, 13.65it/s]\n",
      "Augmenting 020_150: 100%|██████████| 6/6 [00:00<00:00, 13.53it/s]\n",
      "Augmenting 020_151: 100%|██████████| 6/6 [00:00<00:00, 14.11it/s]\n",
      "Augmenting 020_152: 100%|██████████| 6/6 [00:00<00:00, 14.13it/s]\n",
      "Augmenting 020_153: 100%|██████████| 6/6 [00:00<00:00, 13.76it/s]\n",
      "Augmenting 020_154: 100%|██████████| 6/6 [00:00<00:00, 15.04it/s]\n",
      "Augmenting 020_155: 100%|██████████| 6/6 [00:00<00:00, 14.58it/s]\n",
      "Augmenting 020_156: 100%|██████████| 6/6 [00:00<00:00, 14.39it/s]\n",
      "Augmenting 021_157: 100%|██████████| 6/6 [00:00<00:00, 14.52it/s]\n",
      "Augmenting 021_158: 100%|██████████| 6/6 [00:00<00:00, 15.86it/s]\n",
      "Augmenting 021_159: 100%|██████████| 6/6 [00:00<00:00, 14.60it/s]\n",
      "Augmenting 021_160: 100%|██████████| 6/6 [00:00<00:00, 15.78it/s]\n",
      "Augmenting 021_161: 100%|██████████| 6/6 [00:00<00:00, 14.35it/s]\n",
      "Augmenting 021_162: 100%|██████████| 6/6 [00:00<00:00, 13.82it/s]\n",
      "Augmenting 021_163: 100%|██████████| 6/6 [00:00<00:00, 15.42it/s]\n",
      "Augmenting 021_164: 100%|██████████| 6/6 [00:00<00:00, 14.39it/s]\n",
      "Augmenting 021_165: 100%|██████████| 6/6 [00:00<00:00, 14.47it/s]\n",
      "Augmenting 021_166: 100%|██████████| 6/6 [00:00<00:00, 15.46it/s]\n",
      "Augmenting 022_167: 100%|██████████| 6/6 [00:00<00:00, 14.64it/s]\n",
      "Augmenting 022_168: 100%|██████████| 6/6 [00:00<00:00, 14.02it/s]\n",
      "Augmenting 022_169: 100%|██████████| 6/6 [00:00<00:00, 14.43it/s]\n",
      "Augmenting 022_170: 100%|██████████| 6/6 [00:00<00:00, 14.03it/s]\n",
      "Augmenting 022_171: 100%|██████████| 6/6 [00:00<00:00, 14.38it/s]\n",
      "Augmenting 022_172: 100%|██████████| 6/6 [00:00<00:00, 14.45it/s]\n",
      "Augmenting 022_173: 100%|██████████| 6/6 [00:00<00:00, 14.48it/s]\n",
      "Augmenting 022_174: 100%|██████████| 6/6 [00:00<00:00, 14.00it/s]\n",
      "Augmenting 022_175: 100%|██████████| 6/6 [00:00<00:00, 14.64it/s]\n",
      "Augmenting 022_176: 100%|██████████| 6/6 [00:00<00:00, 14.75it/s]\n",
      "Augmenting 023_177: 100%|██████████| 6/6 [00:00<00:00, 14.00it/s]\n",
      "Augmenting 023_178: 100%|██████████| 6/6 [00:00<00:00, 13.48it/s]\n",
      "Augmenting 023_179: 100%|██████████| 6/6 [00:00<00:00, 13.70it/s]\n",
      "Augmenting 023_180: 100%|██████████| 6/6 [00:00<00:00, 14.40it/s]\n",
      "Augmenting 023_181: 100%|██████████| 6/6 [00:00<00:00, 13.61it/s]\n",
      "Augmenting 023_182: 100%|██████████| 6/6 [00:00<00:00, 14.05it/s]\n",
      "Augmenting 023_183: 100%|██████████| 6/6 [00:00<00:00, 15.31it/s]\n",
      "Augmenting 023_184: 100%|██████████| 6/6 [00:00<00:00, 13.84it/s]\n",
      "Augmenting 023_185: 100%|██████████| 6/6 [00:00<00:00, 13.62it/s]\n",
      "Augmenting 023_186: 100%|██████████| 6/6 [00:00<00:00, 13.24it/s]\n",
      "Augmenting 024_187: 100%|██████████| 6/6 [00:00<00:00, 13.79it/s]\n",
      "Augmenting 024_188: 100%|██████████| 6/6 [00:00<00:00, 13.52it/s]\n",
      "Augmenting 024_189: 100%|██████████| 6/6 [00:00<00:00, 15.00it/s]\n",
      "Augmenting 024_190: 100%|██████████| 6/6 [00:00<00:00, 13.16it/s]\n",
      "Augmenting 024_191: 100%|██████████| 6/6 [00:00<00:00, 14.20it/s]\n",
      "Augmenting 024_192: 100%|██████████| 6/6 [00:00<00:00, 13.57it/s]\n",
      "Augmenting 024_193: 100%|██████████| 6/6 [00:00<00:00, 13.41it/s]\n",
      "Augmenting 024_194: 100%|██████████| 6/6 [00:00<00:00, 14.24it/s]\n",
      "Augmenting 024_195: 100%|██████████| 6/6 [00:00<00:00, 13.87it/s]\n",
      "Augmenting 024_196: 100%|██████████| 6/6 [00:00<00:00, 13.21it/s]\n",
      "Augmenting 025_197: 100%|██████████| 6/6 [00:00<00:00, 14.69it/s]\n",
      "Augmenting 025_198: 100%|██████████| 6/6 [00:00<00:00, 14.98it/s]\n",
      "Augmenting 025_199: 100%|██████████| 6/6 [00:00<00:00, 15.64it/s]\n",
      "Augmenting 025_200: 100%|██████████| 6/6 [00:00<00:00, 16.21it/s]\n",
      "Augmenting 025_201: 100%|██████████| 6/6 [00:00<00:00, 14.94it/s]\n",
      "Augmenting 025_202: 100%|██████████| 6/6 [00:00<00:00, 15.68it/s]\n",
      "Augmenting 025_203: 100%|██████████| 6/6 [00:00<00:00, 16.42it/s]\n",
      "Augmenting 025_204: 100%|██████████| 6/6 [00:00<00:00, 15.28it/s]\n",
      "Augmenting 025_205: 100%|██████████| 6/6 [00:00<00:00, 15.77it/s]\n",
      "Augmenting 025_206: 100%|██████████| 6/6 [00:00<00:00, 15.90it/s]\n",
      "Augmenting 026_207: 100%|██████████| 6/6 [00:00<00:00, 14.39it/s]\n",
      "Augmenting 026_208: 100%|██████████| 6/6 [00:00<00:00, 14.00it/s]\n",
      "Augmenting 026_209: 100%|██████████| 6/6 [00:00<00:00, 13.84it/s]\n",
      "Augmenting 026_210: 100%|██████████| 6/6 [00:00<00:00, 14.33it/s]\n",
      "Augmenting 026_211: 100%|██████████| 6/6 [00:00<00:00, 13.58it/s]\n",
      "Augmenting 026_212: 100%|██████████| 6/6 [00:00<00:00, 14.28it/s]\n",
      "Augmenting 026_213: 100%|██████████| 6/6 [00:00<00:00, 14.01it/s]\n",
      "Augmenting 026_214: 100%|██████████| 6/6 [00:00<00:00, 14.44it/s]\n",
      "Augmenting 026_215: 100%|██████████| 6/6 [00:00<00:00, 14.00it/s]\n",
      "Augmenting 026_216: 100%|██████████| 6/6 [00:00<00:00, 13.82it/s]\n",
      "Augmenting 027_217: 100%|██████████| 6/6 [00:00<00:00, 15.16it/s]\n",
      "Augmenting 027_218: 100%|██████████| 6/6 [00:00<00:00, 14.94it/s]\n",
      "Augmenting 027_219: 100%|██████████| 6/6 [00:00<00:00, 13.56it/s]\n",
      "Augmenting 027_220: 100%|██████████| 6/6 [00:00<00:00, 14.55it/s]\n",
      "Augmenting 027_221: 100%|██████████| 6/6 [00:00<00:00, 13.74it/s]\n",
      "Augmenting 027_222: 100%|██████████| 6/6 [00:00<00:00, 13.82it/s]\n",
      "Augmenting 027_223: 100%|██████████| 6/6 [00:00<00:00, 14.43it/s]\n",
      "Augmenting 027_224: 100%|██████████| 6/6 [00:00<00:00, 14.09it/s]\n",
      "Augmenting 027_225: 100%|██████████| 6/6 [00:00<00:00, 14.54it/s]\n",
      "Augmenting 027_226: 100%|██████████| 6/6 [00:00<00:00, 13.32it/s]\n",
      "Augmenting 028_227: 100%|██████████| 6/6 [00:00<00:00, 14.60it/s]\n",
      "Augmenting 028_228: 100%|██████████| 6/6 [00:00<00:00, 14.11it/s]\n",
      "Augmenting 028_229: 100%|██████████| 6/6 [00:00<00:00, 13.41it/s]\n",
      "Augmenting 028_230: 100%|██████████| 6/6 [00:00<00:00, 14.09it/s]\n",
      "Augmenting 028_231: 100%|██████████| 6/6 [00:00<00:00, 14.86it/s]\n",
      "Augmenting 028_232: 100%|██████████| 6/6 [00:00<00:00, 15.07it/s]\n",
      "Augmenting 028_233: 100%|██████████| 6/6 [00:00<00:00, 13.52it/s]\n",
      "Augmenting 028_234: 100%|██████████| 6/6 [00:00<00:00, 13.76it/s]\n",
      "Augmenting 028_235: 100%|██████████| 6/6 [00:00<00:00, 14.95it/s]\n",
      "Augmenting 028_236: 100%|██████████| 6/6 [00:00<00:00, 14.51it/s]\n",
      "Augmenting 029_237: 100%|██████████| 6/6 [00:00<00:00, 14.43it/s]\n",
      "Augmenting 029_238: 100%|██████████| 6/6 [00:00<00:00, 13.72it/s]\n",
      "Augmenting 029_239: 100%|██████████| 6/6 [00:00<00:00, 13.27it/s]\n",
      "Augmenting 029_240: 100%|██████████| 6/6 [00:00<00:00, 13.27it/s]\n",
      "Augmenting 029_241: 100%|██████████| 6/6 [00:00<00:00, 13.72it/s]\n",
      "Augmenting 029_242: 100%|██████████| 6/6 [00:00<00:00, 15.25it/s]\n",
      "Augmenting 029_243: 100%|██████████| 6/6 [00:00<00:00, 14.66it/s]\n",
      "Augmenting 029_244: 100%|██████████| 6/6 [00:00<00:00, 14.25it/s]\n",
      "Augmenting 030_245: 100%|██████████| 6/6 [00:00<00:00, 13.56it/s]\n",
      "Augmenting 030_246: 100%|██████████| 6/6 [00:00<00:00, 14.15it/s]\n",
      "Augmenting 030_247: 100%|██████████| 6/6 [00:00<00:00, 13.70it/s]\n",
      "Augmenting 030_248: 100%|██████████| 6/6 [00:00<00:00, 13.47it/s]\n",
      "Augmenting 030_249: 100%|██████████| 6/6 [00:00<00:00, 13.80it/s]\n",
      "Augmenting 030_250: 100%|██████████| 6/6 [00:00<00:00, 13.88it/s]\n",
      "Augmenting 030_251: 100%|██████████| 6/6 [00:00<00:00, 12.77it/s]\n",
      "Augmenting 030_252: 100%|██████████| 6/6 [00:00<00:00, 14.22it/s]\n",
      "Augmenting 031_253: 100%|██████████| 6/6 [00:00<00:00, 14.22it/s]\n",
      "Augmenting 031_254: 100%|██████████| 6/6 [00:00<00:00, 13.72it/s]\n",
      "Augmenting 031_255: 100%|██████████| 6/6 [00:00<00:00, 14.27it/s]\n",
      "Augmenting 031_256: 100%|██████████| 6/6 [00:00<00:00, 14.16it/s]\n",
      "Augmenting 031_257: 100%|██████████| 6/6 [00:00<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Applying combined damage to 20% of training images per class...\n",
      "Class 001_1: 29 clean + 7 damaged\n",
      "Class 001_2: 29 clean + 7 damaged\n",
      "Class 001_3: 29 clean + 7 damaged\n",
      "Class 001_4: 29 clean + 7 damaged\n",
      "Class 001_5: 29 clean + 7 damaged\n",
      "Class 001_6: 29 clean + 7 damaged\n",
      "Class 002_10: 29 clean + 7 damaged\n",
      "Class 002_11: 29 clean + 7 damaged\n",
      "Class 002_12: 29 clean + 7 damaged\n",
      "Class 002_7: 29 clean + 7 damaged\n",
      "Class 002_8: 29 clean + 7 damaged\n",
      "Class 002_9: 29 clean + 7 damaged\n",
      "Class 003_13: 29 clean + 7 damaged\n",
      "Class 003_14: 29 clean + 7 damaged\n",
      "Class 003_15: 29 clean + 7 damaged\n",
      "Class 003_16: 29 clean + 7 damaged\n",
      "Class 003_17: 29 clean + 7 damaged\n",
      "Class 003_18: 29 clean + 7 damaged\n",
      "Class 004_19: 29 clean + 7 damaged\n",
      "Class 004_20: 29 clean + 7 damaged\n",
      "Class 004_21: 29 clean + 7 damaged\n",
      "Class 004_22: 29 clean + 7 damaged\n",
      "Class 004_23: 29 clean + 7 damaged\n",
      "Class 004_24: 29 clean + 7 damaged\n",
      "Class 005_25: 29 clean + 7 damaged\n",
      "Class 005_26: 29 clean + 7 damaged\n",
      "Class 005_27: 29 clean + 7 damaged\n",
      "Class 005_28: 29 clean + 7 damaged\n",
      "Class 005_29: 29 clean + 7 damaged\n",
      "Class 005_30: 29 clean + 7 damaged\n",
      "Class 006_31: 29 clean + 7 damaged\n",
      "Class 006_32: 29 clean + 7 damaged\n",
      "Class 006_33: 29 clean + 7 damaged\n",
      "Class 006_34: 29 clean + 7 damaged\n",
      "Class 006_35: 29 clean + 7 damaged\n",
      "Class 006_36: 29 clean + 7 damaged\n",
      "Class 007_37: 29 clean + 7 damaged\n",
      "Class 007_38: 29 clean + 7 damaged\n",
      "Class 007_39: 29 clean + 7 damaged\n",
      "Class 007_40: 29 clean + 7 damaged\n",
      "Class 007_41: 29 clean + 7 damaged\n",
      "Class 007_42: 29 clean + 7 damaged\n",
      "Class 008_43: 29 clean + 7 damaged\n",
      "Class 008_44: 29 clean + 7 damaged\n",
      "Class 008_45: 29 clean + 7 damaged\n",
      "Class 009_46: 29 clean + 7 damaged\n",
      "Class 009_47: 29 clean + 7 damaged\n",
      "Class 009_48: 29 clean + 7 damaged\n",
      "Class 009_49: 29 clean + 7 damaged\n",
      "Class 009_50: 29 clean + 7 damaged\n",
      "Class 009_51: 29 clean + 7 damaged\n",
      "Class 010_52: 29 clean + 7 damaged\n",
      "Class 010_53: 29 clean + 7 damaged\n",
      "Class 010_54: 29 clean + 7 damaged\n",
      "Class 010_55: 29 clean + 7 damaged\n",
      "Class 010_56: 29 clean + 7 damaged\n",
      "Class 010_57: 29 clean + 7 damaged\n",
      "Class 010_58: 29 clean + 7 damaged\n",
      "Class 010_59: 29 clean + 7 damaged\n",
      "Class 010_60: 29 clean + 7 damaged\n",
      "Class 010_61: 29 clean + 7 damaged\n",
      "Class 011_62: 29 clean + 7 damaged\n",
      "Class 011_63: 29 clean + 7 damaged\n",
      "Class 011_64: 29 clean + 7 damaged\n",
      "Class 011_65: 29 clean + 7 damaged\n",
      "Class 011_66: 29 clean + 7 damaged\n",
      "Class 011_67: 29 clean + 7 damaged\n",
      "Class 011_68: 29 clean + 7 damaged\n",
      "Class 011_69: 29 clean + 7 damaged\n",
      "Class 011_70: 29 clean + 7 damaged\n",
      "Class 011_71: 29 clean + 7 damaged\n",
      "Class 012_72: 29 clean + 7 damaged\n",
      "Class 012_73: 29 clean + 7 damaged\n",
      "Class 012_74: 29 clean + 7 damaged\n",
      "Class 012_75: 29 clean + 7 damaged\n",
      "Class 012_76: 29 clean + 7 damaged\n",
      "Class 012_77: 29 clean + 7 damaged\n",
      "Class 012_78: 29 clean + 7 damaged\n",
      "Class 012_79: 29 clean + 7 damaged\n",
      "Class 012_80: 29 clean + 7 damaged\n",
      "Class 012_81: 29 clean + 7 damaged\n",
      "Class 013_82: 29 clean + 7 damaged\n",
      "Class 013_83: 29 clean + 7 damaged\n",
      "Class 013_84: 29 clean + 7 damaged\n",
      "Class 013_85: 29 clean + 7 damaged\n",
      "Class 013_86: 29 clean + 7 damaged\n",
      "Class 013_87: 29 clean + 7 damaged\n",
      "Class 013_88: 29 clean + 7 damaged\n",
      "Class 013_89: 29 clean + 7 damaged\n",
      "Class 013_90: 29 clean + 7 damaged\n",
      "Class 013_91: 29 clean + 7 damaged\n",
      "Class 014_100: 29 clean + 7 damaged\n",
      "Class 014_101: 29 clean + 7 damaged\n",
      "Class 014_92: 29 clean + 7 damaged\n",
      "Class 014_93: 29 clean + 7 damaged\n",
      "Class 014_94: 29 clean + 7 damaged\n",
      "Class 014_95: 29 clean + 7 damaged\n",
      "Class 014_96: 29 clean + 7 damaged\n",
      "Class 014_97: 29 clean + 7 damaged\n",
      "Class 014_98: 29 clean + 7 damaged\n",
      "Class 014_99: 29 clean + 7 damaged\n",
      "Class 015_102: 29 clean + 7 damaged\n",
      "Class 015_103: 29 clean + 7 damaged\n",
      "Class 015_104: 29 clean + 7 damaged\n",
      "Class 015_105: 29 clean + 7 damaged\n",
      "Class 015_106: 29 clean + 7 damaged\n",
      "Class 016_107: 29 clean + 7 damaged\n",
      "Class 016_108: 29 clean + 7 damaged\n",
      "Class 016_109: 29 clean + 7 damaged\n",
      "Class 016_110: 29 clean + 7 damaged\n",
      "Class 016_111: 29 clean + 7 damaged\n",
      "Class 016_112: 29 clean + 7 damaged\n",
      "Class 016_113: 29 clean + 7 damaged\n",
      "Class 016_114: 29 clean + 7 damaged\n",
      "Class 016_115: 29 clean + 7 damaged\n",
      "Class 016_116: 29 clean + 7 damaged\n",
      "Class 017_117: 29 clean + 7 damaged\n",
      "Class 017_118: 29 clean + 7 damaged\n",
      "Class 017_119: 29 clean + 7 damaged\n",
      "Class 017_120: 29 clean + 7 damaged\n",
      "Class 017_121: 29 clean + 7 damaged\n",
      "Class 017_122: 29 clean + 7 damaged\n",
      "Class 017_123: 29 clean + 7 damaged\n",
      "Class 017_124: 29 clean + 7 damaged\n",
      "Class 017_125: 29 clean + 7 damaged\n",
      "Class 017_126: 29 clean + 7 damaged\n",
      "Class 018_127: 29 clean + 7 damaged\n",
      "Class 018_128: 29 clean + 7 damaged\n",
      "Class 018_129: 29 clean + 7 damaged\n",
      "Class 018_130: 29 clean + 7 damaged\n",
      "Class 018_131: 29 clean + 7 damaged\n",
      "Class 018_132: 29 clean + 7 damaged\n",
      "Class 018_133: 29 clean + 7 damaged\n",
      "Class 018_134: 29 clean + 7 damaged\n",
      "Class 018_135: 29 clean + 7 damaged\n",
      "Class 018_136: 29 clean + 7 damaged\n",
      "Class 019_137: 29 clean + 7 damaged\n",
      "Class 019_138: 29 clean + 7 damaged\n",
      "Class 019_139: 29 clean + 7 damaged\n",
      "Class 019_140: 29 clean + 7 damaged\n",
      "Class 019_141: 29 clean + 7 damaged\n",
      "Class 019_142: 29 clean + 7 damaged\n",
      "Class 019_143: 29 clean + 7 damaged\n",
      "Class 019_144: 29 clean + 7 damaged\n",
      "Class 019_145: 29 clean + 7 damaged\n",
      "Class 019_146: 29 clean + 7 damaged\n",
      "Class 020_147: 29 clean + 7 damaged\n",
      "Class 020_148: 29 clean + 7 damaged\n",
      "Class 020_149: 29 clean + 7 damaged\n",
      "Class 020_150: 29 clean + 7 damaged\n",
      "Class 020_151: 29 clean + 7 damaged\n",
      "Class 020_152: 29 clean + 7 damaged\n",
      "Class 020_153: 29 clean + 7 damaged\n",
      "Class 020_154: 29 clean + 7 damaged\n",
      "Class 020_155: 29 clean + 7 damaged\n",
      "Class 020_156: 29 clean + 7 damaged\n",
      "Class 021_157: 29 clean + 7 damaged\n",
      "Class 021_158: 29 clean + 7 damaged\n",
      "Class 021_159: 29 clean + 7 damaged\n",
      "Class 021_160: 29 clean + 7 damaged\n",
      "Class 021_161: 29 clean + 7 damaged\n",
      "Class 021_162: 29 clean + 7 damaged\n",
      "Class 021_163: 29 clean + 7 damaged\n",
      "Class 021_164: 29 clean + 7 damaged\n",
      "Class 021_165: 29 clean + 7 damaged\n",
      "Class 021_166: 29 clean + 7 damaged\n",
      "Class 022_167: 29 clean + 7 damaged\n",
      "Class 022_168: 29 clean + 7 damaged\n",
      "Class 022_169: 29 clean + 7 damaged\n",
      "Class 022_170: 29 clean + 7 damaged\n",
      "Class 022_171: 29 clean + 7 damaged\n",
      "Class 022_172: 29 clean + 7 damaged\n",
      "Class 022_173: 29 clean + 7 damaged\n",
      "Class 022_174: 29 clean + 7 damaged\n",
      "Class 022_175: 29 clean + 7 damaged\n",
      "Class 022_176: 29 clean + 7 damaged\n",
      "Class 023_177: 29 clean + 7 damaged\n",
      "Class 023_178: 29 clean + 7 damaged\n",
      "Class 023_179: 29 clean + 7 damaged\n",
      "Class 023_180: 29 clean + 7 damaged\n",
      "Class 023_181: 29 clean + 7 damaged\n",
      "Class 023_182: 29 clean + 7 damaged\n",
      "Class 023_183: 29 clean + 7 damaged\n",
      "Class 023_184: 29 clean + 7 damaged\n",
      "Class 023_185: 29 clean + 7 damaged\n",
      "Class 023_186: 29 clean + 7 damaged\n",
      "Class 024_187: 29 clean + 7 damaged\n",
      "Class 024_188: 29 clean + 7 damaged\n",
      "Class 024_189: 29 clean + 7 damaged\n",
      "Class 024_190: 29 clean + 7 damaged\n",
      "Class 024_191: 29 clean + 7 damaged\n",
      "Class 024_192: 29 clean + 7 damaged\n",
      "Class 024_193: 29 clean + 7 damaged\n",
      "Class 024_194: 29 clean + 7 damaged\n",
      "Class 024_195: 29 clean + 7 damaged\n",
      "Class 024_196: 29 clean + 7 damaged\n",
      "Class 025_197: 29 clean + 7 damaged\n",
      "Class 025_198: 29 clean + 7 damaged\n",
      "Class 025_199: 29 clean + 7 damaged\n",
      "Class 025_200: 29 clean + 7 damaged\n",
      "Class 025_201: 29 clean + 7 damaged\n",
      "Class 025_202: 29 clean + 7 damaged\n",
      "Class 025_203: 29 clean + 7 damaged\n",
      "Class 025_204: 29 clean + 7 damaged\n",
      "Class 025_205: 29 clean + 7 damaged\n",
      "Class 025_206: 29 clean + 7 damaged\n",
      "Class 026_207: 29 clean + 7 damaged\n",
      "Class 026_208: 29 clean + 7 damaged\n",
      "Class 026_209: 29 clean + 7 damaged\n",
      "Class 026_210: 29 clean + 7 damaged\n",
      "Class 026_211: 29 clean + 7 damaged\n",
      "Class 026_212: 29 clean + 7 damaged\n",
      "Class 026_213: 29 clean + 7 damaged\n",
      "Class 026_214: 29 clean + 7 damaged\n",
      "Class 026_215: 29 clean + 7 damaged\n",
      "Class 026_216: 29 clean + 7 damaged\n",
      "Class 027_217: 29 clean + 7 damaged\n",
      "Class 027_218: 29 clean + 7 damaged\n",
      "Class 027_219: 29 clean + 7 damaged\n",
      "Class 027_220: 29 clean + 7 damaged\n",
      "Class 027_221: 29 clean + 7 damaged\n",
      "Class 027_222: 29 clean + 7 damaged\n",
      "Class 027_223: 29 clean + 7 damaged\n",
      "Class 027_224: 29 clean + 7 damaged\n",
      "Class 027_225: 29 clean + 7 damaged\n",
      "Class 027_226: 29 clean + 7 damaged\n",
      "Class 028_227: 29 clean + 7 damaged\n",
      "Class 028_228: 29 clean + 7 damaged\n",
      "Class 028_229: 29 clean + 7 damaged\n",
      "Class 028_230: 29 clean + 7 damaged\n",
      "Class 028_231: 29 clean + 7 damaged\n",
      "Class 028_232: 29 clean + 7 damaged\n",
      "Class 028_233: 29 clean + 7 damaged\n",
      "Class 028_234: 29 clean + 7 damaged\n",
      "Class 028_235: 29 clean + 7 damaged\n",
      "Class 028_236: 29 clean + 7 damaged\n",
      "Class 029_237: 29 clean + 7 damaged\n",
      "Class 029_238: 29 clean + 7 damaged\n",
      "Class 029_239: 29 clean + 7 damaged\n",
      "Class 029_240: 29 clean + 7 damaged\n",
      "Class 029_241: 29 clean + 7 damaged\n",
      "Class 029_242: 29 clean + 7 damaged\n",
      "Class 029_243: 29 clean + 7 damaged\n",
      "Class 029_244: 29 clean + 7 damaged\n",
      "Class 030_245: 29 clean + 7 damaged\n",
      "Class 030_246: 29 clean + 7 damaged\n",
      "Class 030_247: 29 clean + 7 damaged\n",
      "Class 030_248: 29 clean + 7 damaged\n",
      "Class 030_249: 29 clean + 7 damaged\n",
      "Class 030_250: 29 clean + 7 damaged\n",
      "Class 030_251: 29 clean + 7 damaged\n",
      "Class 030_252: 29 clean + 7 damaged\n",
      "Class 031_253: 29 clean + 7 damaged\n",
      "Class 031_254: 29 clean + 7 damaged\n",
      "Class 031_255: 29 clean + 7 damaged\n",
      "Class 031_256: 29 clean + 7 damaged\n",
      "Class 031_257: 29 clean + 7 damaged\n",
      "\n",
      "Final training set: 9252 total — 7453 clean + 1799 damaged\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "RAW_DIR = \"../data/raw\"\n",
    "OUTPUT_DIR = \"../data/processed/\"\n",
    "IMAGE_SIZE = (224, 224)  # For EfficientNetB0\n",
    "\n",
    "def extract_class_id(filename):\n",
    "    \"\"\"Extract class like '001_1' from '001_1_1.tif'\"\"\"\n",
    "    return \"_\".join(filename.split(\"_\")[:2])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Read grayscale, enhance contrast, denoise, resize, convert to RGB\"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "    # 1. CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(img)\n",
    "\n",
    "    # 2. Bilateral Filter\n",
    "    denoised = cv2.bilateralFilter(enhanced, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    # 3. Resize\n",
    "    resized = cv2.resize(denoised, IMAGE_SIZE, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    # 4. Convert to 3-channel RGB\n",
    "    rgb = cv2.cvtColor(resized, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    return Image.fromarray(rgb)\n",
    "\n",
    "\n",
    "def prepare_dataset():\n",
    "    all_files = [f for f in os.listdir(RAW_DIR) if f.endswith(\".tif\")]\n",
    "    class_map = {}\n",
    "\n",
    "    for file in all_files:\n",
    "        class_id = extract_class_id(file)\n",
    "        class_map.setdefault(class_id, []).append(file)\n",
    "\n",
    "    for class_id, files in tqdm(class_map.items(), desc=\"Processing classes\"):\n",
    "        # Sort files by index (ZZZ)\n",
    "        files.sort(key=lambda f: int(f.split(\"_\")[2].split(\".\")[0]))\n",
    "\n",
    "        train_files = files[:6]  # first 6 for train\n",
    "        test_files = files[6:]   # last 2 for test\n",
    "\n",
    "        for split, split_files in [(\"train\", train_files), (\"test\", test_files)]:\n",
    "            out_dir = os.path.join(OUTPUT_DIR, split, class_id)\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "            for file in split_files:\n",
    "                img_path = os.path.join(RAW_DIR, file)\n",
    "                processed_img = preprocess_image(img_path)\n",
    "                processed_img.save(os.path.join(out_dir, file.replace(\".tif\", \".png\")))\n",
    "\n",
    "def add_custom_noise(img_array):\n",
    "    noise = np.random.normal(loc=0, scale=10, size=img_array.shape)\n",
    "    noisy_img = img_array + noise\n",
    "    return np.clip(noisy_img, 0, 255)\n",
    "\n",
    "def add_motion_blur(img_array, degree=5, angle=0):\n",
    "    image = img_array.copy()\n",
    "    k = np.zeros((degree, degree))\n",
    "    k[int((degree - 1) / 2), :] = np.ones(degree)\n",
    "    M = cv2.getRotationMatrix2D((degree / 2 - 0.5, degree / 2 - 0.5), angle, 1)\n",
    "    k = cv2.warpAffine(k, M, (degree, degree))\n",
    "    k = k / np.sum(k)\n",
    "    blurred = cv2.filter2D(image, -1, k)\n",
    "    return blurred\n",
    "\n",
    "def damage_all_test_images(test_dir):\n",
    "    print(\"\\nDamaging ALL test images...\")\n",
    "    total_images = 0\n",
    "\n",
    "    for class_id in os.listdir(test_dir):\n",
    "        class_path = os.path.join(test_dir, class_id)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif'))]\n",
    "\n",
    "        for fname in tqdm(images, desc=f\"Damaging {class_id}\"):\n",
    "            img_path = os.path.join(class_path, fname)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "            if img is not None:\n",
    "                damaged = apply_combined_damage(img)\n",
    "                cv2.imwrite(img_path, damaged)\n",
    "                total_images += 1\n",
    "\n",
    "    print(f\"\\nTotal test images damaged: {total_images}\")\n",
    "\n",
    "\n",
    "def augment_and_save_images_in_place(input_dir, augmentations_per_image=5):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=5,\n",
    "        zoom_range=0.05,\n",
    "        brightness_range=(0.9, 1.1),\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for fname in tqdm(os.listdir(class_path), desc=f\"Augmenting {class_name}\"):\n",
    "            if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                continue\n",
    "\n",
    "            fpath = os.path.join(class_path, fname)\n",
    "            img = load_img(fpath, color_mode='rgb')\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "\n",
    "            prefix = os.path.splitext(fname)[0]\n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, batch_size=1):\n",
    "                aug_img_array = batch[0]\n",
    "\n",
    "                if np.random.rand() < 0.5:\n",
    "                    aug_img_array = add_custom_noise(aug_img_array)\n",
    "\n",
    "                if np.random.rand() < 0.3:\n",
    "                    degree = np.random.randint(3, 7)\n",
    "                    angle = np.random.uniform(-20, 20)\n",
    "                    aug_img_array = add_motion_blur(aug_img_array, degree=degree, angle=angle)\n",
    "\n",
    "                aug_img_array = np.clip(aug_img_array, 0, 255).astype('uint8')\n",
    "\n",
    "                if aug_img_array.ndim == 2:\n",
    "                    aug_img_array = np.expand_dims(aug_img_array, axis=-1)\n",
    "\n",
    "                aug_img = array_to_img(aug_img_array)\n",
    "                aug_img.save(os.path.join(class_path, f\"{prefix}_aug{i+1}.png\"))\n",
    "                i += 1\n",
    "                if i >= augmentations_per_image:\n",
    "                    break\n",
    "\n",
    "def apply_light_block_damage(image, block_size=40, num_blocks=4):\n",
    "    damaged = np.copy(image)\n",
    "    h, w, _ = damaged.shape\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    mask = gray < 250\n",
    "\n",
    "    ys, xs = np.where(mask)\n",
    "\n",
    "    if len(xs) == 0:\n",
    "        return damaged\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        idx = random.randint(0, len(xs) - 1)\n",
    "        x_center, y_center = xs[idx], ys[idx]\n",
    "        x1 = max(0, x_center - block_size // 2)\n",
    "        y1 = max(0, y_center - block_size // 2)\n",
    "        x2 = min(w, x1 + block_size)\n",
    "        y2 = min(h, y1 + block_size)\n",
    "        damaged[y1:y2, x1:x2] = 255\n",
    "    return damaged\n",
    "\n",
    "def apply_blur_damage(image, block_size=30, num_blocks=4):\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        x = random.randint(0, width - block_size)\n",
    "        y = random.randint(0, height - block_size)\n",
    "        roi = damaged[y:y+block_size, x:x+block_size]\n",
    "        blurred = cv2.GaussianBlur(roi, (11, 11), 0)\n",
    "        damaged[y:y+block_size, x:x+block_size] = blurred\n",
    "    return damaged\n",
    "\n",
    "def apply_elliptical_noise(image, num_ellipses=3):\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    for _ in range(num_ellipses):\n",
    "        center = (\n",
    "            random.randint(0, width),\n",
    "            random.randint(0, height)\n",
    "        )\n",
    "        axes = (\n",
    "            random.randint(20, 60), \n",
    "            random.randint(10, 30)   \n",
    "        )\n",
    "        angle = random.randint(0, 180)\n",
    "        startAngle = 0\n",
    "        endAngle = 360\n",
    "        color = (255, 255, 255)\n",
    "        thickness = -1 \n",
    "\n",
    "        cv2.ellipse(damaged, center, axes, angle, startAngle, endAngle, color, thickness)\n",
    "    return damaged\n",
    "\n",
    "def apply_combined_damage(image):\n",
    "    image = apply_light_block_damage(image)\n",
    "    image = apply_blur_damage(image)\n",
    "    image = apply_elliptical_noise(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def damage_percent_of_training_images(train_dir):\n",
    "    total_clean = 0\n",
    "    total_damaged = 0\n",
    "\n",
    "    print(\"\\n Applying combined damage to 20% of training images per class...\")\n",
    "\n",
    "    for class_id in os.listdir(train_dir):\n",
    "        class_path = os.path.join(train_dir, class_id)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif'))]\n",
    "        num_images = len(images)\n",
    "        num_to_damage = int(num_images * 0.2)\n",
    "\n",
    "        selected = random.sample(images, num_to_damage)\n",
    "\n",
    "        for fname in selected:\n",
    "            img_path = os.path.join(class_path, fname)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "            if img is not None:\n",
    "                damaged = apply_combined_damage(img)\n",
    "                cv2.imwrite(img_path, damaged)\n",
    "\n",
    "        total_clean += (num_images - num_to_damage)\n",
    "        total_damaged += num_to_damage\n",
    "        print(f\"Class {class_id}: {num_images - num_to_damage} clean + {num_to_damage} damaged\")\n",
    "\n",
    "    print(f\"\\nFinal training set: {total_clean + total_damaged} total — {total_clean} clean + {total_damaged} damaged\")\n",
    "\n",
    "# Run this cell step by step\n",
    "\n",
    "print(\"Preprocessing and splitting dataset...\")\n",
    "prepare_dataset()\n",
    "\n",
    "print(\"Starting augmentation on training data...\")\n",
    "augment_and_save_images_in_place(os.path.join(OUTPUT_DIR, \"train\"), augmentations_per_image=5)\n",
    "\n",
    "damage_percent_of_training_images(\"../data/processed/train/\")\n",
    "\n",
    "# damage_all_test_images(os.path.join(OUTPUT_DIR, \"test\"))\n",
    "\n",
    "print(\"All done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396b1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d9f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/processed/train\"\n",
    "test_dir = \"../data/processed/test\"\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = len(os.listdir(train_dir))  # number of folders = number of classes\n",
    "EPOCHS = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97583cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9252 images belonging to 257 classes.\n",
      "Found 514 images belonging to 257 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse'  # assuming you're using sparse categorical crossentropy\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad25c992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "579/579 [==============================] - 88s 135ms/step - loss: 7.7011 - accuracy: 0.0053 - val_loss: 7.6169 - val_accuracy: 0.0097 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 7.6134 - accuracy: 0.0112 - val_loss: 7.5047 - val_accuracy: 0.0428 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 7.5218 - accuracy: 0.0203 - val_loss: 7.3509 - val_accuracy: 0.0895 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "579/579 [==============================] - 74s 128ms/step - loss: 7.3779 - accuracy: 0.0357 - val_loss: 7.0974 - val_accuracy: 0.1148 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 7.1903 - accuracy: 0.0499 - val_loss: 6.7687 - val_accuracy: 0.1304 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 6.9836 - accuracy: 0.0678 - val_loss: 6.4222 - val_accuracy: 0.1595 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 6.7417 - accuracy: 0.0851 - val_loss: 6.0848 - val_accuracy: 0.2062 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 6.5147 - accuracy: 0.1047 - val_loss: 5.7470 - val_accuracy: 0.2510 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 6.3036 - accuracy: 0.1300 - val_loss: 5.4680 - val_accuracy: 0.2802 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "579/579 [==============================] - 72s 123ms/step - loss: 6.0766 - accuracy: 0.1513 - val_loss: 5.2034 - val_accuracy: 0.3424 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 5.8766 - accuracy: 0.1749 - val_loss: 4.9663 - val_accuracy: 0.3658 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 5.6657 - accuracy: 0.2004 - val_loss: 4.7332 - val_accuracy: 0.4339 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 5.4604 - accuracy: 0.2257 - val_loss: 4.5063 - val_accuracy: 0.4708 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "579/579 [==============================] - 74s 127ms/step - loss: 5.2694 - accuracy: 0.2543 - val_loss: 4.3134 - val_accuracy: 0.5078 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 5.0860 - accuracy: 0.2750 - val_loss: 4.1208 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 4.9227 - accuracy: 0.3014 - val_loss: 3.9768 - val_accuracy: 0.5447 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 4.7504 - accuracy: 0.3288 - val_loss: 3.8253 - val_accuracy: 0.5875 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "579/579 [==============================] - 71s 123ms/step - loss: 4.6496 - accuracy: 0.3449 - val_loss: 3.7131 - val_accuracy: 0.6109 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "579/579 [==============================] - 72s 123ms/step - loss: 4.5260 - accuracy: 0.3608 - val_loss: 3.6219 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "579/579 [==============================] - 71s 123ms/step - loss: 4.3992 - accuracy: 0.3841 - val_loss: 3.5312 - val_accuracy: 0.6265 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 4.3054 - accuracy: 0.3970 - val_loss: 3.4408 - val_accuracy: 0.6498 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 4.2106 - accuracy: 0.4188 - val_loss: 3.3629 - val_accuracy: 0.6537 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 4.1097 - accuracy: 0.4389 - val_loss: 3.2924 - val_accuracy: 0.6654 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 4.0335 - accuracy: 0.4497 - val_loss: 3.2419 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 3.9695 - accuracy: 0.4678 - val_loss: 3.1837 - val_accuracy: 0.6848 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "579/579 [==============================] - 71s 123ms/step - loss: 3.8822 - accuracy: 0.4840 - val_loss: 3.1370 - val_accuracy: 0.6829 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 3.8038 - accuracy: 0.5015 - val_loss: 3.0942 - val_accuracy: 0.6926 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 3.7106 - accuracy: 0.5211 - val_loss: 3.0460 - val_accuracy: 0.7121 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "579/579 [==============================] - 75s 129ms/step - loss: 3.6434 - accuracy: 0.5364 - val_loss: 3.0054 - val_accuracy: 0.7160 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 3.6179 - accuracy: 0.5429 - val_loss: 2.9700 - val_accuracy: 0.7237 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 3.5194 - accuracy: 0.5589 - val_loss: 2.9393 - val_accuracy: 0.7335 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 3.4923 - accuracy: 0.5651 - val_loss: 2.8944 - val_accuracy: 0.7374 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 3.4130 - accuracy: 0.5812 - val_loss: 2.8697 - val_accuracy: 0.7432 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 3.3960 - accuracy: 0.5860 - val_loss: 2.8462 - val_accuracy: 0.7471 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 3.3460 - accuracy: 0.5952 - val_loss: 2.8118 - val_accuracy: 0.7471 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 3.2929 - accuracy: 0.6067 - val_loss: 2.7903 - val_accuracy: 0.7685 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 3.2448 - accuracy: 0.6125 - val_loss: 2.7633 - val_accuracy: 0.7782 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 3.2045 - accuracy: 0.6260 - val_loss: 2.7472 - val_accuracy: 0.7724 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "579/579 [==============================] - 73s 125ms/step - loss: 3.1624 - accuracy: 0.6373 - val_loss: 2.7185 - val_accuracy: 0.7802 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 3.1172 - accuracy: 0.6499 - val_loss: 2.6993 - val_accuracy: 0.7840 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "579/579 [==============================] - 74s 127ms/step - loss: 3.0847 - accuracy: 0.6556 - val_loss: 2.6823 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 3.0581 - accuracy: 0.6662 - val_loss: 2.6560 - val_accuracy: 0.7918 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 3.0109 - accuracy: 0.6717 - val_loss: 2.6334 - val_accuracy: 0.7899 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.9889 - accuracy: 0.6735 - val_loss: 2.6141 - val_accuracy: 0.7899 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.9545 - accuracy: 0.6890 - val_loss: 2.6037 - val_accuracy: 0.7918 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.9090 - accuracy: 0.6960 - val_loss: 2.5846 - val_accuracy: 0.7918 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.8762 - accuracy: 0.6943 - val_loss: 2.5690 - val_accuracy: 0.7918 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.8487 - accuracy: 0.7094 - val_loss: 2.5474 - val_accuracy: 0.7977 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "579/579 [==============================] - 74s 127ms/step - loss: 2.8304 - accuracy: 0.7090 - val_loss: 2.5356 - val_accuracy: 0.7977 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "579/579 [==============================] - 73s 125ms/step - loss: 2.7943 - accuracy: 0.7180 - val_loss: 2.5301 - val_accuracy: 0.7938 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.7692 - accuracy: 0.7217 - val_loss: 2.5112 - val_accuracy: 0.8054 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.7368 - accuracy: 0.7297 - val_loss: 2.4899 - val_accuracy: 0.8035 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.7022 - accuracy: 0.7402 - val_loss: 2.4814 - val_accuracy: 0.8093 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.6827 - accuracy: 0.7385 - val_loss: 2.4591 - val_accuracy: 0.8113 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 2.6689 - accuracy: 0.7454 - val_loss: 2.4415 - val_accuracy: 0.8171 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.6481 - accuracy: 0.7434 - val_loss: 2.4338 - val_accuracy: 0.8132 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.6157 - accuracy: 0.7557 - val_loss: 2.4232 - val_accuracy: 0.8152 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.5825 - accuracy: 0.7591 - val_loss: 2.4106 - val_accuracy: 0.8152 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.5696 - accuracy: 0.7617 - val_loss: 2.3965 - val_accuracy: 0.8171 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "579/579 [==============================] - 72s 123ms/step - loss: 2.5307 - accuracy: 0.7746 - val_loss: 2.3816 - val_accuracy: 0.8171 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.5132 - accuracy: 0.7737 - val_loss: 2.3732 - val_accuracy: 0.8132 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.4932 - accuracy: 0.7807 - val_loss: 2.3608 - val_accuracy: 0.8249 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.4775 - accuracy: 0.7836 - val_loss: 2.3563 - val_accuracy: 0.8171 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.4445 - accuracy: 0.7899 - val_loss: 2.3401 - val_accuracy: 0.8210 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.4532 - accuracy: 0.7855 - val_loss: 2.3256 - val_accuracy: 0.8210 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.4316 - accuracy: 0.7893 - val_loss: 2.3163 - val_accuracy: 0.8210 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.3995 - accuracy: 0.7982 - val_loss: 2.3062 - val_accuracy: 0.8230 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.3907 - accuracy: 0.7987 - val_loss: 2.2834 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.3648 - accuracy: 0.8046 - val_loss: 2.2773 - val_accuracy: 0.8210 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.3583 - accuracy: 0.8052 - val_loss: 2.2730 - val_accuracy: 0.8307 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 2.3209 - accuracy: 0.8130 - val_loss: 2.2750 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "579/579 [==============================] - 71s 123ms/step - loss: 2.3089 - accuracy: 0.8130 - val_loss: 2.2459 - val_accuracy: 0.8288 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.2976 - accuracy: 0.8131 - val_loss: 2.2382 - val_accuracy: 0.8249 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.2691 - accuracy: 0.8218 - val_loss: 2.2203 - val_accuracy: 0.8327 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.2473 - accuracy: 0.8225 - val_loss: 2.2178 - val_accuracy: 0.8268 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "579/579 [==============================] - 71s 123ms/step - loss: 2.2325 - accuracy: 0.8271 - val_loss: 2.1983 - val_accuracy: 0.8366 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.2362 - accuracy: 0.8235 - val_loss: 2.1853 - val_accuracy: 0.8385 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.2070 - accuracy: 0.8298 - val_loss: 2.1823 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "579/579 [==============================] - 74s 127ms/step - loss: 2.1917 - accuracy: 0.8379 - val_loss: 2.1789 - val_accuracy: 0.8366 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "579/579 [==============================] - 73s 125ms/step - loss: 2.1719 - accuracy: 0.8352 - val_loss: 2.1606 - val_accuracy: 0.8424 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 2.1636 - accuracy: 0.8366 - val_loss: 2.1513 - val_accuracy: 0.8346 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "579/579 [==============================] - 73s 127ms/step - loss: 2.1453 - accuracy: 0.8424 - val_loss: 2.1447 - val_accuracy: 0.8385 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "579/579 [==============================] - 74s 128ms/step - loss: 2.1258 - accuracy: 0.8467 - val_loss: 2.1338 - val_accuracy: 0.8385 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 2.1117 - accuracy: 0.8492 - val_loss: 2.1217 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 2.0854 - accuracy: 0.8566 - val_loss: 2.1070 - val_accuracy: 0.8405 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 2.0812 - accuracy: 0.8544 - val_loss: 2.1097 - val_accuracy: 0.8405 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "579/579 [==============================] - 73s 126ms/step - loss: 2.0631 - accuracy: 0.8521 - val_loss: 2.0916 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.0518 - accuracy: 0.8564 - val_loss: 2.0784 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 2.0317 - accuracy: 0.8631 - val_loss: 2.0746 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "579/579 [==============================] - 77s 133ms/step - loss: 2.0154 - accuracy: 0.8696 - val_loss: 2.0625 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "579/579 [==============================] - 73s 125ms/step - loss: 2.0122 - accuracy: 0.8621 - val_loss: 2.0452 - val_accuracy: 0.8560 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "579/579 [==============================] - 74s 128ms/step - loss: 1.9923 - accuracy: 0.8665 - val_loss: 2.0433 - val_accuracy: 0.8463 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "579/579 [==============================] - 72s 125ms/step - loss: 1.9890 - accuracy: 0.8678 - val_loss: 2.0334 - val_accuracy: 0.8521 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 1.9617 - accuracy: 0.8701 - val_loss: 2.0292 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "579/579 [==============================] - 72s 123ms/step - loss: 1.9456 - accuracy: 0.8718 - val_loss: 2.0148 - val_accuracy: 0.8541 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "579/579 [==============================] - 71s 123ms/step - loss: 1.9306 - accuracy: 0.8755 - val_loss: 2.0049 - val_accuracy: 0.8541 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 1.9287 - accuracy: 0.8713 - val_loss: 1.9893 - val_accuracy: 0.8502 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 1.9162 - accuracy: 0.8766 - val_loss: 1.9854 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 1.9080 - accuracy: 0.8793 - val_loss: 1.9837 - val_accuracy: 0.8502 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "579/579 [==============================] - 72s 124ms/step - loss: 1.8890 - accuracy: 0.8796 - val_loss: 1.9756 - val_accuracy: 0.8560 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(*IMAGE_SIZE, 3))\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=l2(0.001))(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    factor=0.5, \n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_fingerprint_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model with callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=100,\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79c4f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 24ms/step - loss: 1.9756 - accuracy: 0.8560\n",
      "\n",
      " Test Loss: 1.9756\n",
      " Test Accuracy: 0.8560\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"\\n Test Loss: {loss:.4f}\")\n",
    "print(f\" Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259e24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97f8ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 2s 26ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000         2\n",
      "         1.0     1.0000    1.0000    1.0000         2\n",
      "         2.0     1.0000    1.0000    1.0000         2\n",
      "         3.0     1.0000    1.0000    1.0000         2\n",
      "         4.0     0.6667    1.0000    0.8000         2\n",
      "         5.0     1.0000    1.0000    1.0000         2\n",
      "         6.0     1.0000    1.0000    1.0000         2\n",
      "         7.0     1.0000    1.0000    1.0000         2\n",
      "         8.0     1.0000    1.0000    1.0000         2\n",
      "         9.0     1.0000    1.0000    1.0000         2\n",
      "        10.0     1.0000    1.0000    1.0000         2\n",
      "        11.0     1.0000    1.0000    1.0000         2\n",
      "        12.0     1.0000    1.0000    1.0000         2\n",
      "        13.0     1.0000    1.0000    1.0000         2\n",
      "        14.0     1.0000    1.0000    1.0000         2\n",
      "        15.0     1.0000    1.0000    1.0000         2\n",
      "        16.0     1.0000    1.0000    1.0000         2\n",
      "        17.0     1.0000    1.0000    1.0000         2\n",
      "        18.0     0.0000    0.0000    0.0000         2\n",
      "        19.0     1.0000    1.0000    1.0000         2\n",
      "        20.0     1.0000    1.0000    1.0000         2\n",
      "        21.0     1.0000    1.0000    1.0000         2\n",
      "        22.0     0.6667    1.0000    0.8000         2\n",
      "        23.0     0.6667    1.0000    0.8000         2\n",
      "        24.0     1.0000    1.0000    1.0000         2\n",
      "        25.0     1.0000    1.0000    1.0000         2\n",
      "        26.0     1.0000    1.0000    1.0000         2\n",
      "        27.0     1.0000    1.0000    1.0000         2\n",
      "        28.0     1.0000    1.0000    1.0000         2\n",
      "        29.0     1.0000    1.0000    1.0000         2\n",
      "        30.0     1.0000    0.5000    0.6667         2\n",
      "        31.0     1.0000    0.5000    0.6667         2\n",
      "        32.0     1.0000    1.0000    1.0000         2\n",
      "        33.0     1.0000    1.0000    1.0000         2\n",
      "        34.0     0.6667    1.0000    0.8000         2\n",
      "        35.0     0.6667    1.0000    0.8000         2\n",
      "        36.0     1.0000    1.0000    1.0000         2\n",
      "        37.0     1.0000    1.0000    1.0000         2\n",
      "        38.0     1.0000    1.0000    1.0000         2\n",
      "        39.0     1.0000    1.0000    1.0000         2\n",
      "        40.0     1.0000    1.0000    1.0000         2\n",
      "        41.0     0.6667    1.0000    0.8000         2\n",
      "        42.0     1.0000    1.0000    1.0000         2\n",
      "        43.0     1.0000    1.0000    1.0000         2\n",
      "        44.0     1.0000    1.0000    1.0000         2\n",
      "        45.0     0.0000    0.0000    0.0000         2\n",
      "        46.0     1.0000    1.0000    1.0000         2\n",
      "        47.0     1.0000    1.0000    1.0000         2\n",
      "        48.0     1.0000    1.0000    1.0000         2\n",
      "        49.0     0.5000    1.0000    0.6667         2\n",
      "        50.0     1.0000    1.0000    1.0000         2\n",
      "        51.0     1.0000    1.0000    1.0000         2\n",
      "        52.0     0.6667    1.0000    0.8000         2\n",
      "        53.0     1.0000    1.0000    1.0000         2\n",
      "        54.0     1.0000    0.5000    0.6667         2\n",
      "        55.0     1.0000    1.0000    1.0000         2\n",
      "        56.0     1.0000    1.0000    1.0000         2\n",
      "        57.0     1.0000    1.0000    1.0000         2\n",
      "        58.0     1.0000    1.0000    1.0000         2\n",
      "        59.0     1.0000    1.0000    1.0000         2\n",
      "        60.0     1.0000    1.0000    1.0000         2\n",
      "        61.0     1.0000    1.0000    1.0000         2\n",
      "        62.0     1.0000    1.0000    1.0000         2\n",
      "        63.0     1.0000    1.0000    1.0000         2\n",
      "        64.0     1.0000    0.5000    0.6667         2\n",
      "        65.0     1.0000    1.0000    1.0000         2\n",
      "        66.0     1.0000    1.0000    1.0000         2\n",
      "        67.0     1.0000    1.0000    1.0000         2\n",
      "        68.0     0.6667    1.0000    0.8000         2\n",
      "        69.0     1.0000    1.0000    1.0000         2\n",
      "        70.0     1.0000    1.0000    1.0000         2\n",
      "        71.0     0.6667    1.0000    0.8000         2\n",
      "        72.0     1.0000    0.5000    0.6667         2\n",
      "        73.0     1.0000    1.0000    1.0000         2\n",
      "        74.0     1.0000    1.0000    1.0000         2\n",
      "        75.0     1.0000    0.5000    0.6667         2\n",
      "        76.0     1.0000    0.5000    0.6667         2\n",
      "        77.0     1.0000    1.0000    1.0000         2\n",
      "        78.0     1.0000    1.0000    1.0000         2\n",
      "        79.0     0.6667    1.0000    0.8000         2\n",
      "        80.0     1.0000    1.0000    1.0000         2\n",
      "        81.0     1.0000    1.0000    1.0000         2\n",
      "        82.0     1.0000    0.5000    0.6667         2\n",
      "        83.0     1.0000    1.0000    1.0000         2\n",
      "        84.0     0.6667    1.0000    0.8000         2\n",
      "        85.0     1.0000    1.0000    1.0000         2\n",
      "        86.0     1.0000    1.0000    1.0000         2\n",
      "        87.0     0.6667    1.0000    0.8000         2\n",
      "        88.0     1.0000    1.0000    1.0000         2\n",
      "        89.0     1.0000    1.0000    1.0000         2\n",
      "        90.0     1.0000    1.0000    1.0000         2\n",
      "        91.0     0.6667    1.0000    0.8000         2\n",
      "        92.0     1.0000    1.0000    1.0000         2\n",
      "        93.0     1.0000    1.0000    1.0000         2\n",
      "        94.0     1.0000    1.0000    1.0000         2\n",
      "        95.0     0.5000    1.0000    0.6667         2\n",
      "        96.0     0.0000    0.0000    0.0000         2\n",
      "        97.0     1.0000    0.5000    0.6667         2\n",
      "        98.0     1.0000    0.5000    0.6667         2\n",
      "        99.0     1.0000    1.0000    1.0000         2\n",
      "       100.0     1.0000    0.5000    0.6667         2\n",
      "       101.0     1.0000    1.0000    1.0000         2\n",
      "       102.0     1.0000    1.0000    1.0000         2\n",
      "       103.0     0.6667    1.0000    0.8000         2\n",
      "       104.0     0.6667    1.0000    0.8000         2\n",
      "       105.0     1.0000    1.0000    1.0000         2\n",
      "       106.0     1.0000    1.0000    1.0000         2\n",
      "       107.0     1.0000    1.0000    1.0000         2\n",
      "       108.0     0.6667    1.0000    0.8000         2\n",
      "       109.0     0.5000    0.5000    0.5000         2\n",
      "       110.0     1.0000    1.0000    1.0000         2\n",
      "       111.0     1.0000    1.0000    1.0000         2\n",
      "       112.0     1.0000    1.0000    1.0000         2\n",
      "       113.0     1.0000    0.5000    0.6667         2\n",
      "       114.0     0.6667    1.0000    0.8000         2\n",
      "       115.0     1.0000    1.0000    1.0000         2\n",
      "       116.0     1.0000    1.0000    1.0000         2\n",
      "       117.0     1.0000    1.0000    1.0000         2\n",
      "       118.0     1.0000    1.0000    1.0000         2\n",
      "       119.0     1.0000    1.0000    1.0000         2\n",
      "       120.0     1.0000    0.5000    0.6667         2\n",
      "       121.0     0.6667    1.0000    0.8000         2\n",
      "       122.0     1.0000    1.0000    1.0000         2\n",
      "       123.0     1.0000    1.0000    1.0000         2\n",
      "       124.0     1.0000    1.0000    1.0000         2\n",
      "       125.0     1.0000    1.0000    1.0000         2\n",
      "       126.0     1.0000    1.0000    1.0000         2\n",
      "       127.0     1.0000    1.0000    1.0000         2\n",
      "       128.0     1.0000    0.5000    0.6667         2\n",
      "       129.0     1.0000    1.0000    1.0000         2\n",
      "       130.0     1.0000    0.5000    0.6667         2\n",
      "       131.0     0.5000    1.0000    0.6667         2\n",
      "       132.0     1.0000    1.0000    1.0000         2\n",
      "       133.0     1.0000    1.0000    1.0000         2\n",
      "       134.0     0.4000    1.0000    0.5714         2\n",
      "       135.0     1.0000    1.0000    1.0000         2\n",
      "       136.0     0.0000    0.0000    0.0000         2\n",
      "       137.0     1.0000    0.5000    0.6667         2\n",
      "       138.0     1.0000    1.0000    1.0000         2\n",
      "       139.0     1.0000    1.0000    1.0000         2\n",
      "       140.0     1.0000    1.0000    1.0000         2\n",
      "       141.0     1.0000    1.0000    1.0000         2\n",
      "       142.0     1.0000    1.0000    1.0000         2\n",
      "       143.0     1.0000    1.0000    1.0000         2\n",
      "       144.0     1.0000    1.0000    1.0000         2\n",
      "       145.0     0.4000    1.0000    0.5714         2\n",
      "       146.0     1.0000    1.0000    1.0000         2\n",
      "       147.0     1.0000    0.5000    0.6667         2\n",
      "       148.0     1.0000    1.0000    1.0000         2\n",
      "       149.0     1.0000    1.0000    1.0000         2\n",
      "       150.0     1.0000    1.0000    1.0000         2\n",
      "       151.0     1.0000    1.0000    1.0000         2\n",
      "       152.0     1.0000    1.0000    1.0000         2\n",
      "       153.0     1.0000    1.0000    1.0000         2\n",
      "       154.0     0.6667    1.0000    0.8000         2\n",
      "       155.0     1.0000    1.0000    1.0000         2\n",
      "       156.0     0.5000    1.0000    0.6667         2\n",
      "       157.0     1.0000    1.0000    1.0000         2\n",
      "       158.0     0.6667    1.0000    0.8000         2\n",
      "       159.0     1.0000    1.0000    1.0000         2\n",
      "       160.0     1.0000    0.5000    0.6667         2\n",
      "       161.0     1.0000    0.5000    0.6667         2\n",
      "       162.0     1.0000    1.0000    1.0000         2\n",
      "       163.0     1.0000    0.5000    0.6667         2\n",
      "       164.0     1.0000    1.0000    1.0000         2\n",
      "       165.0     1.0000    0.5000    0.6667         2\n",
      "       166.0     1.0000    1.0000    1.0000         2\n",
      "       167.0     1.0000    0.5000    0.6667         2\n",
      "       168.0     1.0000    0.5000    0.6667         2\n",
      "       169.0     1.0000    1.0000    1.0000         2\n",
      "       170.0     1.0000    0.5000    0.6667         2\n",
      "       171.0     0.0000    0.0000    0.0000         2\n",
      "       172.0     0.5000    1.0000    0.6667         2\n",
      "       173.0     0.6667    1.0000    0.8000         2\n",
      "       174.0     1.0000    1.0000    1.0000         2\n",
      "       175.0     1.0000    0.5000    0.6667         2\n",
      "       176.0     0.0000    0.0000    0.0000         2\n",
      "       177.0     1.0000    1.0000    1.0000         2\n",
      "       178.0     1.0000    0.5000    0.6667         2\n",
      "       179.0     0.5000    0.5000    0.5000         2\n",
      "       180.0     1.0000    0.5000    0.6667         2\n",
      "       181.0     0.0000    0.0000    0.0000         2\n",
      "       182.0     0.5000    1.0000    0.6667         2\n",
      "       183.0     0.5000    1.0000    0.6667         2\n",
      "       184.0     1.0000    1.0000    1.0000         2\n",
      "       185.0     0.6667    1.0000    0.8000         2\n",
      "       186.0     0.0000    0.0000    0.0000         2\n",
      "       187.0     0.5000    1.0000    0.6667         2\n",
      "       188.0     0.0000    0.0000    0.0000         2\n",
      "       189.0     1.0000    1.0000    1.0000         2\n",
      "       190.0     0.6667    1.0000    0.8000         2\n",
      "       191.0     1.0000    1.0000    1.0000         2\n",
      "       192.0     0.6667    1.0000    0.8000         2\n",
      "       193.0     0.5000    1.0000    0.6667         2\n",
      "       194.0     1.0000    0.5000    0.6667         2\n",
      "       195.0     0.6667    1.0000    0.8000         2\n",
      "       196.0     0.3333    0.5000    0.4000         2\n",
      "       197.0     0.5000    0.5000    0.5000         2\n",
      "       198.0     0.6667    1.0000    0.8000         2\n",
      "       199.0     0.6667    1.0000    0.8000         2\n",
      "       200.0     1.0000    0.5000    0.6667         2\n",
      "       201.0     0.0000    0.0000    0.0000         2\n",
      "       202.0     1.0000    0.5000    0.6667         2\n",
      "       203.0     0.0000    0.0000    0.0000         2\n",
      "       204.0     1.0000    0.5000    0.6667         2\n",
      "       205.0     0.5000    1.0000    0.6667         2\n",
      "       206.0     0.0000    0.0000    0.0000         2\n",
      "       207.0     0.6667    1.0000    0.8000         2\n",
      "       208.0     1.0000    0.5000    0.6667         2\n",
      "       209.0     1.0000    0.5000    0.6667         2\n",
      "       210.0     1.0000    0.5000    0.6667         2\n",
      "       211.0     1.0000    1.0000    1.0000         2\n",
      "       212.0     0.0000    0.0000    0.0000         2\n",
      "       213.0     0.4000    1.0000    0.5714         2\n",
      "       214.0     0.5000    0.5000    0.5000         2\n",
      "       215.0     1.0000    0.5000    0.6667         2\n",
      "       216.0     0.6667    1.0000    0.8000         2\n",
      "       217.0     1.0000    0.5000    0.6667         2\n",
      "       218.0     0.0000    0.0000    0.0000         2\n",
      "       219.0     1.0000    1.0000    1.0000         2\n",
      "       220.0     0.5000    0.5000    0.5000         2\n",
      "       221.0     1.0000    0.5000    0.6667         2\n",
      "       222.0     1.0000    1.0000    1.0000         2\n",
      "       223.0     0.6667    1.0000    0.8000         2\n",
      "       224.0     1.0000    1.0000    1.0000         2\n",
      "       225.0     1.0000    1.0000    1.0000         2\n",
      "       226.0     1.0000    1.0000    1.0000         2\n",
      "       227.0     1.0000    1.0000    1.0000         2\n",
      "       228.0     0.6667    1.0000    0.8000         2\n",
      "       229.0     1.0000    0.5000    0.6667         2\n",
      "       230.0     1.0000    1.0000    1.0000         2\n",
      "       231.0     1.0000    1.0000    1.0000         2\n",
      "       232.0     1.0000    1.0000    1.0000         2\n",
      "       233.0     1.0000    0.5000    0.6667         2\n",
      "       234.0     1.0000    0.5000    0.6667         2\n",
      "       235.0     1.0000    1.0000    1.0000         2\n",
      "       236.0     1.0000    1.0000    1.0000         2\n",
      "       237.0     1.0000    1.0000    1.0000         2\n",
      "       238.0     1.0000    1.0000    1.0000         2\n",
      "       239.0     1.0000    1.0000    1.0000         2\n",
      "       240.0     1.0000    1.0000    1.0000         2\n",
      "       241.0     1.0000    1.0000    1.0000         2\n",
      "       242.0     1.0000    1.0000    1.0000         2\n",
      "       243.0     1.0000    1.0000    1.0000         2\n",
      "       244.0     1.0000    1.0000    1.0000         2\n",
      "       245.0     1.0000    1.0000    1.0000         2\n",
      "       246.0     1.0000    1.0000    1.0000         2\n",
      "       247.0     1.0000    1.0000    1.0000         2\n",
      "       248.0     1.0000    1.0000    1.0000         2\n",
      "       249.0     1.0000    1.0000    1.0000         2\n",
      "       250.0     1.0000    1.0000    1.0000         2\n",
      "       251.0     1.0000    1.0000    1.0000         2\n",
      "       252.0     1.0000    1.0000    1.0000         2\n",
      "       253.0     1.0000    1.0000    1.0000         2\n",
      "       254.0     1.0000    1.0000    1.0000         2\n",
      "       255.0     1.0000    1.0000    1.0000         2\n",
      "       256.0     0.6667    1.0000    0.8000         2\n",
      "\n",
      "    accuracy                         0.8560       514\n",
      "   macro avg     0.8652    0.8560    0.8387       514\n",
      "weighted avg     0.8652    0.8560    0.8387       514\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "steps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "\n",
    "for i in range(steps):\n",
    "    x, y = next(test_generator)\n",
    "    X_test.append(x)\n",
    "    y_test.append(y)\n",
    "\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "y_pred_probs = model.predict(X_test, batch_size=16)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c77e80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m y_true \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtest_generator\u001b[49m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      8\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(test_generator\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m test_generator\u001b[38;5;241m.\u001b[39mbatch_size))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# run abis code block bawah\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "test_generator.reset()\n",
    "steps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "\n",
    "for _ in range(steps):\n",
    "    x_batch, y_batch = next(test_generator)\n",
    "\n",
    "    if y_batch.ndim > 1:\n",
    "        y_true.extend(np.argmax(y_batch, axis=1))\n",
    "    else:\n",
    "        y_true.extend(y_batch)\n",
    "    \n",
    "    preds = model.predict(x_batch)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", linewidths=0.5, linecolor='gray')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b67f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000         2\n",
      "         1.0     1.0000    1.0000    1.0000         2\n",
      "         2.0     1.0000    1.0000    1.0000         2\n",
      "         3.0     1.0000    1.0000    1.0000         2\n",
      "         4.0     0.6667    1.0000    0.8000         2\n",
      "         5.0     1.0000    1.0000    1.0000         2\n",
      "         6.0     1.0000    1.0000    1.0000         2\n",
      "         7.0     1.0000    1.0000    1.0000         2\n",
      "         8.0     1.0000    1.0000    1.0000         2\n",
      "         9.0     1.0000    1.0000    1.0000         2\n",
      "        10.0     1.0000    1.0000    1.0000         2\n",
      "        11.0     1.0000    1.0000    1.0000         2\n",
      "        12.0     1.0000    1.0000    1.0000         2\n",
      "        13.0     1.0000    1.0000    1.0000         2\n",
      "        14.0     1.0000    1.0000    1.0000         2\n",
      "        15.0     1.0000    1.0000    1.0000         2\n",
      "        16.0     1.0000    1.0000    1.0000         2\n",
      "        17.0     1.0000    1.0000    1.0000         2\n",
      "        18.0     0.0000    0.0000    0.0000         2\n",
      "        19.0     1.0000    1.0000    1.0000         2\n",
      "        20.0     1.0000    1.0000    1.0000         2\n",
      "        21.0     1.0000    1.0000    1.0000         2\n",
      "        22.0     0.6667    1.0000    0.8000         2\n",
      "        23.0     0.6667    1.0000    0.8000         2\n",
      "        24.0     1.0000    1.0000    1.0000         2\n",
      "        25.0     1.0000    1.0000    1.0000         2\n",
      "        26.0     1.0000    1.0000    1.0000         2\n",
      "        27.0     1.0000    1.0000    1.0000         2\n",
      "        28.0     1.0000    1.0000    1.0000         2\n",
      "        29.0     1.0000    1.0000    1.0000         2\n",
      "        30.0     1.0000    0.5000    0.6667         2\n",
      "        31.0     1.0000    0.5000    0.6667         2\n",
      "        32.0     1.0000    1.0000    1.0000         2\n",
      "        33.0     1.0000    1.0000    1.0000         2\n",
      "        34.0     0.6667    1.0000    0.8000         2\n",
      "        35.0     0.6667    1.0000    0.8000         2\n",
      "        36.0     1.0000    1.0000    1.0000         2\n",
      "        37.0     1.0000    1.0000    1.0000         2\n",
      "        38.0     1.0000    1.0000    1.0000         2\n",
      "        39.0     1.0000    1.0000    1.0000         2\n",
      "        40.0     1.0000    1.0000    1.0000         2\n",
      "        41.0     0.6667    1.0000    0.8000         2\n",
      "        42.0     1.0000    1.0000    1.0000         2\n",
      "        43.0     1.0000    1.0000    1.0000         2\n",
      "        44.0     1.0000    1.0000    1.0000         2\n",
      "        45.0     0.0000    0.0000    0.0000         2\n",
      "        46.0     1.0000    1.0000    1.0000         2\n",
      "        47.0     1.0000    1.0000    1.0000         2\n",
      "        48.0     1.0000    1.0000    1.0000         2\n",
      "        49.0     0.5000    1.0000    0.6667         2\n",
      "        50.0     1.0000    1.0000    1.0000         2\n",
      "        51.0     1.0000    1.0000    1.0000         2\n",
      "        52.0     0.6667    1.0000    0.8000         2\n",
      "        53.0     1.0000    1.0000    1.0000         2\n",
      "        54.0     1.0000    0.5000    0.6667         2\n",
      "        55.0     1.0000    1.0000    1.0000         2\n",
      "        56.0     1.0000    1.0000    1.0000         2\n",
      "        57.0     1.0000    1.0000    1.0000         2\n",
      "        58.0     1.0000    1.0000    1.0000         2\n",
      "        59.0     1.0000    1.0000    1.0000         2\n",
      "        60.0     1.0000    1.0000    1.0000         2\n",
      "        61.0     1.0000    1.0000    1.0000         2\n",
      "        62.0     1.0000    1.0000    1.0000         2\n",
      "        63.0     1.0000    1.0000    1.0000         2\n",
      "        64.0     1.0000    0.5000    0.6667         2\n",
      "        65.0     1.0000    1.0000    1.0000         2\n",
      "        66.0     1.0000    1.0000    1.0000         2\n",
      "        67.0     1.0000    1.0000    1.0000         2\n",
      "        68.0     0.6667    1.0000    0.8000         2\n",
      "        69.0     1.0000    1.0000    1.0000         2\n",
      "        70.0     1.0000    1.0000    1.0000         2\n",
      "        71.0     0.6667    1.0000    0.8000         2\n",
      "        72.0     1.0000    0.5000    0.6667         2\n",
      "        73.0     1.0000    1.0000    1.0000         2\n",
      "        74.0     1.0000    1.0000    1.0000         2\n",
      "        75.0     1.0000    0.5000    0.6667         2\n",
      "        76.0     1.0000    0.5000    0.6667         2\n",
      "        77.0     1.0000    1.0000    1.0000         2\n",
      "        78.0     1.0000    1.0000    1.0000         2\n",
      "        79.0     0.6667    1.0000    0.8000         2\n",
      "        80.0     1.0000    1.0000    1.0000         2\n",
      "        81.0     1.0000    1.0000    1.0000         2\n",
      "        82.0     1.0000    0.5000    0.6667         2\n",
      "        83.0     1.0000    1.0000    1.0000         2\n",
      "        84.0     0.6667    1.0000    0.8000         2\n",
      "        85.0     1.0000    1.0000    1.0000         2\n",
      "        86.0     1.0000    1.0000    1.0000         2\n",
      "        87.0     0.6667    1.0000    0.8000         2\n",
      "        88.0     1.0000    1.0000    1.0000         2\n",
      "        89.0     1.0000    1.0000    1.0000         2\n",
      "        90.0     1.0000    1.0000    1.0000         2\n",
      "        91.0     0.6667    1.0000    0.8000         2\n",
      "        92.0     1.0000    1.0000    1.0000         2\n",
      "        93.0     1.0000    1.0000    1.0000         2\n",
      "        94.0     1.0000    1.0000    1.0000         2\n",
      "        95.0     0.5000    1.0000    0.6667         2\n",
      "        96.0     0.0000    0.0000    0.0000         2\n",
      "        97.0     1.0000    0.5000    0.6667         2\n",
      "        98.0     1.0000    0.5000    0.6667         2\n",
      "        99.0     1.0000    1.0000    1.0000         2\n",
      "       100.0     1.0000    0.5000    0.6667         2\n",
      "       101.0     1.0000    1.0000    1.0000         2\n",
      "       102.0     1.0000    1.0000    1.0000         2\n",
      "       103.0     0.6667    1.0000    0.8000         2\n",
      "       104.0     0.6667    1.0000    0.8000         2\n",
      "       105.0     1.0000    1.0000    1.0000         2\n",
      "       106.0     1.0000    1.0000    1.0000         2\n",
      "       107.0     1.0000    1.0000    1.0000         2\n",
      "       108.0     0.6667    1.0000    0.8000         2\n",
      "       109.0     0.5000    0.5000    0.5000         2\n",
      "       110.0     1.0000    1.0000    1.0000         2\n",
      "       111.0     1.0000    1.0000    1.0000         2\n",
      "       112.0     1.0000    1.0000    1.0000         2\n",
      "       113.0     1.0000    0.5000    0.6667         2\n",
      "       114.0     0.6667    1.0000    0.8000         2\n",
      "       115.0     1.0000    1.0000    1.0000         2\n",
      "       116.0     1.0000    1.0000    1.0000         2\n",
      "       117.0     1.0000    1.0000    1.0000         2\n",
      "       118.0     1.0000    1.0000    1.0000         2\n",
      "       119.0     1.0000    1.0000    1.0000         2\n",
      "       120.0     1.0000    0.5000    0.6667         2\n",
      "       121.0     0.6667    1.0000    0.8000         2\n",
      "       122.0     1.0000    1.0000    1.0000         2\n",
      "       123.0     1.0000    1.0000    1.0000         2\n",
      "       124.0     1.0000    1.0000    1.0000         2\n",
      "       125.0     1.0000    1.0000    1.0000         2\n",
      "       126.0     1.0000    1.0000    1.0000         2\n",
      "       127.0     1.0000    1.0000    1.0000         2\n",
      "       128.0     1.0000    0.5000    0.6667         2\n",
      "       129.0     1.0000    1.0000    1.0000         2\n",
      "       130.0     1.0000    0.5000    0.6667         2\n",
      "       131.0     0.5000    1.0000    0.6667         2\n",
      "       132.0     1.0000    1.0000    1.0000         2\n",
      "       133.0     1.0000    1.0000    1.0000         2\n",
      "       134.0     0.4000    1.0000    0.5714         2\n",
      "       135.0     1.0000    1.0000    1.0000         2\n",
      "       136.0     0.0000    0.0000    0.0000         2\n",
      "       137.0     1.0000    0.5000    0.6667         2\n",
      "       138.0     1.0000    1.0000    1.0000         2\n",
      "       139.0     1.0000    1.0000    1.0000         2\n",
      "       140.0     1.0000    1.0000    1.0000         2\n",
      "       141.0     1.0000    1.0000    1.0000         2\n",
      "       142.0     1.0000    1.0000    1.0000         2\n",
      "       143.0     1.0000    1.0000    1.0000         2\n",
      "       144.0     1.0000    1.0000    1.0000         2\n",
      "       145.0     0.4000    1.0000    0.5714         2\n",
      "       146.0     1.0000    1.0000    1.0000         2\n",
      "       147.0     1.0000    0.5000    0.6667         2\n",
      "       148.0     1.0000    1.0000    1.0000         2\n",
      "       149.0     1.0000    1.0000    1.0000         2\n",
      "       150.0     1.0000    1.0000    1.0000         2\n",
      "       151.0     1.0000    1.0000    1.0000         2\n",
      "       152.0     1.0000    1.0000    1.0000         2\n",
      "       153.0     1.0000    1.0000    1.0000         2\n",
      "       154.0     0.6667    1.0000    0.8000         2\n",
      "       155.0     1.0000    1.0000    1.0000         2\n",
      "       156.0     0.5000    1.0000    0.6667         2\n",
      "       157.0     1.0000    1.0000    1.0000         2\n",
      "       158.0     0.6667    1.0000    0.8000         2\n",
      "       159.0     1.0000    1.0000    1.0000         2\n",
      "       160.0     1.0000    0.5000    0.6667         2\n",
      "       161.0     1.0000    0.5000    0.6667         2\n",
      "       162.0     1.0000    1.0000    1.0000         2\n",
      "       163.0     1.0000    0.5000    0.6667         2\n",
      "       164.0     1.0000    1.0000    1.0000         2\n",
      "       165.0     1.0000    0.5000    0.6667         2\n",
      "       166.0     1.0000    1.0000    1.0000         2\n",
      "       167.0     1.0000    0.5000    0.6667         2\n",
      "       168.0     1.0000    0.5000    0.6667         2\n",
      "       169.0     1.0000    1.0000    1.0000         2\n",
      "       170.0     1.0000    0.5000    0.6667         2\n",
      "       171.0     0.0000    0.0000    0.0000         2\n",
      "       172.0     0.5000    1.0000    0.6667         2\n",
      "       173.0     0.6667    1.0000    0.8000         2\n",
      "       174.0     1.0000    1.0000    1.0000         2\n",
      "       175.0     1.0000    0.5000    0.6667         2\n",
      "       176.0     0.0000    0.0000    0.0000         2\n",
      "       177.0     1.0000    1.0000    1.0000         2\n",
      "       178.0     1.0000    0.5000    0.6667         2\n",
      "       179.0     0.5000    0.5000    0.5000         2\n",
      "       180.0     1.0000    0.5000    0.6667         2\n",
      "       181.0     0.0000    0.0000    0.0000         2\n",
      "       182.0     0.5000    1.0000    0.6667         2\n",
      "       183.0     0.5000    1.0000    0.6667         2\n",
      "       184.0     1.0000    1.0000    1.0000         2\n",
      "       185.0     0.6667    1.0000    0.8000         2\n",
      "       186.0     0.0000    0.0000    0.0000         2\n",
      "       187.0     0.5000    1.0000    0.6667         2\n",
      "       188.0     0.0000    0.0000    0.0000         2\n",
      "       189.0     1.0000    1.0000    1.0000         2\n",
      "       190.0     0.6667    1.0000    0.8000         2\n",
      "       191.0     1.0000    1.0000    1.0000         2\n",
      "       192.0     0.6667    1.0000    0.8000         2\n",
      "       193.0     0.5000    1.0000    0.6667         2\n",
      "       194.0     1.0000    0.5000    0.6667         2\n",
      "       195.0     0.6667    1.0000    0.8000         2\n",
      "       196.0     0.3333    0.5000    0.4000         2\n",
      "       197.0     0.5000    0.5000    0.5000         2\n",
      "       198.0     0.6667    1.0000    0.8000         2\n",
      "       199.0     0.6667    1.0000    0.8000         2\n",
      "       200.0     1.0000    0.5000    0.6667         2\n",
      "       201.0     0.0000    0.0000    0.0000         2\n",
      "       202.0     1.0000    0.5000    0.6667         2\n",
      "       203.0     0.0000    0.0000    0.0000         2\n",
      "       204.0     1.0000    0.5000    0.6667         2\n",
      "       205.0     0.5000    1.0000    0.6667         2\n",
      "       206.0     0.0000    0.0000    0.0000         2\n",
      "       207.0     0.6667    1.0000    0.8000         2\n",
      "       208.0     1.0000    0.5000    0.6667         2\n",
      "       209.0     1.0000    0.5000    0.6667         2\n",
      "       210.0     1.0000    0.5000    0.6667         2\n",
      "       211.0     1.0000    1.0000    1.0000         2\n",
      "       212.0     0.0000    0.0000    0.0000         2\n",
      "       213.0     0.4000    1.0000    0.5714         2\n",
      "       214.0     0.5000    0.5000    0.5000         2\n",
      "       215.0     1.0000    0.5000    0.6667         2\n",
      "       216.0     0.6667    1.0000    0.8000         2\n",
      "       217.0     1.0000    0.5000    0.6667         2\n",
      "       218.0     0.0000    0.0000    0.0000         2\n",
      "       219.0     1.0000    1.0000    1.0000         2\n",
      "       220.0     0.5000    0.5000    0.5000         2\n",
      "       221.0     1.0000    0.5000    0.6667         2\n",
      "       222.0     1.0000    1.0000    1.0000         2\n",
      "       223.0     0.6667    1.0000    0.8000         2\n",
      "       224.0     1.0000    1.0000    1.0000         2\n",
      "       225.0     1.0000    1.0000    1.0000         2\n",
      "       226.0     1.0000    1.0000    1.0000         2\n",
      "       227.0     1.0000    1.0000    1.0000         2\n",
      "       228.0     0.6667    1.0000    0.8000         2\n",
      "       229.0     1.0000    0.5000    0.6667         2\n",
      "       230.0     1.0000    1.0000    1.0000         2\n",
      "       231.0     1.0000    1.0000    1.0000         2\n",
      "       232.0     1.0000    1.0000    1.0000         2\n",
      "       233.0     1.0000    0.5000    0.6667         2\n",
      "       234.0     1.0000    0.5000    0.6667         2\n",
      "       235.0     1.0000    1.0000    1.0000         2\n",
      "       236.0     1.0000    1.0000    1.0000         2\n",
      "       237.0     1.0000    1.0000    1.0000         2\n",
      "       238.0     1.0000    1.0000    1.0000         2\n",
      "       239.0     1.0000    1.0000    1.0000         2\n",
      "       240.0     1.0000    1.0000    1.0000         2\n",
      "       241.0     1.0000    1.0000    1.0000         2\n",
      "       242.0     1.0000    1.0000    1.0000         2\n",
      "       243.0     1.0000    1.0000    1.0000         2\n",
      "       244.0     1.0000    1.0000    1.0000         2\n",
      "       245.0     1.0000    1.0000    1.0000         2\n",
      "       246.0     1.0000    1.0000    1.0000         2\n",
      "       247.0     1.0000    1.0000    1.0000         2\n",
      "       248.0     1.0000    1.0000    1.0000         2\n",
      "       249.0     1.0000    1.0000    1.0000         2\n",
      "       250.0     1.0000    1.0000    1.0000         2\n",
      "       251.0     1.0000    1.0000    1.0000         2\n",
      "       252.0     1.0000    1.0000    1.0000         2\n",
      "       253.0     1.0000    1.0000    1.0000         2\n",
      "       254.0     1.0000    1.0000    1.0000         2\n",
      "       255.0     1.0000    1.0000    1.0000         2\n",
      "       256.0     0.6667    1.0000    0.8000         2\n",
      "\n",
      "    accuracy                         0.8560       514\n",
      "   macro avg     0.8652    0.8560    0.8387       514\n",
      "weighted avg     0.8652    0.8560    0.8387       514\n",
      "\n",
      "\n",
      "Macro Avg - Precision: 0.8652, Recall: 0.8560, F1 Score: 0.8387\n",
      "Weighted Avg - Precision: 0.8652, Recall: 0.8560, F1 Score: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "precision_macro = report['macro avg']['precision']\n",
    "recall_macro = report['macro avg']['recall']\n",
    "f1_macro = report['macro avg']['f1-score']\n",
    "\n",
    "precision_weighted = report['weighted avg']['precision']\n",
    "recall_weighted = report['weighted avg']['recall']\n",
    "f1_weighted = report['weighted avg']['f1-score']\n",
    "\n",
    "print(f\"\\nMacro Avg - Precision: {precision_macro:.4f}, Recall: {recall_macro:.4f}, F1 Score: {f1_macro:.4f}\")\n",
    "print(f\"Weighted Avg - Precision: {precision_weighted:.4f}, Recall: {recall_weighted:.4f}, F1 Score: {f1_weighted:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559376f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
