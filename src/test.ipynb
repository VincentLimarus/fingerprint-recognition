{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998273f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fcd2b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9252 images belonging to 257 classes.\n",
      "Found 514 images belonging to 257 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"../data/final/train\"\n",
    "test_dir  = \"../data/final/test\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'  # assuming you're using sparse categorical crossentropy\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4e7dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "579/579 [==============================] - 203s 334ms/step - loss: 7.1585 - accuracy: 0.0372 - val_loss: 6.3480 - val_accuracy: 0.0798 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "579/579 [==============================] - 139s 239ms/step - loss: 5.3183 - accuracy: 0.1876 - val_loss: 5.5021 - val_accuracy: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "579/579 [==============================] - 120s 207ms/step - loss: 4.2393 - accuracy: 0.3487 - val_loss: 5.0885 - val_accuracy: 0.2432 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "579/579 [==============================] - 122s 211ms/step - loss: 3.6529 - accuracy: 0.4631 - val_loss: 5.0401 - val_accuracy: 0.2490 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "579/579 [==============================] - 138s 239ms/step - loss: 3.2434 - accuracy: 0.5457 - val_loss: 5.1207 - val_accuracy: 0.2374 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "579/579 [==============================] - 116s 200ms/step - loss: 2.9766 - accuracy: 0.6091 - val_loss: 4.7660 - val_accuracy: 0.2879 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "579/579 [==============================] - 121s 209ms/step - loss: 2.7314 - accuracy: 0.6546 - val_loss: 4.4665 - val_accuracy: 0.3230 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "579/579 [==============================] - 113s 196ms/step - loss: 2.5612 - accuracy: 0.6925 - val_loss: 4.4558 - val_accuracy: 0.3191 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "579/579 [==============================] - 114s 197ms/step - loss: 2.4056 - accuracy: 0.7198 - val_loss: 4.4288 - val_accuracy: 0.3307 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "579/579 [==============================] - 119s 206ms/step - loss: 2.2557 - accuracy: 0.7518 - val_loss: 4.5925 - val_accuracy: 0.3054 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "579/579 [==============================] - 115s 199ms/step - loss: 2.1331 - accuracy: 0.7752 - val_loss: 4.8868 - val_accuracy: 0.2763 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "579/579 [==============================] - 108s 187ms/step - loss: 2.0333 - accuracy: 0.7861 - val_loss: 4.6174 - val_accuracy: 0.2996 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "579/579 [==============================] - 127s 220ms/step - loss: 1.9069 - accuracy: 0.8166 - val_loss: 4.2894 - val_accuracy: 0.3521 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "579/579 [==============================] - 120s 207ms/step - loss: 1.8571 - accuracy: 0.8190 - val_loss: 4.4059 - val_accuracy: 0.3249 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "579/579 [==============================] - 112s 194ms/step - loss: 1.7914 - accuracy: 0.8370 - val_loss: 4.5671 - val_accuracy: 0.3132 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "579/579 [==============================] - 133s 229ms/step - loss: 1.7655 - accuracy: 0.8365 - val_loss: 4.5711 - val_accuracy: 0.3035 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "579/579 [==============================] - 146s 253ms/step - loss: 1.6942 - accuracy: 0.8511 - val_loss: 4.5403 - val_accuracy: 0.3132 - lr: 2.5000e-05\n",
      "Epoch 18/100\n",
      "579/579 [==============================] - 115s 198ms/step - loss: 1.6850 - accuracy: 0.8486 - val_loss: 4.4682 - val_accuracy: 0.3210 - lr: 2.5000e-05\n",
      "Epoch 19/100\n",
      "579/579 [==============================] - 126s 217ms/step - loss: 1.6490 - accuracy: 0.8567 - val_loss: 4.5018 - val_accuracy: 0.3230 - lr: 2.5000e-05\n",
      "Epoch 20/100\n",
      "579/579 [==============================] - 138s 239ms/step - loss: 1.6204 - accuracy: 0.8634 - val_loss: 4.5270 - val_accuracy: 0.3113 - lr: 1.2500e-05\n",
      "Epoch 21/100\n",
      "579/579 [==============================] - 166s 287ms/step - loss: 1.6063 - accuracy: 0.8635 - val_loss: 4.4674 - val_accuracy: 0.3249 - lr: 1.2500e-05\n",
      "Epoch 22/100\n",
      "579/579 [==============================] - 120s 206ms/step - loss: 1.5862 - accuracy: 0.8685 - val_loss: 4.3807 - val_accuracy: 0.3366 - lr: 1.2500e-05\n",
      "Epoch 23/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.5817 - accuracy: 0.8689Restoring model weights from the end of the best epoch: 13.\n",
      "579/579 [==============================] - 120s 207ms/step - loss: 1.5817 - accuracy: 0.8689 - val_loss: 4.4143 - val_accuracy: 0.3210 - lr: 6.2500e-06\n",
      "Epoch 23: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a825778250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "NUM_CLASSES = len(os.listdir(train_dir))\n",
    "\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers[:-16]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax', \n",
    "                    kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', patience=3, factor=0.5, min_lr=1e-7)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,                 \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_fingerprint_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=100,\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634d77e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 3s 67ms/step - loss: 4.2894 - accuracy: 0.3521\n",
      "\n",
      " Test Loss: 4.2894\n",
      " Test Accuracy: 0.3521\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"\\n Test Loss: {loss:.4f}\")\n",
    "print(f\" Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba4ad782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\lenovo\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\lenovo\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image) (1.13.1)\n",
      "Collecting networkx>=2.8 (from scikit-image)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\lenovo\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image) (11.1.0)\n",
      "Collecting imageio>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2024.8.30-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\lenovo\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image) (24.2)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 3.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.1/12.9 MB 1.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.1/12.9 MB 2.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.9/12.9 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 4.7/12.9 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 6.0/12.9 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.1/12.9 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 8.4/12.9 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.9 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.0/12.9 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.2/12.9 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.7/12.9 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/12.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/12.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.8/1.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.3/1.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
      "Installing collected packages: tifffile, networkx, lazy-loader, imageio, scikit-image\n",
      "Successfully installed imageio-2.37.0 lazy-loader-0.4 networkx-3.2.1 scikit-image-0.24.0 tifffile-2024.8.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
