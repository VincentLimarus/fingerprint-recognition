{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be44000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "raw_dir = \"../data/pre-raw\"\n",
    "output_dir = \"../data/raw\"  \n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.exists(raw_dir):\n",
    "    raw_dir = input(\"Input raw dataset directory:\")\n",
    "\n",
    "files = [f for f in os.listdir(raw_dir) if os.path.isfile(os.path.join(raw_dir, f))]\n",
    "files.sort()\n",
    "\n",
    "individu_finger_map = {}\n",
    "global_finger_serial = 1\n",
    "\n",
    "for file in files:\n",
    "    name, ext = os.path.splitext(file)\n",
    "    parts = name.split(\"_\")\n",
    "\n",
    "    if len(parts) != 3:\n",
    "        print(f\"Skipping invalid filename: {file}\")\n",
    "        continue\n",
    "\n",
    "    individu = parts[0]\n",
    "    finger_orig = int(parts[1])\n",
    "    scan = parts[2]\n",
    "\n",
    "    if individu not in individu_finger_map:\n",
    "        individu_finger_map[individu] = {}\n",
    "\n",
    "    if finger_orig not in individu_finger_map[individu]:\n",
    "        mapped_finger = global_finger_serial\n",
    "        individu_finger_map[individu][finger_orig] = mapped_finger\n",
    "        global_finger_serial += 1  \n",
    "    else:\n",
    "        mapped_finger = individu_finger_map[individu][finger_orig]\n",
    "\n",
    "    new_name = f\"{individu}_{mapped_finger}_{scan}{ext}\"\n",
    "\n",
    "    src_file = os.path.join(raw_dir, file)\n",
    "    dest_file = os.path.join(output_dir, new_name)\n",
    "\n",
    "    shutil.copy(src_file, dest_file)\n",
    "    print(f\"Copied: {file} → {new_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeletonize(img):\n",
    "    \"\"\"Alternative skeletonization implementation without ximgproc\"\"\"\n",
    "    skel = np.zeros(img.shape, np.uint8)\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "    while True:\n",
    "        open_img = cv2.morphologyEx(img, cv2.MORPH_OPEN, element)\n",
    "        temp = cv2.subtract(img, open_img)\n",
    "        eroded = cv2.erode(img, element)\n",
    "        skel = cv2.bitwise_or(skel, temp)\n",
    "        img = eroded.copy()\n",
    "        if cv2.countNonZero(img) == 0:\n",
    "            break\n",
    "    return skel\n",
    "\n",
    "def process_fingerprint(image_path, output_path, target_size=None, upscale_factor=1.0):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "    \n",
    "    # Resize if needed\n",
    "    if target_size:\n",
    "        image = cv2.resize(image, target_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    elif upscale_factor != 1.0:\n",
    "        h, w = image.shape\n",
    "        image = cv2.resize(image, (int(w*upscale_factor), int(h*upscale_factor)), \n",
    "                         interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    # 1. Contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(image)\n",
    "    \n",
    "    # 2. Noise reduction\n",
    "    denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
    "    \n",
    "    # 3. Adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY_INV, 21, 7)\n",
    "    \n",
    "    # 4. Morphological operations\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    # 5. Skeletonization (using alternative method)\n",
    "    skeleton = skeletonize(morph)\n",
    "    \n",
    "    # 6. Final inversion and saving\n",
    "    result = cv2.bitwise_not(skeleton)\n",
    "    cv2.imwrite(output_path, result)\n",
    "\n",
    "def batch_process_fingerprints(input_folder, output_folder, upscale=False):\n",
    "    \"\"\"\n",
    "    Process all fingerprints in a folder\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    files = [f for f in os.listdir(input_folder) if f.lower().endswith('.tif')]\n",
    "    \n",
    "    for filename in tqdm(files, desc=\"Processing Fingerprints\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            if upscale:\n",
    "                process_fingerprint(input_path, output_path, upscale_factor=2.0)\n",
    "            else:\n",
    "                process_fingerprint(input_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {filename}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_FOLDER = \"../data/raw\"\n",
    "    OUTPUT_FOLDER = \"../data/processed\"\n",
    "    UPSCALE_IMAGES = True  # Set to True for 2x upscaling\n",
    "    \n",
    "    print(\"Starting fingerprint processing...\")\n",
    "    batch_process_fingerprints(INPUT_FOLDER, OUTPUT_FOLDER, upscale=UPSCALE_IMAGES)\n",
    "    print(\"\\nProcessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135fb8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)  # Ensures the same split every time you run the code\n",
    "\n",
    "# Define paths\n",
    "processed_dir  = \"../data/processed\"\n",
    "train_dir  = \"../data/final/train\"\n",
    "test_dir  = \"../data/final/test\"\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "finger_groups = defaultdict(list)\n",
    "\n",
    "for filename in sorted(os.listdir(processed_dir)):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\")):\n",
    "        continue\n",
    "    parts = filename.split(\"_\")\n",
    "    if len(parts) < 3:\n",
    "        continue\n",
    "    class_id = f\"{parts[0]}_{parts[1]}\" \n",
    "    finger_groups[class_id].append(filename)\n",
    "\n",
    "# Step 2: Move files into class folders for train/test\n",
    "for class_id, files in finger_groups.items():\n",
    "    files.sort(key=lambda f: int(f.split(\"_\")[2].split(\".\")[0]))  # Sort by image index\n",
    "\n",
    "    train_class_dir = os.path.join(train_dir, class_id)\n",
    "    test_class_dir = os.path.join(test_dir, class_id)\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        src = os.path.join(processed_dir, file)\n",
    "        if i < 6:\n",
    "            dst = os.path.join(train_class_dir, file)\n",
    "        else:\n",
    "            dst = os.path.join(test_class_dir, file)\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"Copied {file} → {'train' if i < 6 else 'test'}/{class_id}\")\n",
    "\n",
    "print(\"✅ Dataset split complete with subfolders as classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path configuration\n",
    "test_dir = \"../data/final/test/\"\n",
    "\n",
    "def apply_block_damage_smart(image, block_size=80, num_blocks=7):\n",
    "    \"\"\"Apply white block damage only on fingerprint area.\"\"\"\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape\n",
    "    mask = image < 250\n",
    "    ys, xs = np.where(mask)\n",
    "\n",
    "    if len(xs) == 0:\n",
    "        return damaged\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        idx = random.randint(0, len(xs) - 1)\n",
    "        x_center, y_center = xs[idx], ys[idx]\n",
    "        x1 = max(0, x_center - block_size // 2)\n",
    "        y1 = max(0, y_center - block_size // 2)\n",
    "        x2 = min(width, x1 + block_size)\n",
    "        y2 = min(height, y1 + block_size)\n",
    "        damaged[y1:y2, x1:x2] = 255\n",
    "    return damaged\n",
    "\n",
    "def apply_blur_damage(image, block_size=60, num_blocks=5):\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        x = random.randint(0, width - block_size)\n",
    "        y = random.randint(0, height - block_size)\n",
    "        roi = damaged[y:y+block_size, x:x+block_size]\n",
    "        blurred = cv2.GaussianBlur(roi, (11, 11), 0)\n",
    "        damaged[y:y+block_size, x:x+block_size] = blurred\n",
    "    return damaged\n",
    "\n",
    "def apply_elliptical_noise(image, num_ellipses=5):\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape\n",
    "\n",
    "    for _ in range(num_ellipses):\n",
    "        center = (\n",
    "            random.randint(0, width),\n",
    "            random.randint(0, height)\n",
    "        )\n",
    "        axes = (\n",
    "            random.randint(20, 60),  # X-axis radius\n",
    "            random.randint(10, 30)   # Y-axis radius\n",
    "        )\n",
    "        angle = random.randint(0, 180)\n",
    "        startAngle = 0\n",
    "        endAngle = 360\n",
    "        color = 255 \n",
    "        thickness = -1 \n",
    "\n",
    "        cv2.ellipse(damaged, center, axes, angle, startAngle, endAngle, color, thickness)\n",
    "    return damaged\n",
    "\n",
    "\n",
    "def apply_combined_damage(image):\n",
    "    \"\"\"Apply all three types of damage sequentially.\"\"\"\n",
    "    image = apply_block_damage_smart(image)\n",
    "    image = apply_blur_damage(image)\n",
    "    image = apply_elliptical_noise(image)\n",
    "    return image\n",
    "\n",
    "# Get all test images (.tif files)\n",
    "test_images = []\n",
    "for root, _, files in os.walk(test_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".tif\"):\n",
    "            test_images.append(os.path.join(root, file))\n",
    "print(f\"Found {len(test_images)} test images to process\")\n",
    "\n",
    "# Process and overwrite originals\n",
    "for image_path in tqdm(test_images, desc=\"Applying combined damage\"):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if image is not None:\n",
    "        damaged_image = apply_combined_damage(image)\n",
    "        cv2.imwrite(image_path, damaged_image)\n",
    "\n",
    "print(f\"\\nOverwritten {len(test_images)} images with combined damage in {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Rotate, ShiftScaleRotate, RandomBrightnessContrast,\n",
    "    CLAHE, GaussNoise, CoarseDropout, GridDistortion, ElasticTransform, MotionBlur\n",
    ")\n",
    "from PIL import Image\n",
    "\n",
    "train_dir = \"../data/final/train\"\n",
    "\n",
    "# Augmentation pipeline\n",
    "def get_augmentation_pipeline():\n",
    "    return Compose([\n",
    "        Rotate(limit=10, p=0.7),\n",
    "        ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        OneOf([\n",
    "            RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
    "            CLAHE(clip_limit=2.0, p=0.5)\n",
    "        ], p=0.6),\n",
    "        OneOf([\n",
    "            MotionBlur(blur_limit=(3, 7), p=0.5),\n",
    "            GaussNoise(var_limit=(10.0, 30.0), p=0.5),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            ElasticTransform(alpha=1, sigma=50, alpha_affine=30, p=0.3),\n",
    "            GridDistortion(num_steps=5, distort_limit=0.3, p=0.3)\n",
    "        ], p=0.4),\n",
    "        CoarseDropout(num_holes=1, max_h_size=16, max_w_size=16, fill_value=0, p=0.5)\n",
    "    ])\n",
    "\n",
    "def augment_and_save_images_in_place(input_dir, augmentations_per_image=5):\n",
    "    transform = get_augmentation_pipeline()\n",
    "\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for fname in tqdm(os.listdir(class_path), desc=f\"Augmenting {class_name}\"):\n",
    "            if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\")):\n",
    "                continue\n",
    "\n",
    "            fpath = os.path.join(class_path, fname)\n",
    "            img = cv2.imread(fpath, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            h, w = img.shape\n",
    "            img = img.reshape(h, w, 1)  \n",
    "\n",
    "            for i in range(augmentations_per_image):\n",
    "                augmented = transform(image=img)\n",
    "                aug_img = augmented[\"image\"]\n",
    "\n",
    "                aug_img = np.clip(aug_img, 0, 255).astype('uint8')\n",
    "\n",
    "                # Save image\n",
    "                aug_img_pil = Image.fromarray(aug_img.squeeze(), mode='L')\n",
    "                prefix = os.path.splitext(fname)[0]\n",
    "                save_path = os.path.join(class_path, f\"{prefix}_aug{i+1}.png\")\n",
    "                aug_img_pil.save(save_path)\n",
    "\n",
    "augment_and_save_images_in_place(train_dir, augmentations_per_image=5)\n",
    "print(\"✅ Augmentation with Albumentations done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e855c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/final/train\"\n",
    "test_dir  = \"../data/final/test\"\n",
    "\n",
    "print(\"\\n🔧 Selecting 20% of training images for damage...\")\n",
    "\n",
    "# Step 1: Gather all training image paths\n",
    "all_train_images = []\n",
    "for class_id in os.listdir(train_dir):\n",
    "    class_path = os.path.join(train_dir, class_id)\n",
    "    for fname in os.listdir(class_path):\n",
    "        if fname.lower().endswith('.tif'):\n",
    "            all_train_images.append((class_id, fname))\n",
    "\n",
    "# Step 2: Randomly select 20% of them\n",
    "num_to_damage = int(len(all_train_images) * 0.2)\n",
    "selected_for_damage = random.sample(all_train_images, num_to_damage)\n",
    "\n",
    "# Step 3: Apply damage and overwrite original images\n",
    "for class_id, fname in tqdm(selected_for_damage, desc=\"Applying damage to 20%\"):\n",
    "    class_folder = os.path.join(train_dir, class_id)\n",
    "    original_path = os.path.join(class_folder, fname)\n",
    "\n",
    "    # Read original image\n",
    "    img = cv2.imread(original_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        damaged_img = apply_combined_damage(img)\n",
    "        cv2.imwrite(original_path, damaged_img)  # Overwrite clean with damaged\n",
    "\n",
    "print(f\"\\n✅ Final training set: {len(all_train_images)} images total — {len(all_train_images) - num_to_damage} clean + {num_to_damage} damaged.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
