{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be44000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# raw_dir = \"../data/pre-raw\"\n",
    "output_dir = \"../data/raw\"  \n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.exists(raw_dir):\n",
    "    raw_dir = input(\"Input raw dataset directory:\")\n",
    "\n",
    "files = [f for f in os.listdir(raw_dir) if os.path.isfile(os.path.join(raw_dir, f))]\n",
    "files.sort()\n",
    "\n",
    "individu_finger_map = {}\n",
    "global_finger_serial = 1\n",
    "\n",
    "for file in files:\n",
    "    name, ext = os.path.splitext(file)\n",
    "    parts = name.split(\"_\")\n",
    "\n",
    "    if len(parts) != 3:\n",
    "        print(f\"Skipping invalid filename: {file}\")\n",
    "        continue\n",
    "\n",
    "    individu = parts[0]\n",
    "    finger_orig = int(parts[1])\n",
    "    scan = parts[2]\n",
    "\n",
    "    if individu not in individu_finger_map:\n",
    "        individu_finger_map[individu] = {}\n",
    "\n",
    "    if finger_orig not in individu_finger_map[individu]:\n",
    "        mapped_finger = global_finger_serial\n",
    "        individu_finger_map[individu][finger_orig] = mapped_finger\n",
    "        global_finger_serial += 1  \n",
    "    else:\n",
    "        mapped_finger = individu_finger_map[individu][finger_orig]\n",
    "\n",
    "    new_name = f\"{individu}_{mapped_finger}_{scan}{ext}\"\n",
    "\n",
    "    src_file = os.path.join(raw_dir, file)\n",
    "    dest_file = os.path.join(output_dir, new_name)\n",
    "\n",
    "    shutil.copy(src_file, dest_file)\n",
    "    print(f\"Copied: {file} → {new_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fingerprint processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Fingerprints: 100%|██████████| 2056/2056 [01:01<00:00, 33.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def skeletonize(img):\n",
    "    \"\"\"Alternative skeletonization implementation without ximgproc\"\"\"\n",
    "    skel = np.zeros(img.shape, np.uint8)\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "    while True:\n",
    "        open_img = cv2.morphologyEx(img, cv2.MORPH_OPEN, element)\n",
    "        temp = cv2.subtract(img, open_img)\n",
    "        eroded = cv2.erode(img, element)\n",
    "        skel = cv2.bitwise_or(skel, temp)\n",
    "        img = eroded.copy()\n",
    "        if cv2.countNonZero(img) == 0:\n",
    "            break\n",
    "    return skel\n",
    "\n",
    "def process_fingerprint(image_path, output_path, target_size=None, upscale_factor=1.0):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "    \n",
    "    # Resize if needed\n",
    "    if target_size:\n",
    "        image = cv2.resize(image, target_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    elif upscale_factor != 1.0:\n",
    "        h, w = image.shape\n",
    "        image = cv2.resize(image, (int(w*upscale_factor), int(h*upscale_factor)), \n",
    "                         interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    # 1. Contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(image)\n",
    "    \n",
    "    # 2. Noise reduction\n",
    "    denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
    "    \n",
    "    # 3. Adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY_INV, 21, 7)\n",
    "    \n",
    "    # 4. Morphological operations\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    # 5. Skeletonization (using alternative method)\n",
    "    skeleton = skeletonize(morph)\n",
    "    \n",
    "    # 6. Final inversion and saving\n",
    "    result = cv2.bitwise_not(skeleton)\n",
    "    cv2.imwrite(output_path, result)\n",
    "\n",
    "def batch_process_fingerprints(input_folder, output_folder, upscale=False):\n",
    "    \"\"\"\n",
    "    Process all fingerprints in a folder\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    files = [f for f in os.listdir(input_folder) if f.lower().endswith('.tif')]\n",
    "    \n",
    "    for filename in tqdm(files, desc=\"Processing Fingerprints\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            if upscale:\n",
    "                process_fingerprint(input_path, output_path, upscale_factor=2.0)\n",
    "            else:\n",
    "                process_fingerprint(input_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {filename}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_FOLDER = \"../data/raw\"\n",
    "    OUTPUT_FOLDER = \"../data/processed\"\n",
    "    UPSCALE_IMAGES = True  # Set to True for 2x upscaling\n",
    "    \n",
    "    print(\"Starting fingerprint processing...\")\n",
    "    batch_process_fingerprints(INPUT_FOLDER, OUTPUT_FOLDER, upscale=UPSCALE_IMAGES)\n",
    "    print(\"\\nProcessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135fb8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)  # Ensures the same split every time you run the code\n",
    "\n",
    "# Define paths\n",
    "processed_dir  = \"../data/processed\"\n",
    "train_dir  = \"../data/final/train\"\n",
    "test_dir  = \"../data/final/test\"\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "finger_groups = defaultdict(list)\n",
    "\n",
    "for filename in sorted(os.listdir(processed_dir)):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\")):\n",
    "        continue\n",
    "    parts = filename.split(\"_\")\n",
    "    if len(parts) < 3:\n",
    "        continue\n",
    "    class_id = f\"{parts[0]}_{parts[1]}\" \n",
    "    finger_groups[class_id].append(filename)\n",
    "\n",
    "# Step 2: Move files into class folders for train/test\n",
    "for class_id, files in finger_groups.items():\n",
    "    files.sort(key=lambda f: int(f.split(\"_\")[2].split(\".\")[0]))  # Sort by image index\n",
    "\n",
    "    train_class_dir = os.path.join(train_dir, class_id)\n",
    "    test_class_dir = os.path.join(test_dir, class_id)\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        src = os.path.join(processed_dir, file)\n",
    "        if i < 6:\n",
    "            dst = os.path.join(train_class_dir, file)\n",
    "        else:\n",
    "            dst = os.path.join(test_class_dir, file)\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"Copied {file} → {'train' if i < 6 else 'test'}/{class_id}\")\n",
    "\n",
    "print(\"✅ Dataset split complete with subfolders as classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17a267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 514 test images to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying combined damage: 100%|██████████| 514/514 [00:08<00:00, 59.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overwritten 514 images with combined damage in ../data/final/test/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path configuration\n",
    "test_dir = \"../data/final/test/\"\n",
    "\n",
    "def apply_block_damage_smart(image, block_size=80, num_blocks=7):\n",
    "    \"\"\"Apply white block damage only on fingerprint area.\"\"\"\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape\n",
    "    mask = image < 250\n",
    "    ys, xs = np.where(mask)\n",
    "\n",
    "    if len(xs) == 0:\n",
    "        return damaged\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        idx = random.randint(0, len(xs) - 1)\n",
    "        x_center, y_center = xs[idx], ys[idx]\n",
    "        x1 = max(0, x_center - block_size // 2)\n",
    "        y1 = max(0, y_center - block_size // 2)\n",
    "        x2 = min(width, x1 + block_size)\n",
    "        y2 = min(height, y1 + block_size)\n",
    "        damaged[y1:y2, x1:x2] = 255\n",
    "    return damaged\n",
    "\n",
    "def apply_blur_damage(image, block_size=60, num_blocks=5):\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        x = random.randint(0, width - block_size)\n",
    "        y = random.randint(0, height - block_size)\n",
    "        roi = damaged[y:y+block_size, x:x+block_size]\n",
    "        blurred = cv2.GaussianBlur(roi, (11, 11), 0)\n",
    "        damaged[y:y+block_size, x:x+block_size] = blurred\n",
    "    return damaged\n",
    "\n",
    "def apply_elliptical_noise(image, num_ellipses=5):\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape\n",
    "\n",
    "    for _ in range(num_ellipses):\n",
    "        center = (\n",
    "            random.randint(0, width),\n",
    "            random.randint(0, height)\n",
    "        )\n",
    "        axes = (\n",
    "            random.randint(20, 60),  # X-axis radius\n",
    "            random.randint(10, 30)   # Y-axis radius\n",
    "        )\n",
    "        angle = random.randint(0, 180)\n",
    "        startAngle = 0\n",
    "        endAngle = 360\n",
    "        color = 255 \n",
    "        thickness = -1 \n",
    "\n",
    "        cv2.ellipse(damaged, center, axes, angle, startAngle, endAngle, color, thickness)\n",
    "    return damaged\n",
    "\n",
    "\n",
    "def apply_combined_damage(image):\n",
    "    \"\"\"Apply all three types of damage sequentially.\"\"\"\n",
    "    image = apply_block_damage_smart(image)\n",
    "    image = apply_blur_damage(image)\n",
    "    image = apply_elliptical_noise(image)\n",
    "    return image\n",
    "\n",
    "# Get all test images (.tif files)\n",
    "test_images = []\n",
    "for root, _, files in os.walk(test_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".tif\"):\n",
    "            test_images.append(os.path.join(root, file))\n",
    "print(f\"Found {len(test_images)} test images to process\")\n",
    "\n",
    "# Process and overwrite originals\n",
    "for image_path in tqdm(test_images, desc=\"Applying combined damage\"):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if image is not None:\n",
    "        damaged_image = apply_combined_damage(image)\n",
    "        cv2.imwrite(image_path, damaged_image)\n",
    "\n",
    "print(f\"\\nOverwritten {len(test_images)} images with combined damage in {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e34d610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting 001_1: 100%|██████████| 6/6 [00:04<00:00,  1.24it/s]\n",
      "Augmenting 001_2: 100%|██████████| 6/6 [00:04<00:00,  1.27it/s]\n",
      "Augmenting 001_3: 100%|██████████| 6/6 [00:05<00:00,  1.18it/s]\n",
      "Augmenting 001_4: 100%|██████████| 6/6 [00:04<00:00,  1.27it/s]\n",
      "Augmenting 001_5: 100%|██████████| 6/6 [00:04<00:00,  1.31it/s]\n",
      "Augmenting 001_6: 100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n",
      "Augmenting 002_10: 100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n",
      "Augmenting 002_11: 100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n",
      "Augmenting 002_12: 100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n",
      "Augmenting 002_7: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]\n",
      "Augmenting 002_8: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]\n",
      "Augmenting 002_9: 100%|██████████| 6/6 [00:06<00:00,  1.07s/it]\n",
      "Augmenting 003_13: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n",
      "Augmenting 003_14: 100%|██████████| 6/6 [00:06<00:00,  1.06s/it]\n",
      "Augmenting 003_15: 100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n",
      "Augmenting 003_16: 100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n",
      "Augmenting 003_17: 100%|██████████| 6/6 [00:06<00:00,  1.04s/it]\n",
      "Augmenting 003_18: 100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n",
      "Augmenting 004_19: 100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n",
      "Augmenting 004_20: 100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n",
      "Augmenting 004_21: 100%|██████████| 6/6 [00:05<00:00,  1.09it/s]\n",
      "Augmenting 004_22: 100%|██████████| 6/6 [00:05<00:00,  1.18it/s]\n",
      "Augmenting 004_23: 100%|██████████| 6/6 [00:05<00:00,  1.17it/s]\n",
      "Augmenting 004_24: 100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n",
      "Augmenting 005_25: 100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n",
      "Augmenting 005_26: 100%|██████████| 6/6 [00:06<00:00,  1.09s/it]\n",
      "Augmenting 005_27: 100%|██████████| 6/6 [00:06<00:00,  1.12s/it]\n",
      "Augmenting 005_28: 100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n",
      "Augmenting 005_29: 100%|██████████| 6/6 [00:06<00:00,  1.16s/it]\n",
      "Augmenting 005_30: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n",
      "Augmenting 006_31: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]\n",
      "Augmenting 006_32: 100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n",
      "Augmenting 006_33: 100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n",
      "Augmenting 006_34: 100%|██████████| 6/6 [00:06<00:00,  1.06s/it]\n",
      "Augmenting 006_35: 100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n",
      "Augmenting 006_36: 100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n",
      "Augmenting 007_37: 100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n",
      "Augmenting 007_38: 100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n",
      "Augmenting 007_39: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]\n",
      "Augmenting 007_40: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]\n",
      "Augmenting 007_41: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
      "Augmenting 007_42: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
      "Augmenting 008_43: 100%|██████████| 6/6 [00:04<00:00,  1.23it/s]\n",
      "Augmenting 008_44: 100%|██████████| 6/6 [00:04<00:00,  1.30it/s]\n",
      "Augmenting 008_45: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
      "Augmenting 009_46: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
      "Augmenting 009_47: 100%|██████████| 6/6 [00:04<00:00,  1.39it/s]\n",
      "Augmenting 009_48: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n",
      "Augmenting 009_49: 100%|██████████| 6/6 [00:04<00:00,  1.33it/s]\n",
      "Augmenting 009_50: 100%|██████████| 6/6 [00:04<00:00,  1.35it/s]\n",
      "Augmenting 009_51: 100%|██████████| 6/6 [00:04<00:00,  1.26it/s]\n",
      "Augmenting 010_52: 100%|██████████| 6/6 [00:02<00:00,  2.65it/s]\n",
      "Augmenting 010_53: 100%|██████████| 6/6 [00:02<00:00,  2.93it/s]\n",
      "Augmenting 010_54: 100%|██████████| 6/6 [00:02<00:00,  2.52it/s]\n",
      "Augmenting 010_55: 100%|██████████| 6/6 [00:02<00:00,  2.58it/s]\n",
      "Augmenting 010_56: 100%|██████████| 6/6 [00:02<00:00,  2.91it/s]\n",
      "Augmenting 010_57: 100%|██████████| 6/6 [00:02<00:00,  2.65it/s]\n",
      "Augmenting 010_58: 100%|██████████| 6/6 [00:02<00:00,  2.59it/s]\n",
      "Augmenting 010_59: 100%|██████████| 6/6 [00:02<00:00,  2.61it/s]\n",
      "Augmenting 010_60: 100%|██████████| 6/6 [00:02<00:00,  2.72it/s]\n",
      "Augmenting 010_61: 100%|██████████| 6/6 [00:02<00:00,  2.81it/s]\n",
      "Augmenting 011_62: 100%|██████████| 6/6 [00:02<00:00,  2.88it/s]\n",
      "Augmenting 011_63: 100%|██████████| 6/6 [00:02<00:00,  2.85it/s]\n",
      "Augmenting 011_64: 100%|██████████| 6/6 [00:02<00:00,  2.69it/s]\n",
      "Augmenting 011_65: 100%|██████████| 6/6 [00:02<00:00,  2.60it/s]\n",
      "Augmenting 011_66: 100%|██████████| 6/6 [00:02<00:00,  2.70it/s]\n",
      "Augmenting 011_67: 100%|██████████| 6/6 [00:02<00:00,  2.50it/s]\n",
      "Augmenting 011_68: 100%|██████████| 6/6 [00:02<00:00,  2.67it/s]\n",
      "Augmenting 011_69: 100%|██████████| 6/6 [00:02<00:00,  2.41it/s]\n",
      "Augmenting 011_70: 100%|██████████| 6/6 [00:02<00:00,  2.56it/s]\n",
      "Augmenting 011_71: 100%|██████████| 6/6 [00:02<00:00,  2.57it/s]\n",
      "Augmenting 012_72: 100%|██████████| 6/6 [00:02<00:00,  2.58it/s]\n",
      "Augmenting 012_73: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s]\n",
      "Augmenting 012_74: 100%|██████████| 6/6 [00:02<00:00,  2.89it/s]\n",
      "Augmenting 012_75: 100%|██████████| 6/6 [00:02<00:00,  2.99it/s]\n",
      "Augmenting 012_76: 100%|██████████| 6/6 [00:02<00:00,  2.55it/s]\n",
      "Augmenting 012_77: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s]\n",
      "Augmenting 012_78: 100%|██████████| 6/6 [00:02<00:00,  2.34it/s]\n",
      "Augmenting 012_79: 100%|██████████| 6/6 [00:02<00:00,  2.03it/s]\n",
      "Augmenting 012_80: 100%|██████████| 6/6 [00:02<00:00,  2.07it/s]\n",
      "Augmenting 012_81: 100%|██████████| 6/6 [00:02<00:00,  2.10it/s]\n",
      "Augmenting 013_82: 100%|██████████| 6/6 [00:02<00:00,  2.05it/s]\n",
      "Augmenting 013_83: 100%|██████████| 6/6 [00:02<00:00,  2.08it/s]\n",
      "Augmenting 013_84: 100%|██████████| 6/6 [00:02<00:00,  2.01it/s]\n",
      "Augmenting 013_85: 100%|██████████| 6/6 [00:02<00:00,  2.14it/s]\n",
      "Augmenting 013_86: 100%|██████████| 6/6 [00:03<00:00,  1.98it/s]\n",
      "Augmenting 013_87: 100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
      "Augmenting 013_88: 100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n",
      "Augmenting 013_89: 100%|██████████| 6/6 [00:02<00:00,  2.09it/s]\n",
      "Augmenting 013_90: 100%|██████████| 6/6 [00:02<00:00,  2.05it/s]\n",
      "Augmenting 013_91: 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Augmenting 014_100: 100%|██████████| 6/6 [00:03<00:00,  1.83it/s]\n",
      "Augmenting 014_101: 100%|██████████| 6/6 [00:02<00:00,  2.08it/s]\n",
      "Augmenting 014_92: 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Augmenting 014_93: 100%|██████████| 6/6 [00:03<00:00,  1.82it/s]\n",
      "Augmenting 014_94: 100%|██████████| 6/6 [00:02<00:00,  2.05it/s]\n",
      "Augmenting 014_95: 100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\n",
      "Augmenting 014_96: 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Augmenting 014_97: 100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n",
      "Augmenting 014_98: 100%|██████████| 6/6 [00:03<00:00,  1.68it/s]\n",
      "Augmenting 014_99: 100%|██████████| 6/6 [00:03<00:00,  1.69it/s]\n",
      "Augmenting 015_102: 100%|██████████| 6/6 [00:03<00:00,  1.73it/s]\n",
      "Augmenting 015_103: 100%|██████████| 6/6 [00:03<00:00,  1.72it/s]\n",
      "Augmenting 015_104: 100%|██████████| 6/6 [00:02<00:00,  2.39it/s]\n",
      "Augmenting 015_105: 100%|██████████| 6/6 [00:02<00:00,  2.95it/s]\n",
      "Augmenting 015_106: 100%|██████████| 6/6 [00:02<00:00,  2.69it/s]\n",
      "Augmenting 016_107: 100%|██████████| 6/6 [00:02<00:00,  2.81it/s]\n",
      "Augmenting 016_108: 100%|██████████| 6/6 [00:02<00:00,  2.57it/s]\n",
      "Augmenting 016_109: 100%|██████████| 6/6 [00:02<00:00,  2.64it/s]\n",
      "Augmenting 016_110: 100%|██████████| 6/6 [00:02<00:00,  2.80it/s]\n",
      "Augmenting 016_111: 100%|██████████| 6/6 [00:02<00:00,  2.77it/s]\n",
      "Augmenting 016_112: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Augmenting 016_113: 100%|██████████| 6/6 [00:02<00:00,  2.62it/s]\n",
      "Augmenting 016_114: 100%|██████████| 6/6 [00:02<00:00,  2.69it/s]\n",
      "Augmenting 016_115: 100%|██████████| 6/6 [00:02<00:00,  2.52it/s]\n",
      "Augmenting 016_116: 100%|██████████| 6/6 [00:02<00:00,  2.52it/s]\n",
      "Augmenting 017_117: 100%|██████████| 6/6 [00:01<00:00,  3.54it/s]\n",
      "Augmenting 017_118: 100%|██████████| 6/6 [00:01<00:00,  3.30it/s]\n",
      "Augmenting 017_119: 100%|██████████| 6/6 [00:01<00:00,  3.50it/s]\n",
      "Augmenting 017_120: 100%|██████████| 6/6 [00:01<00:00,  3.23it/s]\n",
      "Augmenting 017_121: 100%|██████████| 6/6 [00:01<00:00,  3.27it/s]\n",
      "Augmenting 017_122: 100%|██████████| 6/6 [00:01<00:00,  3.42it/s]\n",
      "Augmenting 017_123: 100%|██████████| 6/6 [00:01<00:00,  3.45it/s]\n",
      "Augmenting 017_124: 100%|██████████| 6/6 [00:01<00:00,  3.11it/s]\n",
      "Augmenting 017_125: 100%|██████████| 6/6 [00:01<00:00,  3.77it/s]\n",
      "Augmenting 017_126: 100%|██████████| 6/6 [00:01<00:00,  3.53it/s]\n",
      "Augmenting 018_127: 100%|██████████| 6/6 [00:01<00:00,  3.32it/s]\n",
      "Augmenting 018_128: 100%|██████████| 6/6 [00:01<00:00,  3.46it/s]\n",
      "Augmenting 018_129: 100%|██████████| 6/6 [00:01<00:00,  3.20it/s]\n",
      "Augmenting 018_130: 100%|██████████| 6/6 [00:01<00:00,  3.45it/s]\n",
      "Augmenting 018_131: 100%|██████████| 6/6 [00:01<00:00,  3.42it/s]\n",
      "Augmenting 018_132: 100%|██████████| 6/6 [00:01<00:00,  3.11it/s]\n",
      "Augmenting 018_133: 100%|██████████| 6/6 [00:01<00:00,  3.49it/s]\n",
      "Augmenting 018_134: 100%|██████████| 6/6 [00:01<00:00,  3.28it/s]\n",
      "Augmenting 018_135: 100%|██████████| 6/6 [00:01<00:00,  3.70it/s]\n",
      "Augmenting 018_136: 100%|██████████| 6/6 [00:01<00:00,  3.44it/s]\n",
      "Augmenting 019_137: 100%|██████████| 6/6 [00:03<00:00,  1.54it/s]\n",
      "Augmenting 019_138: 100%|██████████| 6/6 [00:03<00:00,  1.51it/s]\n",
      "Augmenting 019_139: 100%|██████████| 6/6 [00:03<00:00,  1.57it/s]\n",
      "Augmenting 019_140: 100%|██████████| 6/6 [00:03<00:00,  1.66it/s]\n",
      "Augmenting 019_141: 100%|██████████| 6/6 [00:04<00:00,  1.41it/s]\n",
      "Augmenting 019_142: 100%|██████████| 6/6 [00:04<00:00,  1.49it/s]\n",
      "Augmenting 019_143: 100%|██████████| 6/6 [00:04<00:00,  1.35it/s]\n",
      "Augmenting 019_144: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n",
      "Augmenting 019_145: 100%|██████████| 6/6 [00:05<00:00,  1.11it/s]\n",
      "Augmenting 019_146: 100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n",
      "Augmenting 020_147: 100%|██████████| 6/6 [00:02<00:00,  2.64it/s]\n",
      "Augmenting 020_148: 100%|██████████| 6/6 [00:02<00:00,  2.84it/s]\n",
      "Augmenting 020_149: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Augmenting 020_150: 100%|██████████| 6/6 [00:02<00:00,  2.58it/s]\n",
      "Augmenting 020_151: 100%|██████████| 6/6 [00:02<00:00,  2.86it/s]\n",
      "Augmenting 020_152: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Augmenting 020_153: 100%|██████████| 6/6 [00:02<00:00,  2.61it/s]\n",
      "Augmenting 020_154: 100%|██████████| 6/6 [00:02<00:00,  2.71it/s]\n",
      "Augmenting 020_155: 100%|██████████| 6/6 [00:01<00:00,  4.03it/s]\n",
      "Augmenting 020_156: 100%|██████████| 6/6 [00:01<00:00,  3.89it/s]\n",
      "Augmenting 021_157: 100%|██████████| 6/6 [00:02<00:00,  2.11it/s]\n",
      "Augmenting 021_158: 100%|██████████| 6/6 [00:02<00:00,  2.40it/s]\n",
      "Augmenting 021_159: 100%|██████████| 6/6 [00:02<00:00,  2.48it/s]\n",
      "Augmenting 021_160: 100%|██████████| 6/6 [00:02<00:00,  2.06it/s]\n",
      "Augmenting 021_161: 100%|██████████| 6/6 [00:02<00:00,  2.33it/s]\n",
      "Augmenting 021_162: 100%|██████████| 6/6 [00:02<00:00,  2.29it/s]\n",
      "Augmenting 021_163: 100%|██████████| 6/6 [00:02<00:00,  2.10it/s]\n",
      "Augmenting 021_164: 100%|██████████| 6/6 [00:02<00:00,  2.21it/s]\n",
      "Augmenting 021_165: 100%|██████████| 6/6 [00:02<00:00,  2.11it/s]\n",
      "Augmenting 021_166: 100%|██████████| 6/6 [00:02<00:00,  2.63it/s]\n",
      "Augmenting 022_167: 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Augmenting 022_168: 100%|██████████| 6/6 [00:02<00:00,  2.01it/s]\n",
      "Augmenting 022_169: 100%|██████████| 6/6 [00:03<00:00,  1.80it/s]\n",
      "Augmenting 022_170: 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "Augmenting 022_171: 100%|██████████| 6/6 [00:03<00:00,  1.52it/s]\n",
      "Augmenting 022_172: 100%|██████████| 6/6 [00:04<00:00,  1.40it/s]\n",
      "Augmenting 022_173: 100%|██████████| 6/6 [00:04<00:00,  1.48it/s]\n",
      "Augmenting 022_174: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n",
      "Augmenting 022_175: 100%|██████████| 6/6 [00:04<00:00,  1.24it/s]\n",
      "Augmenting 022_176: 100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
      "Augmenting 023_177: 100%|██████████| 6/6 [00:02<00:00,  2.50it/s]\n",
      "Augmenting 023_178: 100%|██████████| 6/6 [00:02<00:00,  2.69it/s]\n",
      "Augmenting 023_179: 100%|██████████| 6/6 [00:02<00:00,  2.61it/s]\n",
      "Augmenting 023_180: 100%|██████████| 6/6 [00:02<00:00,  2.68it/s]\n",
      "Augmenting 023_181: 100%|██████████| 6/6 [00:02<00:00,  2.81it/s]\n",
      "Augmenting 023_182: 100%|██████████| 6/6 [00:02<00:00,  2.62it/s]\n",
      "Augmenting 023_183: 100%|██████████| 6/6 [00:02<00:00,  2.93it/s]\n",
      "Augmenting 023_184: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Augmenting 023_185: 100%|██████████| 6/6 [00:02<00:00,  2.48it/s]\n",
      "Augmenting 023_186: 100%|██████████| 6/6 [00:02<00:00,  2.76it/s]\n",
      "Augmenting 024_187: 100%|██████████| 6/6 [00:02<00:00,  2.27it/s]\n",
      "Augmenting 024_188: 100%|██████████| 6/6 [00:02<00:00,  2.16it/s]\n",
      "Augmenting 024_189: 100%|██████████| 6/6 [00:02<00:00,  2.12it/s]\n",
      "Augmenting 024_190: 100%|██████████| 6/6 [00:02<00:00,  2.17it/s]\n",
      "Augmenting 024_191: 100%|██████████| 6/6 [00:02<00:00,  2.20it/s]\n",
      "Augmenting 024_192: 100%|██████████| 6/6 [00:02<00:00,  2.38it/s]\n",
      "Augmenting 024_193: 100%|██████████| 6/6 [00:02<00:00,  2.29it/s]\n",
      "Augmenting 024_194: 100%|██████████| 6/6 [00:02<00:00,  2.09it/s]\n",
      "Augmenting 024_195: 100%|██████████| 6/6 [00:02<00:00,  2.14it/s]\n",
      "Augmenting 024_196: 100%|██████████| 6/6 [00:02<00:00,  2.25it/s]\n",
      "Augmenting 025_197: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n",
      "Augmenting 025_198: 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n",
      "Augmenting 025_199: 100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n",
      "Augmenting 025_200: 100%|██████████| 6/6 [00:07<00:00,  1.33s/it]\n",
      "Augmenting 025_201: 100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
      "Augmenting 025_202: 100%|██████████| 6/6 [00:08<00:00,  1.39s/it]\n",
      "Augmenting 025_203: 100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n",
      "Augmenting 025_204: 100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n",
      "Augmenting 025_205: 100%|██████████| 6/6 [00:05<00:00,  1.16it/s]\n",
      "Augmenting 025_206: 100%|██████████| 6/6 [00:05<00:00,  1.17it/s]\n",
      "Augmenting 026_207: 100%|██████████| 6/6 [00:02<00:00,  2.47it/s]\n",
      "Augmenting 026_208: 100%|██████████| 6/6 [00:02<00:00,  2.88it/s]\n",
      "Augmenting 026_209: 100%|██████████| 6/6 [00:02<00:00,  2.69it/s]\n",
      "Augmenting 026_210: 100%|██████████| 6/6 [00:02<00:00,  2.76it/s]\n",
      "Augmenting 026_211: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Augmenting 026_212: 100%|██████████| 6/6 [00:02<00:00,  2.90it/s]\n",
      "Augmenting 026_213: 100%|██████████| 6/6 [00:01<00:00,  3.07it/s]\n",
      "Augmenting 026_214: 100%|██████████| 6/6 [00:02<00:00,  2.69it/s]\n",
      "Augmenting 026_215: 100%|██████████| 6/6 [00:02<00:00,  3.00it/s]\n",
      "Augmenting 026_216: 100%|██████████| 6/6 [00:02<00:00,  2.61it/s]\n",
      "Augmenting 027_217: 100%|██████████| 6/6 [00:02<00:00,  2.26it/s]\n",
      "Augmenting 027_218: 100%|██████████| 6/6 [00:02<00:00,  2.26it/s]\n",
      "Augmenting 027_219: 100%|██████████| 6/6 [00:02<00:00,  2.32it/s]\n",
      "Augmenting 027_220: 100%|██████████| 6/6 [00:02<00:00,  2.40it/s]\n",
      "Augmenting 027_221: 100%|██████████| 6/6 [00:02<00:00,  2.15it/s]\n",
      "Augmenting 027_222: 100%|██████████| 6/6 [00:02<00:00,  2.27it/s]\n",
      "Augmenting 027_223: 100%|██████████| 6/6 [00:02<00:00,  2.23it/s]\n",
      "Augmenting 027_224: 100%|██████████| 6/6 [00:02<00:00,  2.24it/s]\n",
      "Augmenting 027_225: 100%|██████████| 6/6 [00:02<00:00,  2.27it/s]\n",
      "Augmenting 027_226: 100%|██████████| 6/6 [00:02<00:00,  2.09it/s]\n",
      "Augmenting 028_227: 100%|██████████| 6/6 [00:02<00:00,  2.91it/s]\n",
      "Augmenting 028_228: 100%|██████████| 6/6 [00:02<00:00,  2.60it/s]\n",
      "Augmenting 028_229: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Augmenting 028_230: 100%|██████████| 6/6 [00:02<00:00,  2.76it/s]\n",
      "Augmenting 028_231: 100%|██████████| 6/6 [00:02<00:00,  2.85it/s]\n",
      "Augmenting 028_232: 100%|██████████| 6/6 [00:02<00:00,  2.68it/s]\n",
      "Augmenting 028_233: 100%|██████████| 6/6 [00:02<00:00,  2.78it/s]\n",
      "Augmenting 028_234: 100%|██████████| 6/6 [00:02<00:00,  2.79it/s]\n",
      "Augmenting 028_235: 100%|██████████| 6/6 [00:02<00:00,  2.77it/s]\n",
      "Augmenting 028_236: 100%|██████████| 6/6 [00:01<00:00,  3.03it/s]\n",
      "Augmenting 029_237: 100%|██████████| 6/6 [00:01<00:00,  4.77it/s]\n",
      "Augmenting 029_238: 100%|██████████| 6/6 [00:01<00:00,  4.86it/s]\n",
      "Augmenting 029_239: 100%|██████████| 6/6 [00:01<00:00,  4.76it/s]\n",
      "Augmenting 029_240: 100%|██████████| 6/6 [00:01<00:00,  4.70it/s]\n",
      "Augmenting 029_241: 100%|██████████| 6/6 [00:01<00:00,  4.80it/s]\n",
      "Augmenting 029_242: 100%|██████████| 6/6 [00:01<00:00,  4.73it/s]\n",
      "Augmenting 029_243: 100%|██████████| 6/6 [00:01<00:00,  5.00it/s]\n",
      "Augmenting 029_244: 100%|██████████| 6/6 [00:01<00:00,  4.76it/s]\n",
      "Augmenting 030_245: 100%|██████████| 6/6 [00:01<00:00,  4.60it/s]\n",
      "Augmenting 030_246: 100%|██████████| 6/6 [00:01<00:00,  4.69it/s]\n",
      "Augmenting 030_247: 100%|██████████| 6/6 [00:01<00:00,  4.67it/s]\n",
      "Augmenting 030_248: 100%|██████████| 6/6 [00:01<00:00,  4.91it/s]\n",
      "Augmenting 030_249: 100%|██████████| 6/6 [00:01<00:00,  4.69it/s]\n",
      "Augmenting 030_250: 100%|██████████| 6/6 [00:01<00:00,  4.46it/s]\n",
      "Augmenting 030_251: 100%|██████████| 6/6 [00:01<00:00,  4.83it/s]\n",
      "Augmenting 030_252: 100%|██████████| 6/6 [00:01<00:00,  4.52it/s]\n",
      "Augmenting 031_253: 100%|██████████| 6/6 [00:01<00:00,  4.43it/s]\n",
      "Augmenting 031_254: 100%|██████████| 6/6 [00:01<00:00,  5.04it/s]\n",
      "Augmenting 031_255: 100%|██████████| 6/6 [00:01<00:00,  4.49it/s]\n",
      "Augmenting 031_256: 100%|██████████| 6/6 [00:01<00:00,  5.18it/s]\n",
      "Augmenting 031_257: 100%|██████████| 6/6 [00:01<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Augmentation done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Rotate, ShiftScaleRotate, RandomBrightnessContrast,\n",
    "    CLAHE, GaussNoise, CoarseDropout, GridDistortion, ElasticTransform, MotionBlur\n",
    ")\n",
    "from PIL import Image\n",
    "\n",
    "train_dir = \"../data/final/train\"\n",
    "\n",
    "# Augmentation pipeline\n",
    "def get_augmentation_pipeline():\n",
    "    return Compose([\n",
    "        Rotate(limit=10, p=0.7),\n",
    "        ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        OneOf([\n",
    "            RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
    "            CLAHE(clip_limit=2.0, p=0.5)\n",
    "        ], p=0.6),\n",
    "        OneOf([\n",
    "            MotionBlur(blur_limit=(3, 7), p=0.5),\n",
    "            GaussNoise(var_limit=(10.0, 30.0), p=0.5),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            ElasticTransform(alpha=1, sigma=50, alpha_affine=30, p=0.3),\n",
    "            GridDistortion(num_steps=5, distort_limit=0.3, p=0.3)\n",
    "        ], p=0.4),\n",
    "        CoarseDropout(num_holes=1, max_h_size=16, max_w_size=16, fill_value=0, p=0.5)\n",
    "    ])\n",
    "\n",
    "def augment_and_save_images_in_place(input_dir, augmentations_per_image=5):\n",
    "    transform = get_augmentation_pipeline()\n",
    "\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for fname in tqdm(os.listdir(class_path), desc=f\"Augmenting {class_name}\"):\n",
    "            if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\")):\n",
    "                continue\n",
    "\n",
    "            fpath = os.path.join(class_path, fname)\n",
    "            img = cv2.imread(fpath, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            h, w = img.shape\n",
    "            img = img.reshape(h, w, 1)  \n",
    "\n",
    "            for i in range(augmentations_per_image):\n",
    "                augmented = transform(image=img)\n",
    "                aug_img = augmented[\"image\"]\n",
    "\n",
    "                aug_img = np.clip(aug_img, 0, 255).astype('uint8')\n",
    "\n",
    "                # Save image\n",
    "                aug_img_pil = Image.fromarray(aug_img.squeeze(), mode='L')\n",
    "                prefix = os.path.splitext(fname)[0]\n",
    "                save_path = os.path.join(class_path, f\"{prefix}_aug{i+1}.png\")\n",
    "                aug_img_pil.save(save_path)\n",
    "\n",
    "augment_and_save_images_in_place(train_dir, augmentations_per_image=5)\n",
    "print(\"✅ Augmentation with Albumentations done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e855c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Applying damage per class in training dataset...\n",
      "Class 001_1: 27 clean + 9 damaged\n",
      "Class 001_2: 27 clean + 9 damaged\n",
      "Class 001_3: 27 clean + 9 damaged\n",
      "Class 001_4: 27 clean + 9 damaged\n",
      "Class 001_5: 27 clean + 9 damaged\n",
      "Class 001_6: 27 clean + 9 damaged\n",
      "Class 002_10: 27 clean + 9 damaged\n",
      "Class 002_11: 27 clean + 9 damaged\n",
      "Class 002_12: 27 clean + 9 damaged\n",
      "Class 002_7: 27 clean + 9 damaged\n",
      "Class 002_8: 27 clean + 9 damaged\n",
      "Class 002_9: 27 clean + 9 damaged\n",
      "Class 003_13: 27 clean + 9 damaged\n",
      "Class 003_14: 27 clean + 9 damaged\n",
      "Class 003_15: 27 clean + 9 damaged\n",
      "Class 003_16: 27 clean + 9 damaged\n",
      "Class 003_17: 27 clean + 9 damaged\n",
      "Class 003_18: 27 clean + 9 damaged\n",
      "Class 004_19: 27 clean + 9 damaged\n",
      "Class 004_20: 27 clean + 9 damaged\n",
      "Class 004_21: 27 clean + 9 damaged\n",
      "Class 004_22: 27 clean + 9 damaged\n",
      "Class 004_23: 27 clean + 9 damaged\n",
      "Class 004_24: 27 clean + 9 damaged\n",
      "Class 005_25: 27 clean + 9 damaged\n",
      "Class 005_26: 27 clean + 9 damaged\n",
      "Class 005_27: 27 clean + 9 damaged\n",
      "Class 005_28: 27 clean + 9 damaged\n",
      "Class 005_29: 27 clean + 9 damaged\n",
      "Class 005_30: 27 clean + 9 damaged\n",
      "Class 006_31: 27 clean + 9 damaged\n",
      "Class 006_32: 27 clean + 9 damaged\n",
      "Class 006_33: 27 clean + 9 damaged\n",
      "Class 006_34: 27 clean + 9 damaged\n",
      "Class 006_35: 27 clean + 9 damaged\n",
      "Class 006_36: 27 clean + 9 damaged\n",
      "Class 007_37: 27 clean + 9 damaged\n",
      "Class 007_38: 27 clean + 9 damaged\n",
      "Class 007_39: 27 clean + 9 damaged\n",
      "Class 007_40: 27 clean + 9 damaged\n",
      "Class 007_41: 27 clean + 9 damaged\n",
      "Class 007_42: 27 clean + 9 damaged\n",
      "Class 008_43: 27 clean + 9 damaged\n",
      "Class 008_44: 27 clean + 9 damaged\n",
      "Class 008_45: 27 clean + 9 damaged\n",
      "Class 009_46: 27 clean + 9 damaged\n",
      "Class 009_47: 27 clean + 9 damaged\n",
      "Class 009_48: 27 clean + 9 damaged\n",
      "Class 009_49: 27 clean + 9 damaged\n",
      "Class 009_50: 27 clean + 9 damaged\n",
      "Class 009_51: 27 clean + 9 damaged\n",
      "Class 010_52: 27 clean + 9 damaged\n",
      "Class 010_53: 27 clean + 9 damaged\n",
      "Class 010_54: 27 clean + 9 damaged\n",
      "Class 010_55: 27 clean + 9 damaged\n",
      "Class 010_56: 27 clean + 9 damaged\n",
      "Class 010_57: 27 clean + 9 damaged\n",
      "Class 010_58: 27 clean + 9 damaged\n",
      "Class 010_59: 27 clean + 9 damaged\n",
      "Class 010_60: 27 clean + 9 damaged\n",
      "Class 010_61: 27 clean + 9 damaged\n",
      "Class 011_62: 27 clean + 9 damaged\n",
      "Class 011_63: 27 clean + 9 damaged\n",
      "Class 011_64: 27 clean + 9 damaged\n",
      "Class 011_65: 27 clean + 9 damaged\n",
      "Class 011_66: 27 clean + 9 damaged\n",
      "Class 011_67: 27 clean + 9 damaged\n",
      "Class 011_68: 27 clean + 9 damaged\n",
      "Class 011_69: 27 clean + 9 damaged\n",
      "Class 011_70: 27 clean + 9 damaged\n",
      "Class 011_71: 27 clean + 9 damaged\n",
      "Class 012_72: 27 clean + 9 damaged\n",
      "Class 012_73: 27 clean + 9 damaged\n",
      "Class 012_74: 27 clean + 9 damaged\n",
      "Class 012_75: 27 clean + 9 damaged\n",
      "Class 012_76: 27 clean + 9 damaged\n",
      "Class 012_77: 27 clean + 9 damaged\n",
      "Class 012_78: 27 clean + 9 damaged\n",
      "Class 012_79: 27 clean + 9 damaged\n",
      "Class 012_80: 27 clean + 9 damaged\n",
      "Class 012_81: 27 clean + 9 damaged\n",
      "Class 013_82: 27 clean + 9 damaged\n",
      "Class 013_83: 27 clean + 9 damaged\n",
      "Class 013_84: 27 clean + 9 damaged\n",
      "Class 013_85: 27 clean + 9 damaged\n",
      "Class 013_86: 27 clean + 9 damaged\n",
      "Class 013_87: 27 clean + 9 damaged\n",
      "Class 013_88: 27 clean + 9 damaged\n",
      "Class 013_89: 27 clean + 9 damaged\n",
      "Class 013_90: 27 clean + 9 damaged\n",
      "Class 013_91: 27 clean + 9 damaged\n",
      "Class 014_100: 27 clean + 9 damaged\n",
      "Class 014_101: 27 clean + 9 damaged\n",
      "Class 014_92: 27 clean + 9 damaged\n",
      "Class 014_93: 27 clean + 9 damaged\n",
      "Class 014_94: 27 clean + 9 damaged\n",
      "Class 014_95: 27 clean + 9 damaged\n",
      "Class 014_96: 27 clean + 9 damaged\n",
      "Class 014_97: 27 clean + 9 damaged\n",
      "Class 014_98: 27 clean + 9 damaged\n",
      "Class 014_99: 27 clean + 9 damaged\n",
      "Class 015_102: 27 clean + 9 damaged\n",
      "Class 015_103: 27 clean + 9 damaged\n",
      "Class 015_104: 27 clean + 9 damaged\n",
      "Class 015_105: 27 clean + 9 damaged\n",
      "Class 015_106: 27 clean + 9 damaged\n",
      "Class 016_107: 27 clean + 9 damaged\n",
      "Class 016_108: 27 clean + 9 damaged\n",
      "Class 016_109: 27 clean + 9 damaged\n",
      "Class 016_110: 27 clean + 9 damaged\n",
      "Class 016_111: 27 clean + 9 damaged\n",
      "Class 016_112: 27 clean + 9 damaged\n",
      "Class 016_113: 27 clean + 9 damaged\n",
      "Class 016_114: 27 clean + 9 damaged\n",
      "Class 016_115: 27 clean + 9 damaged\n",
      "Class 016_116: 27 clean + 9 damaged\n",
      "Class 017_117: 27 clean + 9 damaged\n",
      "Class 017_118: 27 clean + 9 damaged\n",
      "Class 017_119: 27 clean + 9 damaged\n",
      "Class 017_120: 27 clean + 9 damaged\n",
      "Class 017_121: 27 clean + 9 damaged\n",
      "Class 017_122: 27 clean + 9 damaged\n",
      "Class 017_123: 27 clean + 9 damaged\n",
      "Class 017_124: 27 clean + 9 damaged\n",
      "Class 017_125: 27 clean + 9 damaged\n",
      "Class 017_126: 27 clean + 9 damaged\n",
      "Class 018_127: 27 clean + 9 damaged\n",
      "Class 018_128: 27 clean + 9 damaged\n",
      "Class 018_129: 27 clean + 9 damaged\n",
      "Class 018_130: 27 clean + 9 damaged\n",
      "Class 018_131: 27 clean + 9 damaged\n",
      "Class 018_132: 27 clean + 9 damaged\n",
      "Class 018_133: 27 clean + 9 damaged\n",
      "Class 018_134: 27 clean + 9 damaged\n",
      "Class 018_135: 27 clean + 9 damaged\n",
      "Class 018_136: 27 clean + 9 damaged\n",
      "Class 019_137: 27 clean + 9 damaged\n",
      "Class 019_138: 27 clean + 9 damaged\n",
      "Class 019_139: 27 clean + 9 damaged\n",
      "Class 019_140: 27 clean + 9 damaged\n",
      "Class 019_141: 27 clean + 9 damaged\n",
      "Class 019_142: 27 clean + 9 damaged\n",
      "Class 019_143: 27 clean + 9 damaged\n",
      "Class 019_144: 27 clean + 9 damaged\n",
      "Class 019_145: 27 clean + 9 damaged\n",
      "Class 019_146: 27 clean + 9 damaged\n",
      "Class 020_147: 27 clean + 9 damaged\n",
      "Class 020_148: 27 clean + 9 damaged\n",
      "Class 020_149: 27 clean + 9 damaged\n",
      "Class 020_150: 27 clean + 9 damaged\n",
      "Class 020_151: 27 clean + 9 damaged\n",
      "Class 020_152: 27 clean + 9 damaged\n",
      "Class 020_153: 27 clean + 9 damaged\n",
      "Class 020_154: 27 clean + 9 damaged\n",
      "Class 020_155: 27 clean + 9 damaged\n",
      "Class 020_156: 27 clean + 9 damaged\n",
      "Class 021_157: 27 clean + 9 damaged\n",
      "Class 021_158: 27 clean + 9 damaged\n",
      "Class 021_159: 27 clean + 9 damaged\n",
      "Class 021_160: 27 clean + 9 damaged\n",
      "Class 021_161: 27 clean + 9 damaged\n",
      "Class 021_162: 27 clean + 9 damaged\n",
      "Class 021_163: 27 clean + 9 damaged\n",
      "Class 021_164: 27 clean + 9 damaged\n",
      "Class 021_165: 27 clean + 9 damaged\n",
      "Class 021_166: 27 clean + 9 damaged\n",
      "Class 022_167: 27 clean + 9 damaged\n",
      "Class 022_168: 27 clean + 9 damaged\n",
      "Class 022_169: 27 clean + 9 damaged\n",
      "Class 022_170: 27 clean + 9 damaged\n",
      "Class 022_171: 27 clean + 9 damaged\n",
      "Class 022_172: 27 clean + 9 damaged\n",
      "Class 022_173: 27 clean + 9 damaged\n",
      "Class 022_174: 27 clean + 9 damaged\n",
      "Class 022_175: 27 clean + 9 damaged\n",
      "Class 022_176: 27 clean + 9 damaged\n",
      "Class 023_177: 27 clean + 9 damaged\n",
      "Class 023_178: 27 clean + 9 damaged\n",
      "Class 023_179: 27 clean + 9 damaged\n",
      "Class 023_180: 27 clean + 9 damaged\n",
      "Class 023_181: 27 clean + 9 damaged\n",
      "Class 023_182: 27 clean + 9 damaged\n",
      "Class 023_183: 27 clean + 9 damaged\n",
      "Class 023_184: 27 clean + 9 damaged\n",
      "Class 023_185: 27 clean + 9 damaged\n",
      "Class 023_186: 27 clean + 9 damaged\n",
      "Class 024_187: 27 clean + 9 damaged\n",
      "Class 024_188: 27 clean + 9 damaged\n",
      "Class 024_189: 27 clean + 9 damaged\n",
      "Class 024_190: 27 clean + 9 damaged\n",
      "Class 024_191: 27 clean + 9 damaged\n",
      "Class 024_192: 27 clean + 9 damaged\n",
      "Class 024_193: 27 clean + 9 damaged\n",
      "Class 024_194: 27 clean + 9 damaged\n",
      "Class 024_195: 27 clean + 9 damaged\n",
      "Class 024_196: 27 clean + 9 damaged\n",
      "Class 025_197: 27 clean + 9 damaged\n",
      "Class 025_198: 27 clean + 9 damaged\n",
      "Class 025_199: 27 clean + 9 damaged\n",
      "Class 025_200: 27 clean + 9 damaged\n",
      "Class 025_201: 27 clean + 9 damaged\n",
      "Class 025_202: 27 clean + 9 damaged\n",
      "Class 025_203: 27 clean + 9 damaged\n",
      "Class 025_204: 27 clean + 9 damaged\n",
      "Class 025_205: 27 clean + 9 damaged\n",
      "Class 025_206: 27 clean + 9 damaged\n",
      "Class 026_207: 27 clean + 9 damaged\n",
      "Class 026_208: 27 clean + 9 damaged\n",
      "Class 026_209: 27 clean + 9 damaged\n",
      "Class 026_210: 27 clean + 9 damaged\n",
      "Class 026_211: 27 clean + 9 damaged\n",
      "Class 026_212: 27 clean + 9 damaged\n",
      "Class 026_213: 27 clean + 9 damaged\n",
      "Class 026_214: 27 clean + 9 damaged\n",
      "Class 026_215: 27 clean + 9 damaged\n",
      "Class 026_216: 27 clean + 9 damaged\n",
      "Class 027_217: 27 clean + 9 damaged\n",
      "Class 027_218: 27 clean + 9 damaged\n",
      "Class 027_219: 27 clean + 9 damaged\n",
      "Class 027_220: 27 clean + 9 damaged\n",
      "Class 027_221: 27 clean + 9 damaged\n",
      "Class 027_222: 27 clean + 9 damaged\n",
      "Class 027_223: 27 clean + 9 damaged\n",
      "Class 027_224: 27 clean + 9 damaged\n",
      "Class 027_225: 27 clean + 9 damaged\n",
      "Class 027_226: 27 clean + 9 damaged\n",
      "Class 028_227: 27 clean + 9 damaged\n",
      "Class 028_228: 27 clean + 9 damaged\n",
      "Class 028_229: 27 clean + 9 damaged\n",
      "Class 028_230: 27 clean + 9 damaged\n",
      "Class 028_231: 27 clean + 9 damaged\n",
      "Class 028_232: 27 clean + 9 damaged\n",
      "Class 028_233: 27 clean + 9 damaged\n",
      "Class 028_234: 27 clean + 9 damaged\n",
      "Class 028_235: 27 clean + 9 damaged\n",
      "Class 028_236: 27 clean + 9 damaged\n",
      "Class 029_237: 27 clean + 9 damaged\n",
      "Class 029_238: 27 clean + 9 damaged\n",
      "Class 029_239: 27 clean + 9 damaged\n",
      "Class 029_240: 27 clean + 9 damaged\n",
      "Class 029_241: 27 clean + 9 damaged\n",
      "Class 029_242: 27 clean + 9 damaged\n",
      "Class 029_243: 27 clean + 9 damaged\n",
      "Class 029_244: 27 clean + 9 damaged\n",
      "Class 030_245: 27 clean + 9 damaged\n",
      "Class 030_246: 27 clean + 9 damaged\n",
      "Class 030_247: 27 clean + 9 damaged\n",
      "Class 030_248: 27 clean + 9 damaged\n",
      "Class 030_249: 27 clean + 9 damaged\n",
      "Class 030_250: 27 clean + 9 damaged\n",
      "Class 030_251: 27 clean + 9 damaged\n",
      "Class 030_252: 27 clean + 9 damaged\n",
      "Class 031_253: 27 clean + 9 damaged\n",
      "Class 031_254: 27 clean + 9 damaged\n",
      "Class 031_255: 27 clean + 9 damaged\n",
      "Class 031_256: 27 clean + 9 damaged\n",
      "Class 031_257: 27 clean + 9 damaged\n",
      "\n",
      "✅ Final training set: 9252 images total — 6939 clean + 2313 damaged.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dir = \"../data/final/train\"\n",
    "test_dir  = \"../data/final/test\"\n",
    "\n",
    "print(\"\\n🔧 Applying damage per class in training dataset...\")\n",
    "\n",
    "total_clean = 0\n",
    "total_damaged = 0\n",
    "\n",
    "for class_id in os.listdir(train_dir):\n",
    "    class_path = os.path.join(train_dir, class_id)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Collect valid image filenames\n",
    "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.tif', '.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "    num_images = len(images)\n",
    "    \n",
    "    # Calculate 25% of images to damage\n",
    "    num_to_damage = int(num_images * 0.25)\n",
    "    selected = random.sample(images, num_to_damage)\n",
    "\n",
    "    # Apply damage\n",
    "    for fname in selected:\n",
    "        img_path = os.path.join(class_path, fname)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            damaged = apply_combined_damage(img)\n",
    "            cv2.imwrite(img_path, damaged)\n",
    "\n",
    "    total_clean += (num_images - num_to_damage)\n",
    "    total_damaged += num_to_damage\n",
    "    print(f\"Class {class_id}: {num_images - num_to_damage} clean + {num_to_damage} damaged\")\n",
    "\n",
    "print(f\"\\n✅ Final training set: {total_clean + total_damaged} images total — {total_clean} clean + {total_damaged} damaged.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
