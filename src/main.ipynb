{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPROACH THAT WE USED IN THIS RESEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9252 images belonging to 257 classes.\n",
      "Found 514 images belonging to 257 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"../data/final/train\"\n",
    "test_dir  = \"../data/final/test\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "image_files = [f for f in os.listdir(train_dir) if f.endswith(\".tif\")]\n",
    "\n",
    "# Extract class labels from filenames (e.g., \"001_1.tif\" â†’ class 001 â†’ index 0)\n",
    "class_labels = sorted(set(f.split(\"_\")[0] for f in image_files))  # Unique classes\n",
    "class_to_index = {label: i for i, label in enumerate(class_labels)}\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=img_size, batch_size=batch_size, class_mode='sparse', color_mode='rgb'\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False  # ðŸ”’ ensure consistent ordering\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 7.1697 - accuracy: 0.0043\n",
      "Epoch 1: val_accuracy improved from -inf to 0.01167, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 264s 399ms/step - loss: 7.1697 - accuracy: 0.0043 - val_loss: 7.0335 - val_accuracy: 0.0117 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 6.9379 - accuracy: 0.0083\n",
      "Epoch 2: val_accuracy improved from 0.01167 to 0.01362, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 201s 347ms/step - loss: 6.9379 - accuracy: 0.0083 - val_loss: 6.6434 - val_accuracy: 0.0136 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 6.5744 - accuracy: 0.0244\n",
      "Epoch 3: val_accuracy improved from 0.01362 to 0.06226, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 200s 346ms/step - loss: 6.5744 - accuracy: 0.0244 - val_loss: 6.0625 - val_accuracy: 0.0623 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 6.1193 - accuracy: 0.0579\n",
      "Epoch 4: val_accuracy improved from 0.06226 to 0.17510, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 200s 345ms/step - loss: 6.1193 - accuracy: 0.0579 - val_loss: 5.3031 - val_accuracy: 0.1751 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 5.5537 - accuracy: 0.1150\n",
      "Epoch 5: val_accuracy improved from 0.17510 to 0.33074, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 205s 354ms/step - loss: 5.5537 - accuracy: 0.1150 - val_loss: 4.6051 - val_accuracy: 0.3307 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 4.9301 - accuracy: 0.2024\n",
      "Epoch 6: val_accuracy improved from 0.33074 to 0.45525, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 206s 355ms/step - loss: 4.9301 - accuracy: 0.2024 - val_loss: 3.8383 - val_accuracy: 0.4553 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 4.3566 - accuracy: 0.2915\n",
      "Epoch 7: val_accuracy improved from 0.45525 to 0.51167, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 207s 357ms/step - loss: 4.3566 - accuracy: 0.2915 - val_loss: 3.3358 - val_accuracy: 0.5117 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 3.9008 - accuracy: 0.3677\n",
      "Epoch 8: val_accuracy improved from 0.51167 to 0.62451, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 204s 352ms/step - loss: 3.9008 - accuracy: 0.3677 - val_loss: 2.9167 - val_accuracy: 0.6245 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 3.5271 - accuracy: 0.4478\n",
      "Epoch 9: val_accuracy improved from 0.62451 to 0.68872, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 207s 358ms/step - loss: 3.5271 - accuracy: 0.4478 - val_loss: 2.6616 - val_accuracy: 0.6887 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 3.2074 - accuracy: 0.5108\n",
      "Epoch 10: val_accuracy improved from 0.68872 to 0.70428, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 208s 359ms/step - loss: 3.2074 - accuracy: 0.5108 - val_loss: 2.5015 - val_accuracy: 0.7043 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.9624 - accuracy: 0.5584\n",
      "Epoch 11: val_accuracy improved from 0.70428 to 0.70623, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 207s 358ms/step - loss: 2.9624 - accuracy: 0.5584 - val_loss: 2.4085 - val_accuracy: 0.7062 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.7329 - accuracy: 0.6096\n",
      "Epoch 12: val_accuracy improved from 0.70623 to 0.75681, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 217s 375ms/step - loss: 2.7329 - accuracy: 0.6096 - val_loss: 2.1877 - val_accuracy: 0.7568 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.5697 - accuracy: 0.6458\n",
      "Epoch 13: val_accuracy improved from 0.75681 to 0.78599, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 286s 494ms/step - loss: 2.5697 - accuracy: 0.6458 - val_loss: 2.1155 - val_accuracy: 0.7860 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.4395 - accuracy: 0.6761\n",
      "Epoch 14: val_accuracy improved from 0.78599 to 0.82490, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 283s 489ms/step - loss: 2.4395 - accuracy: 0.6761 - val_loss: 1.9651 - val_accuracy: 0.8249 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.2735 - accuracy: 0.7162\n",
      "Epoch 15: val_accuracy did not improve from 0.82490\n",
      "579/579 [==============================] - 280s 484ms/step - loss: 2.2735 - accuracy: 0.7162 - val_loss: 1.9168 - val_accuracy: 0.8210 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.1751 - accuracy: 0.7372\n",
      "Epoch 16: val_accuracy improved from 0.82490 to 0.83852, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 283s 489ms/step - loss: 2.1751 - accuracy: 0.7372 - val_loss: 1.8855 - val_accuracy: 0.8385 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.0849 - accuracy: 0.7664\n",
      "Epoch 17: val_accuracy improved from 0.83852 to 0.85603, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 288s 497ms/step - loss: 2.0849 - accuracy: 0.7664 - val_loss: 1.7739 - val_accuracy: 0.8560 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.9977 - accuracy: 0.7800\n",
      "Epoch 18: val_accuracy improved from 0.85603 to 0.86770, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 276s 476ms/step - loss: 1.9977 - accuracy: 0.7800 - val_loss: 1.7451 - val_accuracy: 0.8677 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.9393 - accuracy: 0.7982\n",
      "Epoch 19: val_accuracy did not improve from 0.86770\n",
      "579/579 [==============================] - 277s 479ms/step - loss: 1.9393 - accuracy: 0.7982 - val_loss: 1.7476 - val_accuracy: 0.8541 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.8663 - accuracy: 0.8197\n",
      "Epoch 20: val_accuracy did not improve from 0.86770\n",
      "579/579 [==============================] - 268s 463ms/step - loss: 1.8663 - accuracy: 0.8197 - val_loss: 1.7306 - val_accuracy: 0.8658 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.8122 - accuracy: 0.8330\n",
      "Epoch 21: val_accuracy did not improve from 0.86770\n",
      "579/579 [==============================] - 275s 475ms/step - loss: 1.8122 - accuracy: 0.8330 - val_loss: 1.6937 - val_accuracy: 0.8580 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.7690 - accuracy: 0.8438\n",
      "Epoch 22: val_accuracy did not improve from 0.86770\n",
      "579/579 [==============================] - 269s 465ms/step - loss: 1.7690 - accuracy: 0.8438 - val_loss: 1.6948 - val_accuracy: 0.8619 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.7156 - accuracy: 0.8618\n",
      "Epoch 23: val_accuracy improved from 0.86770 to 0.88521, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 264s 456ms/step - loss: 1.7156 - accuracy: 0.8618 - val_loss: 1.6044 - val_accuracy: 0.8852 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.6736 - accuracy: 0.8652\n",
      "Epoch 24: val_accuracy improved from 0.88521 to 0.89105, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 278s 480ms/step - loss: 1.6736 - accuracy: 0.8652 - val_loss: 1.6171 - val_accuracy: 0.8911 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.6549 - accuracy: 0.8716\n",
      "Epoch 25: val_accuracy did not improve from 0.89105\n",
      "579/579 [==============================] - 275s 475ms/step - loss: 1.6549 - accuracy: 0.8716 - val_loss: 1.6493 - val_accuracy: 0.8891 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.6067 - accuracy: 0.8832\n",
      "Epoch 26: val_accuracy improved from 0.89105 to 0.89689, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 269s 465ms/step - loss: 1.6067 - accuracy: 0.8832 - val_loss: 1.5950 - val_accuracy: 0.8969 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.6005 - accuracy: 0.8893\n",
      "Epoch 27: val_accuracy improved from 0.89689 to 0.90661, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 263s 454ms/step - loss: 1.6005 - accuracy: 0.8893 - val_loss: 1.5508 - val_accuracy: 0.9066 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.5586 - accuracy: 0.8955\n",
      "Epoch 28: val_accuracy did not improve from 0.90661\n",
      "579/579 [==============================] - 195s 337ms/step - loss: 1.5586 - accuracy: 0.8955 - val_loss: 1.6205 - val_accuracy: 0.8852 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.5384 - accuracy: 0.9036\n",
      "Epoch 29: val_accuracy improved from 0.90661 to 0.91440, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.5384 - accuracy: 0.9036 - val_loss: 1.5271 - val_accuracy: 0.9144 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.5195 - accuracy: 0.9070\n",
      "Epoch 30: val_accuracy did not improve from 0.91440\n",
      "579/579 [==============================] - 199s 344ms/step - loss: 1.5195 - accuracy: 0.9070 - val_loss: 1.6045 - val_accuracy: 0.8852 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.4864 - accuracy: 0.9159\n",
      "Epoch 31: val_accuracy did not improve from 0.91440\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.4864 - accuracy: 0.9159 - val_loss: 1.5397 - val_accuracy: 0.9047 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.4655 - accuracy: 0.9216\n",
      "Epoch 32: val_accuracy did not improve from 0.91440\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.4655 - accuracy: 0.9216 - val_loss: 1.5435 - val_accuracy: 0.9027 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.3866 - accuracy: 0.9460\n",
      "Epoch 33: val_accuracy did not improve from 0.91440\n",
      "579/579 [==============================] - 199s 344ms/step - loss: 1.3866 - accuracy: 0.9460 - val_loss: 1.5435 - val_accuracy: 0.9125 - lr: 5.0000e-06\n",
      "Epoch 34/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.3668 - accuracy: 0.9482\n",
      "Epoch 34: val_accuracy improved from 0.91440 to 0.91829, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.3668 - accuracy: 0.9482 - val_loss: 1.5206 - val_accuracy: 0.9183 - lr: 5.0000e-06\n",
      "Epoch 35/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.3550 - accuracy: 0.9498\n",
      "Epoch 35: val_accuracy did not improve from 0.91829\n",
      "579/579 [==============================] - 199s 344ms/step - loss: 1.3550 - accuracy: 0.9498 - val_loss: 1.4910 - val_accuracy: 0.9144 - lr: 5.0000e-06\n",
      "Epoch 36/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.3473 - accuracy: 0.9523\n",
      "Epoch 36: val_accuracy improved from 0.91829 to 0.92218, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 199s 344ms/step - loss: 1.3473 - accuracy: 0.9523 - val_loss: 1.5001 - val_accuracy: 0.9222 - lr: 5.0000e-06\n",
      "Epoch 37/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.3365 - accuracy: 0.9557\n",
      "Epoch 37: val_accuracy did not improve from 0.92218\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.3365 - accuracy: 0.9557 - val_loss: 1.5215 - val_accuracy: 0.9008 - lr: 5.0000e-06\n",
      "Epoch 38/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.3357 - accuracy: 0.9529\n",
      "Epoch 38: val_accuracy did not improve from 0.92218\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.3357 - accuracy: 0.9529 - val_loss: 1.5101 - val_accuracy: 0.9183 - lr: 5.0000e-06\n",
      "Epoch 39/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2954 - accuracy: 0.9658\n",
      "Epoch 39: val_accuracy did not improve from 0.92218\n",
      "579/579 [==============================] - 198s 343ms/step - loss: 1.2954 - accuracy: 0.9658 - val_loss: 1.4727 - val_accuracy: 0.9163 - lr: 2.5000e-06\n",
      "Epoch 40/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2814 - accuracy: 0.9716\n",
      "Epoch 40: val_accuracy improved from 0.92218 to 0.92412, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.2814 - accuracy: 0.9716 - val_loss: 1.4990 - val_accuracy: 0.9241 - lr: 2.5000e-06\n",
      "Epoch 41/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2758 - accuracy: 0.9709\n",
      "Epoch 41: val_accuracy did not improve from 0.92412\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.2758 - accuracy: 0.9709 - val_loss: 1.5216 - val_accuracy: 0.9222 - lr: 2.5000e-06\n",
      "Epoch 42/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2789 - accuracy: 0.9696\n",
      "Epoch 42: val_accuracy did not improve from 0.92412\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.2789 - accuracy: 0.9696 - val_loss: 1.5321 - val_accuracy: 0.9105 - lr: 2.5000e-06\n",
      "Epoch 43/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2597 - accuracy: 0.9758\n",
      "Epoch 43: val_accuracy did not improve from 0.92412\n",
      "579/579 [==============================] - 198s 343ms/step - loss: 1.2597 - accuracy: 0.9758 - val_loss: 1.4906 - val_accuracy: 0.9222 - lr: 1.2500e-06\n",
      "Epoch 44/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2509 - accuracy: 0.9795\n",
      "Epoch 44: val_accuracy did not improve from 0.92412\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.2509 - accuracy: 0.9795 - val_loss: 1.4790 - val_accuracy: 0.9241 - lr: 1.2500e-06\n",
      "Epoch 45/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2473 - accuracy: 0.9798\n",
      "Epoch 45: val_accuracy improved from 0.92412 to 0.92607, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.2473 - accuracy: 0.9798 - val_loss: 1.4909 - val_accuracy: 0.9261 - lr: 1.2500e-06\n",
      "Epoch 46/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2526 - accuracy: 0.9786\n",
      "Epoch 46: val_accuracy did not improve from 0.92607\n",
      "579/579 [==============================] - 198s 343ms/step - loss: 1.2526 - accuracy: 0.9786 - val_loss: 1.4887 - val_accuracy: 0.9202 - lr: 6.2500e-07\n",
      "Epoch 47/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2489 - accuracy: 0.9789\n",
      "Epoch 47: val_accuracy did not improve from 0.92607\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.2489 - accuracy: 0.9789 - val_loss: 1.4905 - val_accuracy: 0.9183 - lr: 6.2500e-07\n",
      "Epoch 48/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2449 - accuracy: 0.9808\n",
      "Epoch 48: val_accuracy did not improve from 0.92607\n",
      "579/579 [==============================] - 199s 344ms/step - loss: 1.2449 - accuracy: 0.9808 - val_loss: 1.4801 - val_accuracy: 0.9222 - lr: 6.2500e-07\n",
      "Epoch 49/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2395 - accuracy: 0.9807\n",
      "Epoch 49: val_accuracy did not improve from 0.92607\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.2395 - accuracy: 0.9807 - val_loss: 1.4726 - val_accuracy: 0.9241 - lr: 3.1250e-07\n",
      "Epoch 50/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2383 - accuracy: 0.9814\n",
      "Epoch 50: val_accuracy did not improve from 0.92607\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.2383 - accuracy: 0.9814 - val_loss: 1.4781 - val_accuracy: 0.9222 - lr: 3.1250e-07\n",
      "Epoch 51/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2394 - accuracy: 0.9808\n",
      "Epoch 51: val_accuracy improved from 0.92607 to 0.92996, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 199s 344ms/step - loss: 1.2394 - accuracy: 0.9808 - val_loss: 1.4692 - val_accuracy: 0.9300 - lr: 3.1250e-07\n",
      "Epoch 52/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2371 - accuracy: 0.9812\n",
      "Epoch 52: val_accuracy did not improve from 0.92996\n",
      "579/579 [==============================] - 199s 343ms/step - loss: 1.2371 - accuracy: 0.9812 - val_loss: 1.4795 - val_accuracy: 0.9280 - lr: 3.1250e-07\n",
      "Epoch 53/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2392 - accuracy: 0.9797\n",
      "Epoch 53: val_accuracy did not improve from 0.92996\n",
      "579/579 [==============================] - 207s 358ms/step - loss: 1.2392 - accuracy: 0.9797 - val_loss: 1.4715 - val_accuracy: 0.9280 - lr: 3.1250e-07\n",
      "Epoch 54/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2397 - accuracy: 0.9797\n",
      "Epoch 54: val_accuracy improved from 0.92996 to 0.93580, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 200s 345ms/step - loss: 1.2397 - accuracy: 0.9797 - val_loss: 1.4700 - val_accuracy: 0.9358 - lr: 3.1250e-07\n",
      "Epoch 55/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2321 - accuracy: 0.9840\n",
      "Epoch 55: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 198s 341ms/step - loss: 1.2321 - accuracy: 0.9840 - val_loss: 1.4704 - val_accuracy: 0.9280 - lr: 1.5625e-07\n",
      "Epoch 56/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2392 - accuracy: 0.9804\n",
      "Epoch 56: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 199s 344ms/step - loss: 1.2392 - accuracy: 0.9804 - val_loss: 1.4707 - val_accuracy: 0.9319 - lr: 1.5625e-07\n",
      "Epoch 57/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2298 - accuracy: 0.9816\n",
      "Epoch 57: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 197s 339ms/step - loss: 1.2298 - accuracy: 0.9816 - val_loss: 1.4704 - val_accuracy: 0.9339 - lr: 1.5625e-07\n",
      "Epoch 58/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2340 - accuracy: 0.9819\n",
      "Epoch 58: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 197s 341ms/step - loss: 1.2340 - accuracy: 0.9819 - val_loss: 1.4695 - val_accuracy: 0.9319 - lr: 1.0000e-07\n",
      "Epoch 59/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2351 - accuracy: 0.9808\n",
      "Epoch 59: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 196s 338ms/step - loss: 1.2351 - accuracy: 0.9808 - val_loss: 1.4693 - val_accuracy: 0.9280 - lr: 1.0000e-07\n",
      "Epoch 60/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2353 - accuracy: 0.9817\n",
      "Epoch 60: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 196s 338ms/step - loss: 1.2353 - accuracy: 0.9817 - val_loss: 1.4691 - val_accuracy: 0.9319 - lr: 1.0000e-07\n",
      "Epoch 61/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2337 - accuracy: 0.9830\n",
      "Epoch 61: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 196s 339ms/step - loss: 1.2337 - accuracy: 0.9830 - val_loss: 1.4662 - val_accuracy: 0.9300 - lr: 1.0000e-07\n",
      "Epoch 62/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2279 - accuracy: 0.9842\n",
      "Epoch 62: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 196s 339ms/step - loss: 1.2279 - accuracy: 0.9842 - val_loss: 1.4692 - val_accuracy: 0.9280 - lr: 1.0000e-07\n",
      "Epoch 63/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2301 - accuracy: 0.9819\n",
      "Epoch 63: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 197s 340ms/step - loss: 1.2301 - accuracy: 0.9819 - val_loss: 1.4700 - val_accuracy: 0.9319 - lr: 1.0000e-07\n",
      "Epoch 64/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2348 - accuracy: 0.9813Restoring model weights from the end of the best epoch: 54.\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.93580\n",
      "579/579 [==============================] - 198s 342ms/step - loss: 1.2348 - accuracy: 0.9813 - val_loss: 1.4625 - val_accuracy: 0.9358 - lr: 1.0000e-07\n",
      "Epoch 64: early stopping\n",
      "\n",
      "âœ… Model trained and saved as best_fingerprint_model.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers[:-16]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(train_gen.num_classes, activation='softmax', \n",
    "                    kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-7)\n",
    "\n",
    "\n",
    "# # EarlyStopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,                 \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ModelCheckpoint to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_fingerprint_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "    epochs=100,\n",
    "    callbacks=[lr_scheduler, early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save(\"best_fingerprint_model.h5\")\n",
    "print(\"\\nâœ… Model trained and saved as best_fingerprint_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'001_1': 0, '001_2': 1, '001_3': 2, '001_4': 3, '001_5': 4, '001_6': 5, '002_10': 6, '002_11': 7, '002_12': 8, '002_7': 9, '002_8': 10, '002_9': 11, '003_13': 12, '003_14': 13, '003_15': 14, '003_16': 15, '003_17': 16, '003_18': 17, '004_19': 18, '004_20': 19, '004_21': 20, '004_22': 21, '004_23': 22, '004_24': 23, '005_25': 24, '005_26': 25, '005_27': 26, '005_28': 27, '005_29': 28, '005_30': 29, '006_31': 30, '006_32': 31, '006_33': 32, '006_34': 33, '006_35': 34, '006_36': 35, '007_37': 36, '007_38': 37, '007_39': 38, '007_40': 39, '007_41': 40, '007_42': 41, '008_43': 42, '008_44': 43, '008_45': 44, '009_46': 45, '009_47': 46, '009_48': 47, '009_49': 48, '009_50': 49, '009_51': 50, '010_52': 51, '010_53': 52, '010_54': 53, '010_55': 54, '010_56': 55, '010_57': 56, '010_58': 57, '010_59': 58, '010_60': 59, '010_61': 60, '011_62': 61, '011_63': 62, '011_64': 63, '011_65': 64, '011_66': 65, '011_67': 66, '011_68': 67, '011_69': 68, '011_70': 69, '011_71': 70, '012_72': 71, '012_73': 72, '012_74': 73, '012_75': 74, '012_76': 75, '012_77': 76, '012_78': 77, '012_79': 78, '012_80': 79, '012_81': 80, '013_82': 81, '013_83': 82, '013_84': 83, '013_85': 84, '013_86': 85, '013_87': 86, '013_88': 87, '013_89': 88, '013_90': 89, '013_91': 90, '014_100': 91, '014_101': 92, '014_92': 93, '014_93': 94, '014_94': 95, '014_95': 96, '014_96': 97, '014_97': 98, '014_98': 99, '014_99': 100, '015_102': 101, '015_103': 102, '015_104': 103, '015_105': 104, '015_106': 105, '016_107': 106, '016_108': 107, '016_109': 108, '016_110': 109, '016_111': 110, '016_112': 111, '016_113': 112, '016_114': 113, '016_115': 114, '016_116': 115, '017_117': 116, '017_118': 117, '017_119': 118, '017_120': 119, '017_121': 120, '017_122': 121, '017_123': 122, '017_124': 123, '017_125': 124, '017_126': 125, '018_127': 126, '018_128': 127, '018_129': 128, '018_130': 129, '018_131': 130, '018_132': 131, '018_133': 132, '018_134': 133, '018_135': 134, '018_136': 135, '019_137': 136, '019_138': 137, '019_139': 138, '019_140': 139, '019_141': 140, '019_142': 141, '019_143': 142, '019_144': 143, '019_145': 144, '019_146': 145, '020_147': 146, '020_148': 147, '020_149': 148, '020_150': 149, '020_151': 150, '020_152': 151, '020_153': 152, '020_154': 153, '020_155': 154, '020_156': 155, '021_157': 156, '021_158': 157, '021_159': 158, '021_160': 159, '021_161': 160, '021_162': 161, '021_163': 162, '021_164': 163, '021_165': 164, '021_166': 165, '022_167': 166, '022_168': 167, '022_169': 168, '022_170': 169, '022_171': 170, '022_172': 171, '022_173': 172, '022_174': 173, '022_175': 174, '022_176': 175, '023_177': 176, '023_178': 177, '023_179': 178, '023_180': 179, '023_181': 180, '023_182': 181, '023_183': 182, '023_184': 183, '023_185': 184, '023_186': 185, '024_187': 186, '024_188': 187, '024_189': 188, '024_190': 189, '024_191': 190, '024_192': 191, '024_193': 192, '024_194': 193, '024_195': 194, '024_196': 195, '025_197': 196, '025_198': 197, '025_199': 198, '025_200': 199, '025_201': 200, '025_202': 201, '025_203': 202, '025_204': 203, '025_205': 204, '025_206': 205, '026_207': 206, '026_208': 207, '026_209': 208, '026_210': 209, '026_211': 210, '026_212': 211, '026_213': 212, '026_214': 213, '026_215': 214, '026_216': 215, '027_217': 216, '027_218': 217, '027_219': 218, '027_220': 219, '027_221': 220, '027_222': 221, '027_223': 222, '027_224': 223, '027_225': 224, '027_226': 225, '028_227': 226, '028_228': 227, '028_229': 228, '028_230': 229, '028_231': 230, '028_232': 231, '028_233': 232, '028_234': 233, '028_235': 234, '028_236': 235, '029_237': 236, '029_238': 237, '029_239': 238, '029_240': 239, '029_241': 240, '029_242': 241, '029_243': 242, '029_244': 243, '030_245': 244, '030_246': 245, '030_247': 246, '030_248': 247, '030_249': 248, '030_250': 249, '030_251': 250, '030_252': 251, '031_253': 252, '031_254': 253, '031_255': 254, '031_256': 255, '031_257': 256}\n"
     ]
    }
   ],
   "source": [
    "print(test_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 4s 105ms/step - loss: 1.4700 - accuracy: 0.9358\n",
      "\n",
      "ðŸ“Š Test Loss: 1.4700\n",
      "âœ… Test Accuracy: 0.9358\n"
     ]
    }
   ],
   "source": [
    "# Load the best model from checkpoint before evaluation\n",
    "model = load_model(\"best_fingerprint_model.h5\")\n",
    "\n",
    "# Evaluate using the best model\n",
    "loss, accuracy = model.evaluate(test_gen) \n",
    "print(f\"\\nðŸ“Š Test Loss: {loss:.4f}\")\n",
    "print(f\"âœ… Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/block1_conv2/Relu' defined at (most recent call last):\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_33284\\497643483.py\", line 17, in <module>\n      y_pred_probs = model.predict(X_test, batch_size=16)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'model/block1_conv2/Relu'\nOOM when allocating tensor with shape[16,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/block1_conv2/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_168969]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m y_pred_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_probs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Classification Report & Confusion Matrix\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/block1_conv2/Relu' defined at (most recent call last):\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_33284\\497643483.py\", line 17, in <module>\n      y_pred_probs = model.predict(X_test, batch_size=16)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'model/block1_conv2/Relu'\nOOM when allocating tensor with shape[16,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/block1_conv2/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_168969]"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Calculate number of steps needed to cover all test samples\n",
    "steps = int(np.ceil(test_gen.samples / test_gen.batch_size))\n",
    "\n",
    "# Collect only the required number of batches\n",
    "for i in range(steps):\n",
    "    x, y = next(test_gen)\n",
    "    X_test.append(x)\n",
    "    y_test.append(y)\n",
    "\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test, batch_size=16)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Classification Report & Confusion Matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Reset the generator before iterating\n",
    "test_gen.reset()\n",
    "steps = int(np.ceil(test_gen.samples / test_gen.batch_size))\n",
    "\n",
    "for _ in range(steps):\n",
    "    x_batch, y_batch = next(test_gen)\n",
    "\n",
    "    # Handle one-hot encoded or integer labels\n",
    "    if y_batch.ndim > 1:\n",
    "        y_true.extend(np.argmax(y_batch, axis=1))\n",
    "    else:\n",
    "        y_true.extend(y_batch)\n",
    "\n",
    "    preds = model.predict(x_batch)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", linewidths=0.5, linecolor='gray')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Macro averages (treats all classes equally)\n",
    "precision_macro = report['macro avg']['precision']\n",
    "recall_macro = report['macro avg']['recall']\n",
    "f1_macro = report['macro avg']['f1-score']\n",
    "\n",
    "# Weighted averages (accounts for class imbalance)\n",
    "precision_weighted = report['weighted avg']['precision']\n",
    "recall_weighted = report['weighted avg']['recall']\n",
    "f1_weighted = report['weighted avg']['f1-score']\n",
    "\n",
    "print(f\"\\nMacro Avg - Precision: {precision_macro:.4f}, Recall: {recall_macro:.4f}, F1 Score: {f1_macro:.4f}\")\n",
    "print(f\"Weighted Avg - Precision: {precision_weighted:.4f}, Recall: {recall_weighted:.4f}, F1 Score: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode true labels\n",
    "y_test_onehot = label_binarize(y_test, classes=np.arange(model.output_shape[-1]))\n",
    "\n",
    "# y_pred_probs: already predicted earlier like this\n",
    "# y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Multi-class ROC AUC using 'macro' average\n",
    "roc_auc = roc_auc_score(y_test_onehot, y_pred_probs, average='macro', multi_class='ovr')\n",
    "\n",
    "print(f\"ROC AUC Score (macro): {roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
