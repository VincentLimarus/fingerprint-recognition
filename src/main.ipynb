{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPROACH THAT WE USED IN THIS RESEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9252 images belonging to 257 classes.\n",
      "Found 514 images belonging to 257 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"../data/final/train\"\n",
    "test_dir  = \"../data/final/test\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "image_files = [f for f in os.listdir(train_dir) if f.endswith(\".tif\")]\n",
    "\n",
    "# Extract class labels from filenames (e.g., \"001_1.tif\" â†’ class 001 â†’ index 0)\n",
    "class_labels = sorted(set(f.split(\"_\")[0] for f in image_files))  # Unique classes\n",
    "class_to_index = {label: i for i, label in enumerate(class_labels)}\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=img_size, batch_size=batch_size, class_mode='sparse', color_mode='rgb'\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False  # ðŸ”’ ensure consistent ordering\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 7.1538 - accuracy: 0.0046\n",
      "Epoch 1: val_accuracy improved from -inf to 0.01167, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 167s 250ms/step - loss: 7.1538 - accuracy: 0.0046 - val_loss: 7.0379 - val_accuracy: 0.0117 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 6.8987 - accuracy: 0.0058\n",
      "Epoch 2: val_accuracy did not improve from 0.01167\n",
      "579/579 [==============================] - 143s 247ms/step - loss: 6.8987 - accuracy: 0.0058 - val_loss: 6.7670 - val_accuracy: 0.0097 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 6.6223 - accuracy: 0.0097\n",
      "Epoch 3: val_accuracy did not improve from 0.01167\n",
      "579/579 [==============================] - 142s 244ms/step - loss: 6.6223 - accuracy: 0.0097 - val_loss: 6.3814 - val_accuracy: 0.0117 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 6.1922 - accuracy: 0.0273\n",
      "Epoch 4: val_accuracy improved from 0.01167 to 0.08366, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 143s 247ms/step - loss: 6.1922 - accuracy: 0.0273 - val_loss: 5.6921 - val_accuracy: 0.0837 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 5.4792 - accuracy: 0.0941\n",
      "Epoch 5: val_accuracy improved from 0.08366 to 0.22374, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 5.4792 - accuracy: 0.0941 - val_loss: 4.8215 - val_accuracy: 0.2237 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 4.5937 - accuracy: 0.2134\n",
      "Epoch 6: val_accuracy improved from 0.22374 to 0.42412, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 143s 246ms/step - loss: 4.5937 - accuracy: 0.2134 - val_loss: 3.7827 - val_accuracy: 0.4241 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 3.7947 - accuracy: 0.3451\n",
      "Epoch 7: val_accuracy improved from 0.42412 to 0.56615, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 144s 249ms/step - loss: 3.7947 - accuracy: 0.3451 - val_loss: 3.0393 - val_accuracy: 0.5661 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 3.1612 - accuracy: 0.4750\n",
      "Epoch 8: val_accuracy improved from 0.56615 to 0.66926, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 3.1612 - accuracy: 0.4750 - val_loss: 2.5777 - val_accuracy: 0.6693 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.7060 - accuracy: 0.5794\n",
      "Epoch 9: val_accuracy improved from 0.66926 to 0.70233, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 143s 247ms/step - loss: 2.7060 - accuracy: 0.5794 - val_loss: 2.3813 - val_accuracy: 0.7023 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.3716 - accuracy: 0.6481\n",
      "Epoch 10: val_accuracy improved from 0.70233 to 0.73541, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 143s 246ms/step - loss: 2.3716 - accuracy: 0.6481 - val_loss: 2.2076 - val_accuracy: 0.7354 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 2.1254 - accuracy: 0.7096\n",
      "Epoch 11: val_accuracy improved from 0.73541 to 0.74903, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 143s 247ms/step - loss: 2.1254 - accuracy: 0.7096 - val_loss: 2.0435 - val_accuracy: 0.7490 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.9423 - accuracy: 0.7606\n",
      "Epoch 12: val_accuracy improved from 0.74903 to 0.77821, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 144s 249ms/step - loss: 1.9423 - accuracy: 0.7606 - val_loss: 1.9949 - val_accuracy: 0.7782 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.8195 - accuracy: 0.7929\n",
      "Epoch 13: val_accuracy improved from 0.77821 to 0.80350, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 145s 249ms/step - loss: 1.8195 - accuracy: 0.7929 - val_loss: 1.8523 - val_accuracy: 0.8035 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.6915 - accuracy: 0.8270\n",
      "Epoch 14: val_accuracy improved from 0.80350 to 0.81323, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 145s 250ms/step - loss: 1.6915 - accuracy: 0.8270 - val_loss: 1.7952 - val_accuracy: 0.8132 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.6014 - accuracy: 0.8564\n",
      "Epoch 15: val_accuracy did not improve from 0.81323\n",
      "579/579 [==============================] - 143s 246ms/step - loss: 1.6014 - accuracy: 0.8564 - val_loss: 1.8744 - val_accuracy: 0.7996 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.5450 - accuracy: 0.8711\n",
      "Epoch 16: val_accuracy improved from 0.81323 to 0.85992, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 143s 247ms/step - loss: 1.5450 - accuracy: 0.8711 - val_loss: 1.6617 - val_accuracy: 0.8599 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.4824 - accuracy: 0.8929\n",
      "Epoch 17: val_accuracy did not improve from 0.85992\n",
      "579/579 [==============================] - 142s 245ms/step - loss: 1.4824 - accuracy: 0.8929 - val_loss: 1.7046 - val_accuracy: 0.8463 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.4179 - accuracy: 0.9055\n",
      "Epoch 18: val_accuracy did not improve from 0.85992\n",
      "579/579 [==============================] - 142s 246ms/step - loss: 1.4179 - accuracy: 0.9055 - val_loss: 1.7440 - val_accuracy: 0.8346 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.3737 - accuracy: 0.9228\n",
      "Epoch 19: val_accuracy did not improve from 0.85992\n",
      "579/579 [==============================] - 142s 246ms/step - loss: 1.3737 - accuracy: 0.9228 - val_loss: 1.6951 - val_accuracy: 0.8327 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.3038 - accuracy: 0.9402\n",
      "Epoch 20: val_accuracy improved from 0.85992 to 0.87743, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 143s 246ms/step - loss: 1.3038 - accuracy: 0.9402 - val_loss: 1.5795 - val_accuracy: 0.8774 - lr: 5.0000e-06\n",
      "Epoch 21/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2776 - accuracy: 0.9476\n",
      "Epoch 21: val_accuracy did not improve from 0.87743\n",
      "579/579 [==============================] - 143s 246ms/step - loss: 1.2776 - accuracy: 0.9476 - val_loss: 1.5779 - val_accuracy: 0.8658 - lr: 5.0000e-06\n",
      "Epoch 22/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2591 - accuracy: 0.9530\n",
      "Epoch 22: val_accuracy improved from 0.87743 to 0.88716, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 1.2591 - accuracy: 0.9530 - val_loss: 1.5459 - val_accuracy: 0.8872 - lr: 5.0000e-06\n",
      "Epoch 23/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2523 - accuracy: 0.9538\n",
      "Epoch 23: val_accuracy did not improve from 0.88716\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 1.2523 - accuracy: 0.9538 - val_loss: 1.5663 - val_accuracy: 0.8716 - lr: 5.0000e-06\n",
      "Epoch 24/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2448 - accuracy: 0.9560\n",
      "Epoch 24: val_accuracy did not improve from 0.88716\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 1.2448 - accuracy: 0.9560 - val_loss: 1.6185 - val_accuracy: 0.8599 - lr: 5.0000e-06\n",
      "Epoch 25/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.2231 - accuracy: 0.9614\n",
      "Epoch 25: val_accuracy did not improve from 0.88716\n",
      "579/579 [==============================] - 144s 249ms/step - loss: 1.2231 - accuracy: 0.9614 - val_loss: 1.5811 - val_accuracy: 0.8813 - lr: 5.0000e-06\n",
      "Epoch 26/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1939 - accuracy: 0.9728\n",
      "Epoch 26: val_accuracy did not improve from 0.88716\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 1.1939 - accuracy: 0.9728 - val_loss: 1.5427 - val_accuracy: 0.8774 - lr: 2.5000e-06\n",
      "Epoch 27/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1889 - accuracy: 0.9724\n",
      "Epoch 27: val_accuracy did not improve from 0.88716\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 1.1889 - accuracy: 0.9724 - val_loss: 1.5236 - val_accuracy: 0.8852 - lr: 2.5000e-06\n",
      "Epoch 28/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1807 - accuracy: 0.9751\n",
      "Epoch 28: val_accuracy did not improve from 0.88716\n",
      "579/579 [==============================] - 144s 249ms/step - loss: 1.1807 - accuracy: 0.9751 - val_loss: 1.5673 - val_accuracy: 0.8755 - lr: 2.5000e-06\n",
      "Epoch 29/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1784 - accuracy: 0.9740\n",
      "Epoch 29: val_accuracy did not improve from 0.88716\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 1.1784 - accuracy: 0.9740 - val_loss: 1.5500 - val_accuracy: 0.8696 - lr: 2.5000e-06\n",
      "Epoch 30/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1684 - accuracy: 0.9782\n",
      "Epoch 30: val_accuracy did not improve from 0.88716\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 1.1684 - accuracy: 0.9782 - val_loss: 1.6518 - val_accuracy: 0.8580 - lr: 2.5000e-06\n",
      "Epoch 31/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1532 - accuracy: 0.9834\n",
      "Epoch 31: val_accuracy improved from 0.88716 to 0.89105, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 144s 249ms/step - loss: 1.1532 - accuracy: 0.9834 - val_loss: 1.5311 - val_accuracy: 0.8911 - lr: 1.2500e-06\n",
      "Epoch 32/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1586 - accuracy: 0.9803\n",
      "Epoch 32: val_accuracy did not improve from 0.89105\n",
      "579/579 [==============================] - 144s 248ms/step - loss: 1.1586 - accuracy: 0.9803 - val_loss: 1.5194 - val_accuracy: 0.8911 - lr: 1.2500e-06\n",
      "Epoch 33/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1484 - accuracy: 0.9842\n",
      "Epoch 33: val_accuracy improved from 0.89105 to 0.89300, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 146s 251ms/step - loss: 1.1484 - accuracy: 0.9842 - val_loss: 1.5407 - val_accuracy: 0.8930 - lr: 1.2500e-06\n",
      "Epoch 34/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1558 - accuracy: 0.9815\n",
      "Epoch 34: val_accuracy did not improve from 0.89300\n",
      "579/579 [==============================] - 145s 251ms/step - loss: 1.1558 - accuracy: 0.9815 - val_loss: 1.5427 - val_accuracy: 0.8930 - lr: 1.2500e-06\n",
      "Epoch 35/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1488 - accuracy: 0.9841\n",
      "Epoch 35: val_accuracy did not improve from 0.89300\n",
      "579/579 [==============================] - 144s 249ms/step - loss: 1.1488 - accuracy: 0.9841 - val_loss: 1.5143 - val_accuracy: 0.8911 - lr: 1.2500e-06\n",
      "Epoch 36/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1504 - accuracy: 0.9834\n",
      "Epoch 36: val_accuracy improved from 0.89300 to 0.89494, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 145s 249ms/step - loss: 1.1504 - accuracy: 0.9834 - val_loss: 1.5451 - val_accuracy: 0.8949 - lr: 1.2500e-06\n",
      "Epoch 37/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1452 - accuracy: 0.9836\n",
      "Epoch 37: val_accuracy did not improve from 0.89494\n",
      "579/579 [==============================] - 144s 249ms/step - loss: 1.1452 - accuracy: 0.9836 - val_loss: 1.5677 - val_accuracy: 0.8833 - lr: 1.2500e-06\n",
      "Epoch 38/100\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.1375 - accuracy: 0.9867\n",
      "Epoch 38: val_accuracy improved from 0.89494 to 0.90078, saving model to best_fingerprint_model.h5\n",
      "579/579 [==============================] - 145s 251ms/step - loss: 1.1375 - accuracy: 0.9867 - val_loss: 1.5291 - val_accuracy: 0.9008 - lr: 1.2500e-06\n",
      "Epoch 39/100\n",
      "145/579 [======>.......................] - ETA: 1:44 - loss: 1.1331 - accuracy: 0.9862"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# ModelCheckpoint to save the best model\u001b[39;00m\n\u001b[0;32m     29\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m     30\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_fingerprint_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     35\u001b[0m )\n\u001b[1;32m---> 37\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[0;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_fingerprint_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers[:-16]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(train_gen.num_classes, activation='softmax', \n",
    "                    kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-7)\n",
    "\n",
    "\n",
    "# # EarlyStopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,                 \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ModelCheckpoint to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_fingerprint_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "    epochs=100,\n",
    "    callbacks=[lr_scheduler, early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save(\"best_fingerprint_model.h5\")\n",
    "print(\"\\nâœ… Model trained and saved as best_fingerprint_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'001_1': 0, '001_2': 1, '001_3': 2, '001_4': 3, '001_5': 4, '001_6': 5, '002_10': 6, '002_11': 7, '002_12': 8, '002_7': 9, '002_8': 10, '002_9': 11, '003_13': 12, '003_14': 13, '003_15': 14, '003_16': 15, '003_17': 16, '003_18': 17, '004_19': 18, '004_20': 19, '004_21': 20, '004_22': 21, '004_23': 22, '004_24': 23, '005_25': 24, '005_26': 25, '005_27': 26, '005_28': 27, '005_29': 28, '005_30': 29, '006_31': 30, '006_32': 31, '006_33': 32, '006_34': 33, '006_35': 34, '006_36': 35, '007_37': 36, '007_38': 37, '007_39': 38, '007_40': 39, '007_41': 40, '007_42': 41, '008_43': 42, '008_44': 43, '008_45': 44, '009_46': 45, '009_47': 46, '009_48': 47, '009_49': 48, '009_50': 49, '009_51': 50, '010_52': 51, '010_53': 52, '010_54': 53, '010_55': 54, '010_56': 55, '010_57': 56, '010_58': 57, '010_59': 58, '010_60': 59, '010_61': 60, '011_62': 61, '011_63': 62, '011_64': 63, '011_65': 64, '011_66': 65, '011_67': 66, '011_68': 67, '011_69': 68, '011_70': 69, '011_71': 70, '012_72': 71, '012_73': 72, '012_74': 73, '012_75': 74, '012_76': 75, '012_77': 76, '012_78': 77, '012_79': 78, '012_80': 79, '012_81': 80, '013_82': 81, '013_83': 82, '013_84': 83, '013_85': 84, '013_86': 85, '013_87': 86, '013_88': 87, '013_89': 88, '013_90': 89, '013_91': 90, '014_100': 91, '014_101': 92, '014_92': 93, '014_93': 94, '014_94': 95, '014_95': 96, '014_96': 97, '014_97': 98, '014_98': 99, '014_99': 100, '015_102': 101, '015_103': 102, '015_104': 103, '015_105': 104, '015_106': 105, '016_107': 106, '016_108': 107, '016_109': 108, '016_110': 109, '016_111': 110, '016_112': 111, '016_113': 112, '016_114': 113, '016_115': 114, '016_116': 115, '017_117': 116, '017_118': 117, '017_119': 118, '017_120': 119, '017_121': 120, '017_122': 121, '017_123': 122, '017_124': 123, '017_125': 124, '017_126': 125, '018_127': 126, '018_128': 127, '018_129': 128, '018_130': 129, '018_131': 130, '018_132': 131, '018_133': 132, '018_134': 133, '018_135': 134, '018_136': 135, '019_137': 136, '019_138': 137, '019_139': 138, '019_140': 139, '019_141': 140, '019_142': 141, '019_143': 142, '019_144': 143, '019_145': 144, '019_146': 145, '020_147': 146, '020_148': 147, '020_149': 148, '020_150': 149, '020_151': 150, '020_152': 151, '020_153': 152, '020_154': 153, '020_155': 154, '020_156': 155, '021_157': 156, '021_158': 157, '021_159': 158, '021_160': 159, '021_161': 160, '021_162': 161, '021_163': 162, '021_164': 163, '021_165': 164, '021_166': 165, '022_167': 166, '022_168': 167, '022_169': 168, '022_170': 169, '022_171': 170, '022_172': 171, '022_173': 172, '022_174': 173, '022_175': 174, '022_176': 175, '023_177': 176, '023_178': 177, '023_179': 178, '023_180': 179, '023_181': 180, '023_182': 181, '023_183': 182, '023_184': 183, '023_185': 184, '023_186': 185, '024_187': 186, '024_188': 187, '024_189': 188, '024_190': 189, '024_191': 190, '024_192': 191, '024_193': 192, '024_194': 193, '024_195': 194, '024_196': 195, '025_197': 196, '025_198': 197, '025_199': 198, '025_200': 199, '025_201': 200, '025_202': 201, '025_203': 202, '025_204': 203, '025_205': 204, '025_206': 205, '026_207': 206, '026_208': 207, '026_209': 208, '026_210': 209, '026_211': 210, '026_212': 211, '026_213': 212, '026_214': 213, '026_215': 214, '026_216': 215, '027_217': 216, '027_218': 217, '027_219': 218, '027_220': 219, '027_221': 220, '027_222': 221, '027_223': 222, '027_224': 223, '027_225': 224, '027_226': 225, '028_227': 226, '028_228': 227, '028_229': 228, '028_230': 229, '028_231': 230, '028_232': 231, '028_233': 232, '028_234': 233, '028_235': 234, '028_236': 235, '029_237': 236, '029_238': 237, '029_239': 238, '029_240': 239, '029_241': 240, '029_242': 241, '029_243': 242, '029_244': 243, '030_245': 244, '030_246': 245, '030_247': 246, '030_248': 247, '030_249': 248, '030_250': 249, '030_251': 250, '030_252': 251, '031_253': 252, '031_254': 253, '031_255': 254, '031_256': 255, '031_257': 256}\n"
     ]
    }
   ],
   "source": [
    "print(test_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 4s 93ms/step - loss: 1.5291 - accuracy: 0.9008\n",
      "\n",
      "ðŸ“Š Test Loss: 1.5291\n",
      "âœ… Test Accuracy: 0.9008\n"
     ]
    }
   ],
   "source": [
    "# Load the best model from checkpoint before evaluation\n",
    "model = load_model(\"best_fingerprint_model.h5\")\n",
    "\n",
    "# Evaluate using the best model\n",
    "loss, accuracy = model.evaluate(test_gen)\n",
    "print(f\"\\nðŸ“Š Test Loss: {loss:.4f}\")\n",
    "print(f\"âœ… Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 3s 71ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.5000    0.6667         2\n",
      "         1.0     1.0000    1.0000    1.0000         2\n",
      "         2.0     1.0000    1.0000    1.0000         2\n",
      "         3.0     1.0000    1.0000    1.0000         2\n",
      "         4.0     1.0000    0.5000    0.6667         2\n",
      "         5.0     1.0000    1.0000    1.0000         2\n",
      "         6.0     1.0000    1.0000    1.0000         2\n",
      "         7.0     0.6667    1.0000    0.8000         2\n",
      "         8.0     1.0000    1.0000    1.0000         2\n",
      "         9.0     1.0000    1.0000    1.0000         2\n",
      "        10.0     1.0000    1.0000    1.0000         2\n",
      "        11.0     1.0000    0.5000    0.6667         2\n",
      "        12.0     1.0000    1.0000    1.0000         2\n",
      "        13.0     1.0000    1.0000    1.0000         2\n",
      "        14.0     1.0000    1.0000    1.0000         2\n",
      "        15.0     1.0000    0.5000    0.6667         2\n",
      "        16.0     1.0000    1.0000    1.0000         2\n",
      "        17.0     1.0000    1.0000    1.0000         2\n",
      "        18.0     1.0000    1.0000    1.0000         2\n",
      "        19.0     1.0000    1.0000    1.0000         2\n",
      "        20.0     1.0000    1.0000    1.0000         2\n",
      "        21.0     0.6667    1.0000    0.8000         2\n",
      "        22.0     1.0000    1.0000    1.0000         2\n",
      "        23.0     1.0000    1.0000    1.0000         2\n",
      "        24.0     1.0000    1.0000    1.0000         2\n",
      "        25.0     0.6667    1.0000    0.8000         2\n",
      "        26.0     1.0000    1.0000    1.0000         2\n",
      "        27.0     1.0000    1.0000    1.0000         2\n",
      "        28.0     0.5000    0.5000    0.5000         2\n",
      "        29.0     0.5000    0.5000    0.5000         2\n",
      "        30.0     0.6667    1.0000    0.8000         2\n",
      "        31.0     1.0000    1.0000    1.0000         2\n",
      "        32.0     1.0000    1.0000    1.0000         2\n",
      "        33.0     0.5000    0.5000    0.5000         2\n",
      "        34.0     0.6667    1.0000    0.8000         2\n",
      "        35.0     1.0000    1.0000    1.0000         2\n",
      "        36.0     0.5000    0.5000    0.5000         2\n",
      "        37.0     1.0000    0.5000    0.6667         2\n",
      "        38.0     1.0000    1.0000    1.0000         2\n",
      "        39.0     1.0000    1.0000    1.0000         2\n",
      "        40.0     1.0000    1.0000    1.0000         2\n",
      "        41.0     1.0000    0.5000    0.6667         2\n",
      "        42.0     0.3333    0.5000    0.4000         2\n",
      "        43.0     0.5000    0.5000    0.5000         2\n",
      "        44.0     1.0000    1.0000    1.0000         2\n",
      "        45.0     1.0000    1.0000    1.0000         2\n",
      "        46.0     1.0000    1.0000    1.0000         2\n",
      "        47.0     1.0000    1.0000    1.0000         2\n",
      "        48.0     1.0000    1.0000    1.0000         2\n",
      "        49.0     1.0000    1.0000    1.0000         2\n",
      "        50.0     1.0000    1.0000    1.0000         2\n",
      "        51.0     1.0000    1.0000    1.0000         2\n",
      "        52.0     0.6667    1.0000    0.8000         2\n",
      "        53.0     1.0000    1.0000    1.0000         2\n",
      "        54.0     1.0000    0.5000    0.6667         2\n",
      "        55.0     1.0000    1.0000    1.0000         2\n",
      "        56.0     1.0000    1.0000    1.0000         2\n",
      "        57.0     1.0000    1.0000    1.0000         2\n",
      "        58.0     1.0000    1.0000    1.0000         2\n",
      "        59.0     1.0000    1.0000    1.0000         2\n",
      "        60.0     1.0000    1.0000    1.0000         2\n",
      "        61.0     1.0000    1.0000    1.0000         2\n",
      "        62.0     1.0000    1.0000    1.0000         2\n",
      "        63.0     1.0000    1.0000    1.0000         2\n",
      "        64.0     0.5000    0.5000    0.5000         2\n",
      "        65.0     1.0000    1.0000    1.0000         2\n",
      "        66.0     1.0000    1.0000    1.0000         2\n",
      "        67.0     1.0000    1.0000    1.0000         2\n",
      "        68.0     0.6667    1.0000    0.8000         2\n",
      "        69.0     1.0000    1.0000    1.0000         2\n",
      "        70.0     1.0000    1.0000    1.0000         2\n",
      "        71.0     1.0000    1.0000    1.0000         2\n",
      "        72.0     1.0000    1.0000    1.0000         2\n",
      "        73.0     1.0000    1.0000    1.0000         2\n",
      "        74.0     1.0000    1.0000    1.0000         2\n",
      "        75.0     1.0000    1.0000    1.0000         2\n",
      "        76.0     1.0000    1.0000    1.0000         2\n",
      "        77.0     1.0000    1.0000    1.0000         2\n",
      "        78.0     1.0000    1.0000    1.0000         2\n",
      "        79.0     1.0000    1.0000    1.0000         2\n",
      "        80.0     1.0000    1.0000    1.0000         2\n",
      "        81.0     1.0000    1.0000    1.0000         2\n",
      "        82.0     1.0000    1.0000    1.0000         2\n",
      "        83.0     1.0000    1.0000    1.0000         2\n",
      "        84.0     1.0000    1.0000    1.0000         2\n",
      "        85.0     0.6667    1.0000    0.8000         2\n",
      "        86.0     1.0000    1.0000    1.0000         2\n",
      "        87.0     1.0000    1.0000    1.0000         2\n",
      "        88.0     1.0000    1.0000    1.0000         2\n",
      "        89.0     1.0000    1.0000    1.0000         2\n",
      "        90.0     1.0000    1.0000    1.0000         2\n",
      "        91.0     1.0000    1.0000    1.0000         2\n",
      "        92.0     1.0000    1.0000    1.0000         2\n",
      "        93.0     1.0000    1.0000    1.0000         2\n",
      "        94.0     1.0000    1.0000    1.0000         2\n",
      "        95.0     1.0000    1.0000    1.0000         2\n",
      "        96.0     1.0000    1.0000    1.0000         2\n",
      "        97.0     1.0000    0.5000    0.6667         2\n",
      "        98.0     1.0000    1.0000    1.0000         2\n",
      "        99.0     1.0000    1.0000    1.0000         2\n",
      "       100.0     0.5000    0.5000    0.5000         2\n",
      "       101.0     1.0000    1.0000    1.0000         2\n",
      "       102.0     0.6667    1.0000    0.8000         2\n",
      "       103.0     1.0000    1.0000    1.0000         2\n",
      "       104.0     1.0000    1.0000    1.0000         2\n",
      "       105.0     1.0000    1.0000    1.0000         2\n",
      "       106.0     1.0000    1.0000    1.0000         2\n",
      "       107.0     1.0000    1.0000    1.0000         2\n",
      "       108.0     1.0000    0.5000    0.6667         2\n",
      "       109.0     1.0000    1.0000    1.0000         2\n",
      "       110.0     1.0000    1.0000    1.0000         2\n",
      "       111.0     1.0000    1.0000    1.0000         2\n",
      "       112.0     1.0000    1.0000    1.0000         2\n",
      "       113.0     1.0000    0.5000    0.6667         2\n",
      "       114.0     1.0000    1.0000    1.0000         2\n",
      "       115.0     1.0000    1.0000    1.0000         2\n",
      "       116.0     0.6667    1.0000    0.8000         2\n",
      "       117.0     1.0000    1.0000    1.0000         2\n",
      "       118.0     1.0000    1.0000    1.0000         2\n",
      "       119.0     1.0000    1.0000    1.0000         2\n",
      "       120.0     1.0000    1.0000    1.0000         2\n",
      "       121.0     1.0000    1.0000    1.0000         2\n",
      "       122.0     1.0000    1.0000    1.0000         2\n",
      "       123.0     1.0000    1.0000    1.0000         2\n",
      "       124.0     1.0000    1.0000    1.0000         2\n",
      "       125.0     1.0000    1.0000    1.0000         2\n",
      "       126.0     1.0000    1.0000    1.0000         2\n",
      "       127.0     1.0000    1.0000    1.0000         2\n",
      "       128.0     1.0000    0.5000    0.6667         2\n",
      "       129.0     1.0000    1.0000    1.0000         2\n",
      "       130.0     1.0000    1.0000    1.0000         2\n",
      "       131.0     1.0000    1.0000    1.0000         2\n",
      "       132.0     1.0000    1.0000    1.0000         2\n",
      "       133.0     1.0000    1.0000    1.0000         2\n",
      "       134.0     0.5000    1.0000    0.6667         2\n",
      "       135.0     1.0000    1.0000    1.0000         2\n",
      "       136.0     1.0000    0.5000    0.6667         2\n",
      "       137.0     1.0000    0.5000    0.6667         2\n",
      "       138.0     1.0000    1.0000    1.0000         2\n",
      "       139.0     1.0000    1.0000    1.0000         2\n",
      "       140.0     0.6667    1.0000    0.8000         2\n",
      "       141.0     1.0000    1.0000    1.0000         2\n",
      "       142.0     1.0000    1.0000    1.0000         2\n",
      "       143.0     1.0000    1.0000    1.0000         2\n",
      "       144.0     1.0000    1.0000    1.0000         2\n",
      "       145.0     0.6667    1.0000    0.8000         2\n",
      "       146.0     0.6667    1.0000    0.8000         2\n",
      "       147.0     1.0000    0.5000    0.6667         2\n",
      "       148.0     1.0000    1.0000    1.0000         2\n",
      "       149.0     1.0000    1.0000    1.0000         2\n",
      "       150.0     1.0000    1.0000    1.0000         2\n",
      "       151.0     1.0000    1.0000    1.0000         2\n",
      "       152.0     1.0000    1.0000    1.0000         2\n",
      "       153.0     1.0000    1.0000    1.0000         2\n",
      "       154.0     1.0000    1.0000    1.0000         2\n",
      "       155.0     1.0000    1.0000    1.0000         2\n",
      "       156.0     1.0000    0.5000    0.6667         2\n",
      "       157.0     1.0000    0.5000    0.6667         2\n",
      "       158.0     0.6667    1.0000    0.8000         2\n",
      "       159.0     1.0000    1.0000    1.0000         2\n",
      "       160.0     1.0000    1.0000    1.0000         2\n",
      "       161.0     1.0000    1.0000    1.0000         2\n",
      "       162.0     0.6667    1.0000    0.8000         2\n",
      "       163.0     1.0000    1.0000    1.0000         2\n",
      "       164.0     1.0000    1.0000    1.0000         2\n",
      "       165.0     1.0000    0.5000    0.6667         2\n",
      "       166.0     1.0000    1.0000    1.0000         2\n",
      "       167.0     1.0000    1.0000    1.0000         2\n",
      "       168.0     1.0000    1.0000    1.0000         2\n",
      "       169.0     0.6667    1.0000    0.8000         2\n",
      "       170.0     1.0000    0.5000    0.6667         2\n",
      "       171.0     1.0000    1.0000    1.0000         2\n",
      "       172.0     1.0000    1.0000    1.0000         2\n",
      "       173.0     1.0000    1.0000    1.0000         2\n",
      "       174.0     1.0000    1.0000    1.0000         2\n",
      "       175.0     0.0000    0.0000    0.0000         2\n",
      "       176.0     0.0000    0.0000    0.0000         2\n",
      "       177.0     1.0000    1.0000    1.0000         2\n",
      "       178.0     1.0000    0.5000    0.6667         2\n",
      "       179.0     1.0000    0.5000    0.6667         2\n",
      "       180.0     0.5000    0.5000    0.5000         2\n",
      "       181.0     1.0000    0.5000    0.6667         2\n",
      "       182.0     0.6667    1.0000    0.8000         2\n",
      "       183.0     1.0000    0.5000    0.6667         2\n",
      "       184.0     1.0000    1.0000    1.0000         2\n",
      "       185.0     0.5000    1.0000    0.6667         2\n",
      "       186.0     1.0000    1.0000    1.0000         2\n",
      "       187.0     1.0000    1.0000    1.0000         2\n",
      "       188.0     1.0000    1.0000    1.0000         2\n",
      "       189.0     1.0000    1.0000    1.0000         2\n",
      "       190.0     1.0000    1.0000    1.0000         2\n",
      "       191.0     1.0000    1.0000    1.0000         2\n",
      "       192.0     1.0000    1.0000    1.0000         2\n",
      "       193.0     1.0000    1.0000    1.0000         2\n",
      "       194.0     1.0000    1.0000    1.0000         2\n",
      "       195.0     0.6667    1.0000    0.8000         2\n",
      "       196.0     1.0000    1.0000    1.0000         2\n",
      "       197.0     1.0000    1.0000    1.0000         2\n",
      "       198.0     0.6667    1.0000    0.8000         2\n",
      "       199.0     0.0000    0.0000    0.0000         2\n",
      "       200.0     0.3333    1.0000    0.5000         2\n",
      "       201.0     0.5000    1.0000    0.6667         2\n",
      "       202.0     0.0000    0.0000    0.0000         2\n",
      "       203.0     1.0000    0.5000    0.6667         2\n",
      "       204.0     1.0000    0.5000    0.6667         2\n",
      "       205.0     1.0000    0.5000    0.6667         2\n",
      "       206.0     0.0000    0.0000    0.0000         2\n",
      "       207.0     1.0000    1.0000    1.0000         2\n",
      "       208.0     1.0000    0.5000    0.6667         2\n",
      "       209.0     1.0000    1.0000    1.0000         2\n",
      "       210.0     1.0000    1.0000    1.0000         2\n",
      "       211.0     1.0000    1.0000    1.0000         2\n",
      "       212.0     1.0000    0.5000    0.6667         2\n",
      "       213.0     0.5000    1.0000    0.6667         2\n",
      "       214.0     1.0000    1.0000    1.0000         2\n",
      "       215.0     0.3333    0.5000    0.4000         2\n",
      "       216.0     1.0000    1.0000    1.0000         2\n",
      "       217.0     1.0000    0.5000    0.6667         2\n",
      "       218.0     0.6667    1.0000    0.8000         2\n",
      "       219.0     1.0000    1.0000    1.0000         2\n",
      "       220.0     1.0000    1.0000    1.0000         2\n",
      "       221.0     0.6667    1.0000    0.8000         2\n",
      "       222.0     1.0000    1.0000    1.0000         2\n",
      "       223.0     1.0000    1.0000    1.0000         2\n",
      "       224.0     1.0000    1.0000    1.0000         2\n",
      "       225.0     1.0000    1.0000    1.0000         2\n",
      "       226.0     1.0000    1.0000    1.0000         2\n",
      "       227.0     1.0000    0.5000    0.6667         2\n",
      "       228.0     1.0000    1.0000    1.0000         2\n",
      "       229.0     1.0000    1.0000    1.0000         2\n",
      "       230.0     1.0000    1.0000    1.0000         2\n",
      "       231.0     1.0000    1.0000    1.0000         2\n",
      "       232.0     1.0000    1.0000    1.0000         2\n",
      "       233.0     0.6667    1.0000    0.8000         2\n",
      "       234.0     1.0000    1.0000    1.0000         2\n",
      "       235.0     1.0000    0.5000    0.6667         2\n",
      "       236.0     1.0000    1.0000    1.0000         2\n",
      "       237.0     1.0000    1.0000    1.0000         2\n",
      "       238.0     1.0000    1.0000    1.0000         2\n",
      "       239.0     1.0000    1.0000    1.0000         2\n",
      "       240.0     1.0000    1.0000    1.0000         2\n",
      "       241.0     1.0000    1.0000    1.0000         2\n",
      "       242.0     1.0000    1.0000    1.0000         2\n",
      "       243.0     1.0000    1.0000    1.0000         2\n",
      "       244.0     1.0000    1.0000    1.0000         2\n",
      "       245.0     1.0000    1.0000    1.0000         2\n",
      "       246.0     1.0000    1.0000    1.0000         2\n",
      "       247.0     1.0000    1.0000    1.0000         2\n",
      "       248.0     1.0000    1.0000    1.0000         2\n",
      "       249.0     1.0000    1.0000    1.0000         2\n",
      "       250.0     1.0000    1.0000    1.0000         2\n",
      "       251.0     1.0000    1.0000    1.0000         2\n",
      "       252.0     1.0000    1.0000    1.0000         2\n",
      "       253.0     0.5000    1.0000    0.6667         2\n",
      "       254.0     1.0000    1.0000    1.0000         2\n",
      "       255.0     1.0000    0.5000    0.6667         2\n",
      "       256.0     1.0000    1.0000    1.0000         2\n",
      "\n",
      "    accuracy                         0.9008       514\n",
      "   macro avg     0.9189    0.9008    0.8946       514\n",
      "weighted avg     0.9189    0.9008    0.8946       514\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Calculate number of steps needed to cover all test samples\n",
    "steps = int(np.ceil(test_gen.samples / test_gen.batch_size))\n",
    "\n",
    "# Collect only the required number of batches\n",
    "for i in range(steps):\n",
    "    x, y = next(test_gen)\n",
    "    X_test.append(x)\n",
    "    y_test.append(y)\n",
    "\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test, batch_size=16)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Classification Report & Confusion Matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue Label\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\pyplot.py:612\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    611\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\decorator.py:235\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    234\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\backend_bases.py:2178\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2178\u001b[0m         bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2180\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(layout_engine, ConstrainedLayoutEngine) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   2181\u001b[0m                 pad_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2182\u001b[0m             h_pad \u001b[38;5;241m=\u001b[39m layout_engine\u001b[38;5;241m.\u001b[39mget()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:457\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    452\u001b[0m     warn_deprecated(\n\u001b[0;32m    453\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    456\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\figure.py:1787\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[1;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m# some Axes don't take the bbox_extra_artists kwarg so we\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m# need this conditional....\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1787\u001b[0m         bbox \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1790\u001b[0m         bbox \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:457\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    452\u001b[0m     warn_deprecated(\n\u001b[0;32m    453\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    456\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\axes\\_base.py:4499\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[1;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[0;32m   4496\u001b[0m     bbox_artists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_default_bbox_extra_artists()\n\u001b[0;32m   4498\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m bbox_artists:\n\u001b[1;32m-> 4499\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4501\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m bbox\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m   4502\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m bbox\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39minf):\n\u001b[0;32m   4503\u001b[0m         bb\u001b[38;5;241m.\u001b[39mappend(bbox)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\artist.py:365\u001b[0m, in \u001b[0;36mArtist.get_tightbbox\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_tightbbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m    Like `.Artist.get_window_extent`, but includes any clipping.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m        Returns None if clipping results in no intersection.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_on():\n\u001b[0;32m    367\u001b[0m         clip_box \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_box()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\text.py:961\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    959\u001b[0m bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_layout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer)\n\u001b[0;32m    960\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[1;32m--> 961\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    962\u001b[0m bbox \u001b[38;5;241m=\u001b[39m bbox\u001b[38;5;241m.\u001b[39mtranslated(x, y)\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bbox\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\transforms.py:1505\u001b[0m, in \u001b[0;36mTransform.transform\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m   1502\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dims))\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# Transform the values\u001b[39;00m\n\u001b[1;32m-> 1505\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_non_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# Convert the result back to the shape of the input values.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:300\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m     warn_deprecated(\n\u001b[0;32m    296\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    299\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[1;32m--> 300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\transforms.py:2428\u001b[0m, in \u001b[0;36mCompositeGenericTransform.transform_affine\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m   2425\u001b[0m \u001b[38;5;129m@_api\u001b[39m\u001b[38;5;241m.\u001b[39mrename_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform_affine\u001b[39m(\u001b[38;5;28mself\u001b[39m, values):\n\u001b[0;32m   2427\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[1;32m-> 2428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(values)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\transforms.py:2455\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[0;32m   2454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Affine2D(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2456\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Reset the generator before iterating\n",
    "test_gen.reset()\n",
    "steps = int(np.ceil(test_gen.samples / test_gen.batch_size))\n",
    "\n",
    "for _ in range(steps):\n",
    "    x_batch, y_batch = next(test_gen)\n",
    "\n",
    "    # Handle one-hot encoded or integer labels\n",
    "    if y_batch.ndim > 1:\n",
    "        y_true.extend(np.argmax(y_batch, axis=1))\n",
    "    else:\n",
    "        y_true.extend(y_batch)\n",
    "\n",
    "    preds = model.predict(x_batch)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", linewidths=0.5, linecolor='gray')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro Avg - Precision: 0.8903, Recall: 0.8794, F1 Score: 0.8668\n",
      "Weighted Avg - Precision: 0.8903, Recall: 0.8794, F1 Score: 0.8668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Macro averages (treats all classes equally)\n",
    "precision_macro = report['macro avg']['precision']\n",
    "recall_macro = report['macro avg']['recall']\n",
    "f1_macro = report['macro avg']['f1-score']\n",
    "\n",
    "# Weighted averages (accounts for class imbalance)\n",
    "precision_weighted = report['weighted avg']['precision']\n",
    "recall_weighted = report['weighted avg']['recall']\n",
    "f1_weighted = report['weighted avg']['f1-score']\n",
    "\n",
    "print(f\"\\nMacro Avg - Precision: {precision_macro:.4f}, Recall: {recall_macro:.4f}, F1 Score: {f1_macro:.4f}\")\n",
    "print(f\"Weighted Avg - Precision: {precision_weighted:.4f}, Recall: {recall_weighted:.4f}, F1 Score: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score (macro): 0.9976\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode true labels\n",
    "y_test_onehot = label_binarize(y_test, classes=np.arange(model.output_shape[-1]))\n",
    "\n",
    "# y_pred_probs: already predicted earlier like this\n",
    "# y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Multi-class ROC AUC using 'macro' average\n",
    "roc_auc = roc_auc_score(y_test_onehot, y_pred_probs, average='macro', multi_class='ovr')\n",
    "\n",
    "print(f\"ROC AUC Score (macro): {roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
