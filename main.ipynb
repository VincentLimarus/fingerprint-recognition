{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = \"./assets/2002_4\"\n",
    "\n",
    "if not directory:\n",
    "    directory = input(\"Input raw dataset directory:\")\n",
    "\n",
    "files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "count = 1\n",
    "if files:\n",
    "    curr = files[0].split(\"_\")[0]\n",
    "else:\n",
    "    print(\"No files found in the directory.\")\n",
    "    exit()\n",
    "\n",
    "for file in files:\n",
    "    file_split = file.split(\"_\")\n",
    "    if file_split[0] != curr:\n",
    "        curr = file_split[0]\n",
    "        count += 1\n",
    "    \n",
    "    new_file_name = \"_\".join(file_split[1:])\n",
    "    new_file_name = str(count).zfill(3) + \"_\" + new_file_name\n",
    "    \n",
    "    old_path = os.path.join(directory, file)\n",
    "    new_path = os.path.join(directory, new_file_name)\n",
    "    \n",
    "    os.rename(old_path, new_path)\n",
    "    print(f\"Successfully changed file name from ({file}) to ({new_file_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def skeletonize(img):\n",
    "    \"\"\"Alternative skeletonization implementation without ximgproc\"\"\"\n",
    "    skel = np.zeros(img.shape, np.uint8)\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "    while True:\n",
    "        open_img = cv2.morphologyEx(img, cv2.MORPH_OPEN, element)\n",
    "        temp = cv2.subtract(img, open_img)\n",
    "        eroded = cv2.erode(img, element)\n",
    "        skel = cv2.bitwise_or(skel, temp)\n",
    "        img = eroded.copy()\n",
    "        if cv2.countNonZero(img) == 0:\n",
    "            break\n",
    "    return skel\n",
    "\n",
    "def process_fingerprint(image_path, output_path, target_size=None, upscale_factor=1.0):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "    \n",
    "    # Resize if needed\n",
    "    if target_size:\n",
    "        image = cv2.resize(image, target_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    elif upscale_factor != 1.0:\n",
    "        h, w = image.shape\n",
    "        image = cv2.resize(image, (int(w*upscale_factor), int(h*upscale_factor)), \n",
    "                         interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    # 1. Contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(image)\n",
    "    \n",
    "    # 2. Noise reduction\n",
    "    denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
    "    \n",
    "    # 3. Adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY_INV, 21, 7)\n",
    "    \n",
    "    # 4. Morphological operations\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    # 5. Skeletonization (using alternative method)\n",
    "    skeleton = skeletonize(morph)\n",
    "    \n",
    "    # 6. Final inversion and saving\n",
    "    result = cv2.bitwise_not(skeleton)\n",
    "    cv2.imwrite(output_path, result)\n",
    "\n",
    "def batch_process_fingerprints(input_folder, output_folder, upscale=False):\n",
    "    \"\"\"\n",
    "    Process all fingerprints in a folder\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    files = [f for f in os.listdir(input_folder) if f.lower().endswith('.tif')]\n",
    "    \n",
    "    for filename in tqdm(files, desc=\"Processing Fingerprints\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            if upscale:\n",
    "                process_fingerprint(input_path, output_path, upscale_factor=2.0)\n",
    "            else:\n",
    "                process_fingerprint(input_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {filename}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_FOLDER = \"assets\"\n",
    "    OUTPUT_FOLDER = \"processed\"\n",
    "    UPSCALE_IMAGES = True  # Set to True for 2x upscaling\n",
    "    \n",
    "    print(\"Starting fingerprint processing...\")\n",
    "    batch_process_fingerprints(INPUT_FOLDER, OUTPUT_FOLDER, upscale=UPSCALE_IMAGES)\n",
    "    print(\"\\nProcessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "dataset_folder = \"processed\"\n",
    "train_folder = \"dataset/train\"\n",
    "test_folder = \"dataset/test\"\n",
    "\n",
    "# Create train and test folders\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Get all image files\n",
    "all_files = [f for f in os.listdir(dataset_folder) if f.endswith('.tif')]  # Only get .tif files\n",
    "\n",
    "# Separate files: _1.tif for test, others for train\n",
    "test_files = [f for f in all_files if f.endswith(\"_1.tif\")]\n",
    "train_files = [f for f in all_files]  # Exclude test files from train\n",
    "\n",
    "print(f\"Found {len(all_files)} total fingerprint images\")\n",
    "print(f\"- Training images: {len(train_files)}\")\n",
    "print(f\"- Test images: {len(test_files)}\")\n",
    "\n",
    "# Function to copy files\n",
    "def copy_files(file_list, destination_folder):\n",
    "    for file in tqdm(file_list, desc=f\"Copying to {os.path.basename(destination_folder)}\"):\n",
    "        src = os.path.join(dataset_folder, file)\n",
    "        dest = os.path.join(destination_folder, file)\n",
    "        shutil.copy2(src, dest)\n",
    "\n",
    "# Copy files to respective folders\n",
    "copy_files(train_files, train_folder)\n",
    "copy_files(test_files, test_folder)\n",
    "\n",
    "print(\"\\nDataset organization completed:\")\n",
    "print(f\"- Training set: {len(train_files)} images (copied to {train_folder})\")\n",
    "print(f\"- Test set: {len(test_files)} images (copied to {test_folder})\")\n",
    "print(f\"Original files remain intact in {dataset_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path configuration\n",
    "test_dir = os.path.join(\"dataset\", \"test\")\n",
    "\n",
    "def apply_block_damage(image, block_size=70, num_blocks=10):\n",
    "    \"\"\"Apply rectangular block damage to fingerprint image with WHITE blocks\"\"\"\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = random.randint(0, width - block_size)\n",
    "        y = random.randint(0, height - block_size)\n",
    "        damaged[y:y+block_size, x:x+block_size] = 255  # White blocks (changed from 0 to 255)\n",
    "    return damaged\n",
    "\n",
    "# Get all test images\n",
    "test_images = [f for f in os.listdir(test_dir) if f.endswith(\"_1.tif\")]\n",
    "print(f\"Found {len(test_images)} test images to process\")\n",
    "\n",
    "# Process all images with block damage (overwriting originals)\n",
    "for filename in tqdm(test_images, desc=\"Applying block damage\"):\n",
    "    image_path = os.path.join(test_dir, filename)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is not None:\n",
    "        # Apply block damage and overwrite original\n",
    "        damaged_image = apply_block_damage(image)\n",
    "        cv2.imwrite(image_path, damaged_image)\n",
    "\n",
    "print(f\"\\nSuccessfully applied block damage to {len(test_images)} images\")\n",
    "print(f\"Original images in {test_dir} have been overwritten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOT FINAL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Lambda, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Konfigurasi path\n",
    "train_dir = \"./dataset/train/\"\n",
    "test_dir = \"./dataset/test/\"\n",
    "\n",
    "# Parameter\n",
    "IMG_SIZE = (600, 600)  # Pertahankan resolusi tinggi\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 30\n",
    "NUM_CLASSES = 80  # 80 individu berbeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First image size: (600, 600)\n"
     ]
    }
   ],
   "source": [
    "# Load semua path gambar dan label\n",
    "def load_data_paths(directory):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.tif'):\n",
    "            # Format nama file: 'ID_XXX.tif' (contoh: '001_1.tif')\n",
    "            class_id = filename.split('_')[0]  \n",
    "            image_paths.append(os.path.join(directory, filename))\n",
    "            labels.append(int(class_id) - 1)  # Konversi ke indeks 0-based\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "# Load data train dan test\n",
    "train_paths, train_labels = load_data_paths(train_dir)\n",
    "test_paths, test_labels = load_data_paths(test_dir)\n",
    "\n",
    "sample_img = cv2.imread(train_paths[0], cv2.IMREAD_GRAYSCALE)\n",
    "print(f\"\\nFirst image size: {sample_img.shape}\")  # Should be (height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(600,600)):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img_rgb = np.stack([img]*3, axis=-1)\n",
    "    return img_rgb / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerprintDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_paths, labels, batch_size=BATCH_SIZE, img_size=IMG_SIZE, augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))  # Fix: Calculate based on paths\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.image_paths[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        batch_labels = self.labels[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for path, label in zip(batch_paths, batch_labels):\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, self.img_size)  # Force resize\n",
    "            img_rgb = np.stack([img]*3, axis=-1)\n",
    "            img_normalized = img_rgb / 255.0\n",
    "            X.append(img_normalized)\n",
    "            y.append(label)\n",
    "        \n",
    "        return np.array(X), tf.keras.utils.to_categorical(np.array(y), num_classes=NUM_CLASSES)\n",
    "\n",
    "# Create generators\n",
    "train_generator = FingerprintDataGenerator(train_paths, train_labels, augment=True)\n",
    "test_generator = FingerprintDataGenerator(test_paths, test_labels, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16_600x600(num_classes):\n",
    "    # Input layer for 600x600 RGB\n",
    "    input_tensor = Input(shape=(600, 600, 3))\n",
    "    \n",
    "    # Load VGG16 without FC layers\n",
    "    base_model = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=input_tensor\n",
    "    )\n",
    "    \n",
    "    # Freeze all VGG layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Custom head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_vgg16_600x600(NUM_CLASSES)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_69']\n",
      "Received: inputs=Tensor(shape=(None, 600, 600, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m33s\u001b[0m 4s/step - accuracy: 0.0172 - loss: 4.5610"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'vgg16_600x600_best.h5',\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy'\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "]\n",
    "\n",
    "# 9. Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 10. Evaluation\n",
    "best_model = tf.keras.models.load_model('vgg16_600x600_best.h5')\n",
    "test_loss, test_acc = best_model.evaluate(test_generator)\n",
    "print(f'\\nTest Accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi label\n",
    "y_pred = np.argmax(best_model.predict(test_generator), axis=1)\n",
    "y_true = test_generator.labels[:len(test_generator.image_paths)]\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
