{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = \"./assets\"\n",
    "\n",
    "if not directory:\n",
    "    directory = input(\"Input raw dataset directory:\")\n",
    "\n",
    "files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "count = 1\n",
    "if files:\n",
    "    curr = files[0].split(\"_\")[0]\n",
    "else:\n",
    "    print(\"No files found in the directory.\")\n",
    "    exit()\n",
    "\n",
    "for file in files:\n",
    "    file_split = file.split(\"_\")\n",
    "    if file_split[0] != curr:\n",
    "        curr = file_split[0]\n",
    "        count += 1\n",
    "    \n",
    "    new_file_name = \"_\".join(file_split[1:])\n",
    "    new_file_name = str(count).zfill(3) + \"_\" + new_file_name\n",
    "    \n",
    "    old_path = os.path.join(directory, file)\n",
    "    new_path = os.path.join(directory, new_file_name)\n",
    "    \n",
    "    os.rename(old_path, new_path)\n",
    "    print(f\"Successfully changed file name from ({file}) to ({new_file_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def skeletonize(img):\n",
    "    \"\"\"Alternative skeletonization implementation without ximgproc\"\"\"\n",
    "    skel = np.zeros(img.shape, np.uint8)\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "    while True:\n",
    "        open_img = cv2.morphologyEx(img, cv2.MORPH_OPEN, element)\n",
    "        temp = cv2.subtract(img, open_img)\n",
    "        eroded = cv2.erode(img, element)\n",
    "        skel = cv2.bitwise_or(skel, temp)\n",
    "        img = eroded.copy()\n",
    "        if cv2.countNonZero(img) == 0:\n",
    "            break\n",
    "    return skel\n",
    "\n",
    "def process_fingerprint(image_path, output_path, target_size=None, upscale_factor=1.0):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "    \n",
    "    # Resize if needed\n",
    "    if target_size:\n",
    "        image = cv2.resize(image, target_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    elif upscale_factor != 1.0:\n",
    "        h, w = image.shape\n",
    "        image = cv2.resize(image, (int(w*upscale_factor), int(h*upscale_factor)), \n",
    "                         interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    # 1. Contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(image)\n",
    "    \n",
    "    # 2. Noise reduction\n",
    "    denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
    "    \n",
    "    # 3. Adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY_INV, 21, 7)\n",
    "    \n",
    "    # 4. Morphological operations\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    # 5. Skeletonization (using alternative method)\n",
    "    skeleton = skeletonize(morph)\n",
    "    \n",
    "    # 6. Final inversion and saving\n",
    "    result = cv2.bitwise_not(skeleton)\n",
    "    cv2.imwrite(output_path, result)\n",
    "\n",
    "def batch_process_fingerprints(input_folder, output_folder, upscale=False):\n",
    "    \"\"\"\n",
    "    Process all fingerprints in a folder\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    files = [f for f in os.listdir(input_folder) if f.lower().endswith('.tif')]\n",
    "    \n",
    "    for filename in tqdm(files, desc=\"Processing Fingerprints\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            if upscale:\n",
    "                process_fingerprint(input_path, output_path, upscale_factor=2.0)\n",
    "            else:\n",
    "                process_fingerprint(input_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {filename}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_FOLDER = \"assets\"\n",
    "    OUTPUT_FOLDER = \"processed\"\n",
    "    UPSCALE_IMAGES = True  # Set to True for 2x upscaling\n",
    "    \n",
    "    print(\"Starting fingerprint processing...\")\n",
    "    batch_process_fingerprints(INPUT_FOLDER, OUTPUT_FOLDER, upscale=UPSCALE_IMAGES)\n",
    "    print(\"\\nProcessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)  # Ensures the same split every time you run the code\n",
    "\n",
    "# Define paths\n",
    "dataset_folder = \"processed\"\n",
    "train_folder = \"dataset/train\"\n",
    "test_folder = \"dataset/test\"\n",
    "\n",
    "# Create train and test folders\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Get all image files and shuffle them\n",
    "all_files = [f for f in os.listdir(dataset_folder) if f.endswith('.tif')]\n",
    "random.shuffle(all_files)  # Shuffle to ensure random distribution\n",
    "\n",
    "# Calculate split index (80% train, 20% test)\n",
    "split_idx = int(0.8 * len(all_files))\n",
    "train_files = all_files[:split_idx]  # First 80% for training\n",
    "test_files = all_files[split_idx:]   # Remaining 20% for testing\n",
    "\n",
    "print(f\"Found {len(all_files)} total fingerprint images\")\n",
    "print(f\"- Training images: {len(train_files)} (80%)\")\n",
    "print(f\"- Test images: {len(test_files)} (20%)\")\n",
    "\n",
    "# Function to copy files\n",
    "def copy_files(file_list, destination_folder):\n",
    "    for file in tqdm(file_list, desc=f\"Copying to {os.path.basename(destination_folder)}\"):\n",
    "        src = os.path.join(dataset_folder, file)\n",
    "        dest = os.path.join(destination_folder, file)\n",
    "        shutil.copy2(src, dest)\n",
    "\n",
    "# Copy files to respective folders\n",
    "copy_files(train_files, train_folder)\n",
    "copy_files(test_files, test_folder)\n",
    "\n",
    "print(\"\\nDataset organization completed:\")\n",
    "print(f\"- Training set: {len(train_files)} images (copied to {train_folder})\")\n",
    "print(f\"- Test set: {len(test_files)} images (copied to {test_folder})\")\n",
    "print(f\"Original files remain intact in {dataset_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path configuration\n",
    "test_dir = os.path.join(\"dataset\", \"test\")\n",
    "\n",
    "def apply_block_damage(image, block_size=70, num_blocks=10):\n",
    "    \"\"\"Apply rectangular white block damage to fingerprint image.\"\"\"\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        # Ensure blocks don't go out of bounds\n",
    "        x = random.randint(0, max(0, width - block_size - 1))\n",
    "        y = random.randint(0, max(0, height - block_size - 1))\n",
    "        damaged[y:y+block_size, x:x+block_size] = 255  # White blocks\n",
    "    return damaged\n",
    "\n",
    "# Get all test images (include all .tif files)\n",
    "test_images = [f for f in os.listdir(test_dir) if f.endswith(\".tif\")]\n",
    "print(f\"Found {len(test_images)} test images to process\")\n",
    "\n",
    "# Process and overwrite originals (with progress bar)\n",
    "for filename in tqdm(test_images, desc=\"Damaging images\"):\n",
    "    image_path = os.path.join(test_dir, filename)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is not None:\n",
    "        damaged_image = apply_block_damage(image)\n",
    "        cv2.imwrite(image_path, damaged_image)  # Overwrite original\n",
    "\n",
    "print(f\"\\nOverwritten {len(test_images)} images with block damage in {test_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST NEW APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "train_dir = \"dataset/train\"\n",
    "test_dir = \"dataset/test\"\n",
    "batch_size = 32\n",
    "img_size = (224, 224)  # Resize images\n",
    "\n",
    "# Get all .tif images\n",
    "image_files = [f for f in os.listdir(train_dir) if f.endswith(\".tif\")]\n",
    "\n",
    "# Extract class labels from filenames (e.g., \"001_1.tif\" → class 001 → index 0)\n",
    "class_labels = sorted(set(f.split(\"_\")[0] for f in image_files))  # Unique classes\n",
    "class_to_index = {label: i for i, label in enumerate(class_labels)}\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_image(filename, dir_path, class_to_index):\n",
    "    img_path = os.path.join(dir_path, filename)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # still loading in grayscale\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)           # (224, 224, 1)\n",
    "    img = np.repeat(img, 3, axis=-1)             # (224, 224, 3) → RGB from grayscale\n",
    "\n",
    "    class_id = filename.split(\"_\")[0]\n",
    "    label = class_to_index[class_id]\n",
    "\n",
    "    return img, label\n",
    "\n",
    "# Load all images into memory\n",
    "dataset = [load_image(f, train_dir, class_to_index) for f in image_files]\n",
    "\n",
    "# Convert to TensorFlow dataset\n",
    "X, y = zip(*dataset)  # Split images and labels\n",
    "X = np.array(X, dtype=np.float32)  # Convert to NumPy array\n",
    "y = np.array(y, dtype=np.int32)\n",
    "\n",
    "# Create tf.data.Dataset\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "tf_dataset = tf_dataset.batch(batch_size).shuffle(len(y))\n",
    "\n",
    "print(f\"✅ Loaded {len(y)} images into a TensorFlow dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [f for f in os.listdir(train_dir) if f.endswith(\".tif\")]\n",
    "train_labels = sorted(set(f.split(\"_\")[0] for f in train_files))\n",
    "class_to_index = {label: i for i, label in enumerate(train_labels)}\n",
    "\n",
    "# Load training data\n",
    "train_data = [load_image(f, train_dir, class_to_index) for f in train_files]\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "\n",
    "# Convert to tf.data.Dataset and batch it\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "tf_dataset = tf_dataset.shuffle(len(y_train)).batch(batch_size)\n",
    "\n",
    "print(f\"✅ Loaded {len(y_train)} training images into TensorFlow dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_files = [f for f in os.listdir(test_dir) if f.endswith(\".tif\")]\n",
    "\n",
    "# Function to load and preprocess test images\n",
    "test_dataset = [load_image(f, test_dir, class_to_index) for f in test_image_files]\n",
    "\n",
    "# Convert to TensorFlow test dataset\n",
    "X_test, y_test = zip(*test_dataset)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.int32)\n",
    "\n",
    "# Create tf.data.Dataset for testing\n",
    "tf_test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "tf_test_dataset = tf_test_dataset.batch(batch_size)\n",
    "print(f\"✅ Loaded {len(y_test)} training images into TensorFlow dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.05),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomBrightness(factor=0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "def augment(image, label):\n",
    "    return data_augmentation(image), label\n",
    "\n",
    "# Apply augmentation before batching\n",
    "tf_dataset = tf_dataset.map(augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input, Conv2D, MaxPooling2D\n",
    "\n",
    "# Number of classes (adjust dynamically)\n",
    "num_classes = 80  # Since your classes range from 001 to 080\n",
    "\n",
    "# Input shape (grayscale images need 3 channels for VGG16)\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Load VGG16 with pre-trained weights (exclude top layers)\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Freeze the base model (VGG16) to retain pre-trained weights\n",
    "base_model.trainable = False  \n",
    "\n",
    "# Add custom layers on top of VGG16\n",
    "x = base_model.output\n",
    "x = Flatten()(x)  # Flatten features\n",
    "x = Dense(1024, activation=\"relu\")(x)  # Fully connected layer\n",
    "x = Dropout(0.5)(x)  # Regularization\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(num_classes, activation=\"softmax\")(x)  # Classification layer\n",
    "\n",
    "# Define model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Print summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile with a smaller learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# LR Scheduler (dipakai ulang)\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1\n",
    ")\n",
    "\n",
    "# === STAGE 1 ===\n",
    "ckpt_1 = ModelCheckpoint(\"model_stage1.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(tf_dataset,\n",
    "          validation_data=tf_test_dataset,\n",
    "          epochs=30,\n",
    "          callbacks=[lr_scheduler, ckpt_1])\n",
    "\n",
    "# === STAGE 2 ===\n",
    "ckpt_2 = ModelCheckpoint(\"model_stage2.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(tf_dataset,\n",
    "          validation_data=tf_test_dataset,\n",
    "          epochs=15,\n",
    "          callbacks=[lr_scheduler, ckpt_2])\n",
    "\n",
    "# === STAGE 3 ===\n",
    "ckpt_3 = ModelCheckpoint(\"model_stage3.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(tf_dataset,\n",
    "          validation_data=tf_test_dataset,\n",
    "          epochs=15,\n",
    "          callbacks=[lr_scheduler, ckpt_3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(tf_test_dataset) # 60 epochs -> 0.9301\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")               # 69 epochs -> 0.9462\n",
    "print(f\"Test Loss: {test_loss:.4f}\")                  # 88 epochs -> 0.9624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for x, y in tf_test_dataset:\n",
    "    X_test.append(x.numpy())\n",
    "    y_test.append(y.numpy())\n",
    "\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Classification Report & Confusion Matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Ambil semua label asli & prediksi\n",
    "y_true = np.concatenate([y.numpy() for _, y in tf_test_dataset], axis=0)\n",
    "y_pred = np.concatenate([np.argmax(model.predict(x), axis=1) for x, _ in tf_test_dataset], axis=0)\n",
    "\n",
    "# Buat confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualisasi pakai heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
