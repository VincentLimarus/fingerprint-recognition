{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = \"./assets/2002_4\"\n",
    "\n",
    "if not directory:\n",
    "    directory = input(\"Input raw dataset directory:\")\n",
    "\n",
    "files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "count = 1\n",
    "if files:\n",
    "    curr = files[0].split(\"_\")[0]\n",
    "else:\n",
    "    print(\"No files found in the directory.\")\n",
    "    exit()\n",
    "\n",
    "for file in files:\n",
    "    file_split = file.split(\"_\")\n",
    "    if file_split[0] != curr:\n",
    "        curr = file_split[0]\n",
    "        count += 1\n",
    "    \n",
    "    new_file_name = \"_\".join(file_split[1:])\n",
    "    new_file_name = str(count).zfill(3) + \"_\" + new_file_name\n",
    "    \n",
    "    old_path = os.path.join(directory, file)\n",
    "    new_path = os.path.join(directory, new_file_name)\n",
    "    \n",
    "    os.rename(old_path, new_path)\n",
    "    print(f\"Successfully changed file name from ({file}) to ({new_file_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fingerprint processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Fingerprints: 100%|██████████| 640/640 [00:17<00:00, 35.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def skeletonize(img):\n",
    "    \"\"\"Alternative skeletonization implementation without ximgproc\"\"\"\n",
    "    skel = np.zeros(img.shape, np.uint8)\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "    while True:\n",
    "        open_img = cv2.morphologyEx(img, cv2.MORPH_OPEN, element)\n",
    "        temp = cv2.subtract(img, open_img)\n",
    "        eroded = cv2.erode(img, element)\n",
    "        skel = cv2.bitwise_or(skel, temp)\n",
    "        img = eroded.copy()\n",
    "        if cv2.countNonZero(img) == 0:\n",
    "            break\n",
    "    return skel\n",
    "\n",
    "def process_fingerprint(image_path, output_path, target_size=None, upscale_factor=1.0):\n",
    "    \"\"\"\n",
    "    Enhanced fingerprint processing pipeline with optional upscaling\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "    \n",
    "    # Resize if needed\n",
    "    if target_size:\n",
    "        image = cv2.resize(image, target_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    elif upscale_factor != 1.0:\n",
    "        h, w = image.shape\n",
    "        image = cv2.resize(image, (int(w*upscale_factor), int(h*upscale_factor)), \n",
    "                         interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    # 1. Contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(image)\n",
    "    \n",
    "    # 2. Noise reduction\n",
    "    denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
    "    \n",
    "    # 3. Adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY_INV, 21, 7)\n",
    "    \n",
    "    # 4. Morphological operations\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    # 5. Skeletonization (using alternative method)\n",
    "    skeleton = skeletonize(morph)\n",
    "    \n",
    "    # 6. Final inversion and saving\n",
    "    result = cv2.bitwise_not(skeleton)\n",
    "    cv2.imwrite(output_path, result)\n",
    "\n",
    "def batch_process_fingerprints(input_folder, output_folder, upscale=False):\n",
    "    \"\"\"\n",
    "    Process all fingerprints in a folder\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    files = [f for f in os.listdir(input_folder) if f.lower().endswith('.tif')]\n",
    "    \n",
    "    for filename in tqdm(files, desc=\"Processing Fingerprints\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            if upscale:\n",
    "                process_fingerprint(input_path, output_path, upscale_factor=2.0)\n",
    "            else:\n",
    "                process_fingerprint(input_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {filename}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_FOLDER = \"assets\"\n",
    "    OUTPUT_FOLDER = \"processed\"\n",
    "    UPSCALE_IMAGES = True  # Set to True for 2x upscaling\n",
    "    \n",
    "    print(\"Starting fingerprint processing...\")\n",
    "    batch_process_fingerprints(INPUT_FOLDER, OUTPUT_FOLDER, upscale=UPSCALE_IMAGES)\n",
    "    print(\"\\nProcessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 total fingerprint images\n",
      "- Training images: 640\n",
      "- Test images: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying to train: 100%|██████████| 640/640 [00:00<00:00, 906.78it/s]\n",
      "Copying to test: 100%|██████████| 80/80 [00:00<00:00, 714.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset organization completed:\n",
      "- Training set: 640 images (copied to dataset/train)\n",
      "- Test set: 80 images (copied to dataset/test)\n",
      "Original files remain intact in processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "dataset_folder = \"processed\"\n",
    "train_folder = \"dataset/train\"\n",
    "test_folder = \"dataset/test\"\n",
    "\n",
    "# Create train and test folders\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Get all image files\n",
    "all_files = [f for f in os.listdir(dataset_folder) if f.endswith('.tif')]  # Only get .tif files\n",
    "\n",
    "# Separate files: _1.tif for test, others for train\n",
    "test_files = [f for f in all_files if f.endswith(\"_1.tif\")]\n",
    "train_files = [f for f in all_files]  # Exclude test files from train\n",
    "\n",
    "print(f\"Found {len(all_files)} total fingerprint images\")\n",
    "print(f\"- Training images: {len(train_files)}\")\n",
    "print(f\"- Test images: {len(test_files)}\")\n",
    "\n",
    "# Function to copy files\n",
    "def copy_files(file_list, destination_folder):\n",
    "    for file in tqdm(file_list, desc=f\"Copying to {os.path.basename(destination_folder)}\"):\n",
    "        src = os.path.join(dataset_folder, file)\n",
    "        dest = os.path.join(destination_folder, file)\n",
    "        shutil.copy2(src, dest)\n",
    "\n",
    "# Copy files to respective folders\n",
    "copy_files(train_files, train_folder)\n",
    "copy_files(test_files, test_folder)\n",
    "\n",
    "print(\"\\nDataset organization completed:\")\n",
    "print(f\"- Training set: {len(train_files)} images (copied to {train_folder})\")\n",
    "print(f\"- Test set: {len(test_files)} images (copied to {test_folder})\")\n",
    "print(f\"Original files remain intact in {dataset_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 test images to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying block damage: 100%|██████████| 80/80 [00:01<00:00, 47.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully applied block damage to 80 images\n",
      "Original images in dataset\\test have been overwritten\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path configuration\n",
    "test_dir = os.path.join(\"dataset\", \"test\")\n",
    "\n",
    "def apply_block_damage(image, block_size=40, num_blocks=10):\n",
    "    \"\"\"Apply rectangular block damage to fingerprint image with WHITE blocks\"\"\"\n",
    "    damaged = np.copy(image)\n",
    "    height, width = image.shape\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = random.randint(0, width - block_size)\n",
    "        y = random.randint(0, height - block_size)\n",
    "        damaged[y:y+block_size, x:x+block_size] = 255  # White blocks (changed from 0 to 255)\n",
    "    \n",
    "    return damaged\n",
    "\n",
    "# Get all test images\n",
    "test_images = [f for f in os.listdir(test_dir) if f.endswith(\"_1.tif\")]\n",
    "print(f\"Found {len(test_images)} test images to process\")\n",
    "\n",
    "# Process all images with block damage (overwriting originals)\n",
    "for filename in tqdm(test_images, desc=\"Applying block damage\"):\n",
    "    image_path = os.path.join(test_dir, filename)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is not None:\n",
    "        # Apply block damage and overwrite original\n",
    "        damaged_image = apply_block_damage(image)\n",
    "        cv2.imwrite(image_path, damaged_image)\n",
    "\n",
    "print(f\"\\nSuccessfully applied block damage to {len(test_images)} images\")\n",
    "print(f\"Original images in {test_dir} have been overwritten\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
